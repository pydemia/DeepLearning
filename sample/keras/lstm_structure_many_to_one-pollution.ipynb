{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#LSTM-Lecture\" data-toc-modified-id=\"LSTM-Lecture-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>LSTM Lecture</a></div><div class=\"lev1 toc-item\"><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Many-to-One\" data-toc-modified-id=\"Many-to-One-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Many to One</a></div><div class=\"lev2 toc-item\"><a href=\"#Reshaping-the-Data-1-(X-:-Multiple,-Y-:-1)\" data-toc-modified-id=\"Reshaping-the-Data-1-(X-:-Multiple,-Y-:-1)-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Reshaping the Data 1 (X : Multiple, Y : 1)</a></div><div class=\"lev3 toc-item\"><a href=\"#Dimension\" data-toc-modified-id=\"Dimension-311\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Dimension</a></div><div class=\"lev3 toc-item\"><a href=\"#Assignment\" data-toc-modified-id=\"Assignment-312\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Assignment</a></div><div class=\"lev3 toc-item\"><a href=\"#Reshaping-:-1D-to-2D-(for-MinMaxScaler)\" data-toc-modified-id=\"Reshaping-:-1D-to-2D-(for-MinMaxScaler)-313\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Reshaping : 1D to 2D (for <code>MinMaxScaler</code>)</a></div><div class=\"lev3 toc-item\"><a href=\"#Scaling-:-MinMax,-0-~-1\" data-toc-modified-id=\"Scaling-:-MinMax,-0-~-1-314\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Scaling : <code>MinMax</code>, 0 ~ 1</a></div><div class=\"lev3 toc-item\"><a href=\"#Reshaping-X:-2D-to-3D,-(Samples,-Timestep-Sequence,-Features)\" data-toc-modified-id=\"Reshaping-X:-2D-to-3D,-(Samples,-Timestep-Sequence,-Features)-315\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Reshaping <code>X</code>: 2D to 3D, (Samples, Timestep-Sequence, Features)</a></div><div class=\"lev3 toc-item\"><a href=\"#Splitting-:-Train-&amp;-Test\" data-toc-modified-id=\"Splitting-:-Train-&amp;-Test-316\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Splitting : Train &amp; Test</a></div><div class=\"lev3 toc-item\"><a href=\"#Callback-Objects\" data-toc-modified-id=\"Callback-Objects-317\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Callback Objects</a></div><div class=\"lev2 toc-item\"><a href=\"#LSTM-Model-:-Single-Output\" data-toc-modified-id=\"LSTM-Model-:-Single-Output-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>LSTM Model : Single Output</a></div><div class=\"lev3 toc-item\"><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Modeling</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Training</a></div><div class=\"lev3 toc-item\"><a href=\"#Scoring\" data-toc-modified-id=\"Scoring-323\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Scoring</a></div><div class=\"lev3 toc-item\"><a href=\"#Testing\" data-toc-modified-id=\"Testing-324\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Testing</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm'](lstm.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Recurrent Neural Networks, we are quickly confronted to the so-called __gradient vanishing problem__:\n",
    "\n",
    "In machine learning, __the vanishing gradient problem__ is a difficulty found in training artificial neural networks with gradient-based learning methods and backpropagation.  \n",
    "In such methods, each of the neural network’s weights receives an update proportional to the gradient of the error function with respect to the current weight in each iteration of training.   \n",
    "_Traditional activation functions such as the hyperbolic tangent function have gradients in the range `(−1,1)` or `(0,1)`_, and backpropagation computes gradients by the chain rule.  \n",
    "This has the effect of multiplying n of these small numbers to compute gradients of the “front” layers in an n-layer network, meaning that the gradient (error signal) decreases exponentially with n and the front layers train very slowly.\n",
    "\n",
    "One solution is __to consider *adding the updates* instead of multiplying them__, and this is exactly what the LSTM does. The state of every cell is updated in an additive way (Equation 9) such that the gradient hardly vanishes.\n",
    "\n",
    "![lstm](keras_stateful_lstm_2.png)\n",
    "![lstm](lstm_basic.png)\n",
    "![lstm](lstm_module.jpg)\n",
    "![](LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Flatten\n",
    "from keras.callbacks import Callback, LambdaCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Embedding, RepeatVector, Permute, Lambda\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Reshape, dot, multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
      "date                                                                          \n",
      "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
      "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
      "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
      "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
      "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 05:00:00</th>\n",
       "      <td>109.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>7.14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 06:00:00</th>\n",
       "      <td>105.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>8.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 07:00:00</th>\n",
       "      <td>124.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 08:00:00</th>\n",
       "      <td>120.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 09:00:00</th>\n",
       "      <td>132.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>14.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 10:00:00</th>\n",
       "      <td>140.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>17.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 11:00:00</th>\n",
       "      <td>152.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>20.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 12:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>23.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 13:00:00</th>\n",
       "      <td>164.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>27.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 14:00:00</th>\n",
       "      <td>158.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>31.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 15:00:00</th>\n",
       "      <td>154.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>35.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 16:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>37.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 17:00:00</th>\n",
       "      <td>164.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>39.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 18:00:00</th>\n",
       "      <td>170.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>42.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 19:00:00</th>\n",
       "      <td>149.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>44.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 20:00:00</th>\n",
       "      <td>154.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>46.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 21:00:00</th>\n",
       "      <td>164.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>49.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 22:00:00</th>\n",
       "      <td>156.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>52.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 23:00:00</th>\n",
       "      <td>126.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>55.43</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 00:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>58.56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 01:00:00</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>61.69</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 02:00:00</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>65.71</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 03:00:00</th>\n",
       "      <td>55.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>68.84</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 04:00:00</th>\n",
       "      <td>65.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>72.86</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 05:00:00</th>\n",
       "      <td>83.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>76.88</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 18:00:00</th>\n",
       "      <td>79.0</td>\n",
       "      <td>-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 19:00:00</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 20:00:00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 21:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>21.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>31.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 23:00:00</th>\n",
       "      <td>16.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>38.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 00:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>51.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 01:00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-18</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>61.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 02:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>70.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 03:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>81.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 04:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>94.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 05:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>109.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 06:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>130.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 07:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>143.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 08:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>150.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>155.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 10:00:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>163.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 11:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>170.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>17.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>177.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 13:00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>186.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>196.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>205.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>214.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>221.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>226.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
       "date                                                                          \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n",
       "2010-01-02 05:00:00      109.0   -7  -6.0  1022.0      SE     7.14     3     0\n",
       "2010-01-02 06:00:00      105.0   -7  -6.0  1023.0      SE     8.93     4     0\n",
       "2010-01-02 07:00:00      124.0   -7  -5.0  1024.0      SE    10.72     0     0\n",
       "2010-01-02 08:00:00      120.0   -8  -6.0  1024.0      SE    12.51     0     0\n",
       "2010-01-02 09:00:00      132.0   -7  -5.0  1025.0      SE    14.30     0     0\n",
       "2010-01-02 10:00:00      140.0   -7  -5.0  1026.0      SE    17.43     1     0\n",
       "2010-01-02 11:00:00      152.0   -8  -5.0  1026.0      SE    20.56     0     0\n",
       "2010-01-02 12:00:00      148.0   -8  -5.0  1026.0      SE    23.69     0     0\n",
       "2010-01-02 13:00:00      164.0   -8  -5.0  1025.0      SE    27.71     0     0\n",
       "2010-01-02 14:00:00      158.0   -9  -5.0  1025.0      SE    31.73     0     0\n",
       "2010-01-02 15:00:00      154.0   -9  -5.0  1025.0      SE    35.75     0     0\n",
       "2010-01-02 16:00:00      159.0   -9  -5.0  1026.0      SE    37.54     0     0\n",
       "2010-01-02 17:00:00      164.0   -8  -5.0  1027.0      SE    39.33     0     0\n",
       "2010-01-02 18:00:00      170.0   -8  -5.0  1027.0      SE    42.46     0     0\n",
       "2010-01-02 19:00:00      149.0   -8  -5.0  1028.0      SE    44.25     0     0\n",
       "2010-01-02 20:00:00      154.0   -7  -5.0  1028.0      SE    46.04     0     0\n",
       "2010-01-02 21:00:00      164.0   -7  -5.0  1027.0      SE    49.17     1     0\n",
       "2010-01-02 22:00:00      156.0   -8  -6.0  1028.0      SE    52.30     2     0\n",
       "2010-01-02 23:00:00      126.0   -8  -6.0  1027.0      SE    55.43     3     0\n",
       "2010-01-03 00:00:00       90.0   -7  -6.0  1027.0      SE    58.56     4     0\n",
       "2010-01-03 01:00:00       63.0   -8  -6.0  1026.0      SE    61.69     5     0\n",
       "2010-01-03 02:00:00       65.0   -8  -7.0  1026.0      SE    65.71     6     0\n",
       "2010-01-03 03:00:00       55.0   -8  -7.0  1025.0      SE    68.84     7     0\n",
       "2010-01-03 04:00:00       65.0   -8  -7.0  1024.0      SE    72.86     8     0\n",
       "2010-01-03 05:00:00       83.0   -9  -8.0  1024.0      SE    76.88     9     0\n",
       "...                        ...  ...   ...     ...     ...      ...   ...   ...\n",
       "2014-12-30 18:00:00       79.0  -13   2.0  1020.0      NE     3.58     0     0\n",
       "2014-12-30 19:00:00       35.0   -8   6.0  1021.0      NW     5.81     0     0\n",
       "2014-12-30 20:00:00       26.0  -11   5.0  1022.0      NW    12.96     0     0\n",
       "2014-12-30 21:00:00       20.0  -12   4.0  1023.0      NW    21.90     0     0\n",
       "2014-12-30 22:00:00        8.0  -21   2.0  1025.0      NW    31.73     0     0\n",
       "2014-12-30 23:00:00       16.0  -22   0.0  1026.0      NW    38.88     0     0\n",
       "2014-12-31 00:00:00       10.0  -19  -1.0  1027.0      NW    51.84     0     0\n",
       "2014-12-31 01:00:00       11.0  -18  -1.0  1028.0      NW    61.67     0     0\n",
       "2014-12-31 02:00:00       20.0  -17  -1.0  1028.0      NW    70.61     0     0\n",
       "2014-12-31 03:00:00        9.0  -17  -1.0  1029.0      NW    81.79     0     0\n",
       "2014-12-31 04:00:00        8.0  -19  -2.0  1030.0      NW    94.75     0     0\n",
       "2014-12-31 05:00:00        9.0  -21  -3.0  1030.0      NW   109.95     0     0\n",
       "2014-12-31 06:00:00        8.0  -23  -4.0  1032.0      NW   130.07     0     0\n",
       "2014-12-31 07:00:00        8.0  -22  -5.0  1034.0      NW   143.03     0     0\n",
       "2014-12-31 08:00:00        8.0  -22  -5.0  1034.0      NW   150.18     0     0\n",
       "2014-12-31 09:00:00        8.0  -22  -3.0  1034.0      NW   155.99     0     0\n",
       "2014-12-31 10:00:00        7.0  -22  -2.0  1034.0      NW   163.14     0     0\n",
       "2014-12-31 11:00:00       12.0  -22  -2.0  1034.0      NW   170.29     0     0\n",
       "2014-12-31 12:00:00       17.0  -22   0.0  1033.0      NW   177.44     0     0\n",
       "2014-12-31 13:00:00       11.0  -27   0.0  1032.0      NW   186.38     0     0\n",
       "2014-12-31 14:00:00        9.0  -27   1.0  1032.0      NW   196.21     0     0\n",
       "2014-12-31 15:00:00       11.0  -26   1.0  1032.0      NW   205.15     0     0\n",
       "2014-12-31 16:00:00        8.0  -23   0.0  1032.0      NW   214.09     0     0\n",
       "2014-12-31 17:00:00        9.0  -22  -1.0  1033.0      NW   221.24     0     0\n",
       "2014-12-31 18:00:00       10.0  -22  -2.0  1033.0      NW   226.16     0     0\n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0      NW   231.97     0     0\n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0      NW   237.78     0     0\n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0      NW   242.70     0     0\n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0      NW   246.72     0     0\n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0      NW   249.85     0     0\n",
       "\n",
       "[43800 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
    "data = read_csv('PRSA_data_2010.1.1-2014.12.31.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "data.drop('No', axis=1, inplace=True)\n",
    "# manually specify column names\n",
    "data.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "data.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "data['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "data = data[24:]\n",
    "# summarize first 5 rows\n",
    "print(data.head(5))\n",
    "# save to file\n",
    "data.to_csv('pollution.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28a5553048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# specify columns to plot\n",
    "groups = [0, 1, 2, 3, 5, 6, 7]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(values[:, group])\n",
    "\tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
      "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
      "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
      "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
      "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
      "\n",
      "   var7(t-1)  var8(t-1)   var1(t)  \n",
      "1   0.000000        0.0  0.148893  \n",
      "2   0.000000        0.0  0.159960  \n",
      "3   0.000000        0.0  0.182093  \n",
      "4   0.037037        0.0  0.138833  \n",
      "5   0.074074        0.0  0.109658  \n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 8) (8760,) (35039, 1, 8) (35039,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print('Train_X\\t: %s\\nTrain_Y\\t: %s\\nTest_X\\t: %s\\nTest_Y\\t: %s\\n' % \n",
    "      (train_X.shape, train_Y.shape, test_X.shape, test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                18688     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 18,753\n",
      "Trainable params: 18,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7008 samples, validate on 1752 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0713\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0496\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0275 - val_loss: 0.0363\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0143\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    validation_split=.2,\n",
    "                    #validation_data=(test_X, test_y),\n",
    "                    verbose=2,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28a3169358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.578\n"
     ]
    }
   ],
   "source": [
    "from numpy import concatenate, sqrt\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.,  20.,  19., ...,  10.,   8.,  12.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 38.78778839,  32.81549835,  21.99749947, ...,  13.15476322,\n",
       "        13.13411522,  11.38121605], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 12.0, Predict: 11.3812\n"
     ]
    }
   ],
   "source": [
    "print('Real: %s, Predict: %s' % (inv_y[-1], inv_yhat[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_many_to_one'](lstm_many_to_one.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the Data 1 (X : Multiple, Y : 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcol = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "ycol = ['pollution']\n",
    "xfeature = len(xcol)\n",
    "yfeature = len(ycol)\n",
    "look_back = timestep = xlen = 5\n",
    "foresight = 1\n",
    "ylen = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "data.iloc[:, 4] = encoder.fit_transform(data.iloc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43800, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 129.        ,  -16.        ,   -4.        , ...,    1.78999996,\n",
       "           0.        ,    0.        ],\n",
       "       [ 148.        ,  -15.        ,   -4.        , ...,    2.68000007,\n",
       "           0.        ,    0.        ],\n",
       "       [ 159.        ,  -11.        ,   -5.        , ...,    3.56999993,\n",
       "           0.        ,    0.        ],\n",
       "       ..., \n",
       "       [  10.        ,  -22.        ,   -3.        , ...,  242.69999695,\n",
       "           0.        ,    0.        ],\n",
       "       [   8.        ,  -22.        ,   -4.        , ...,  246.72000122,\n",
       "           0.        ,    0.        ],\n",
       "       [  12.        ,  -21.        ,   -3.        , ...,  249.8500061 ,\n",
       "           0.        ,    0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_1d = data.loc[:, xcol].values.astype('float32')\n",
    "print(data_X_1d.shape)\n",
    "data_X_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43800, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 129.],\n",
       "       [ 148.],\n",
       "       [ 159.],\n",
       "       ..., \n",
       "       [  10.],\n",
       "       [   8.],\n",
       "       [  12.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y_1d = data.loc[:, ycol].values.astype('float32')\n",
    "print(data_Y_1d.shape)\n",
    "data_Y_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping : 1D to 2D (for `MinMaxScaler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43800, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 129.        ,  -16.        ,   -4.        , ...,    1.78999996,\n",
       "           0.        ,    0.        ],\n",
       "       [ 148.        ,  -15.        ,   -4.        , ...,    2.68000007,\n",
       "           0.        ,    0.        ],\n",
       "       [ 159.        ,  -11.        ,   -5.        , ...,    3.56999993,\n",
       "           0.        ,    0.        ],\n",
       "       ..., \n",
       "       [  10.        ,  -22.        ,   -3.        , ...,  242.69999695,\n",
       "           0.        ,    0.        ],\n",
       "       [   8.        ,  -22.        ,   -4.        , ...,  246.72000122,\n",
       "           0.        ,    0.        ],\n",
       "       [  12.        ,  -21.        ,   -3.        , ...,  249.8500061 ,\n",
       "           0.        ,    0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_2d = data_X_1d.reshape(-1, xfeature)\n",
    "print(data_X_2d.shape)\n",
    "data_X_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43800, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 129.],\n",
       "       [ 148.],\n",
       "       [ 159.],\n",
       "       ..., \n",
       "       [  10.],\n",
       "       [   8.],\n",
       "       [  12.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y_2d = data_Y_1d.reshape(-1, yfeature)\n",
    "print(data_Y_2d.shape)\n",
    "data_Y_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling : `MinMax`, 0 ~ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12977867  0.35294122  0.24590163 ...,  0.00229001  0.          0.        ]\n",
      " [ 0.14889336  0.36764708  0.24590163 ...,  0.00381099  0.          0.        ]\n",
      " [ 0.15995975  0.42647061  0.22950819 ...,  0.00533197  0.          0.        ]\n",
      " ..., \n",
      " [ 0.01006036  0.2647059   0.26229507 ...,  0.41399646  0.          0.        ]\n",
      " [ 0.00804829  0.2647059   0.24590163 ...,  0.42086649  0.          0.        ]\n",
      " [ 0.01207243  0.27941179  0.26229507 ...,  0.42621556  0.          0.        ]]\n",
      "[[ 0.12977867]\n",
      " [ 0.14889336]\n",
      " [ 0.15995975]\n",
      " ..., \n",
      " [ 0.01006036]\n",
      " [ 0.00804829]\n",
      " [ 0.01207243]]\n"
     ]
    }
   ],
   "source": [
    "scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_X = scalerX.fit_transform(data_X_2d)\n",
    "scaled_Y = scalerY.fit_transform(data_Y_2d)\n",
    "\n",
    "print(scaled_X)\n",
    "print(scaled_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping `X`: 2D to 3D, (Samples, Timestep-Sequence, Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43793"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_X) - xlen - foresight - ylen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (43795, 5, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.12977867,  0.35294122,  0.24590163, ...,  0.00229001,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.14889336,  0.36764708,  0.24590163, ...,  0.00381099,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.15995975,  0.42647061,  0.22950819, ...,  0.00533197,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.18209255,  0.48529413,  0.22950819, ...,  0.00839101,\n",
       "          0.03703704,  0.        ],\n",
       "        [ 0.13883299,  0.48529413,  0.22950819, ...,  0.00991199,\n",
       "          0.07407407,  0.        ]],\n",
       "\n",
       "       [[ 0.14889336,  0.36764708,  0.24590163, ...,  0.00381099,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.15995975,  0.42647061,  0.22950819, ...,  0.00533197,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.18209255,  0.48529413,  0.22950819, ...,  0.00839101,\n",
       "          0.03703704,  0.        ],\n",
       "        [ 0.13883299,  0.48529413,  0.22950819, ...,  0.00991199,\n",
       "          0.07407407,  0.        ],\n",
       "        [ 0.10965794,  0.48529413,  0.21311474, ...,  0.01143297,\n",
       "          0.11111111,  0.        ]],\n",
       "\n",
       "       [[ 0.15995975,  0.42647061,  0.22950819, ...,  0.00533197,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.18209255,  0.48529413,  0.22950819, ...,  0.00839101,\n",
       "          0.03703704,  0.        ],\n",
       "        [ 0.13883299,  0.48529413,  0.22950819, ...,  0.00991199,\n",
       "          0.07407407,  0.        ],\n",
       "        [ 0.10965794,  0.48529413,  0.21311474, ...,  0.01143297,\n",
       "          0.11111111,  0.        ],\n",
       "        [ 0.1056338 ,  0.48529413,  0.21311474, ...,  0.01449201,\n",
       "          0.14814815,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.00804829,  0.25000003,  0.3114754 , ...,  0.36510301,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00905433,  0.2647059 ,  0.29508194, ...,  0.37732211,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.27868852, ...,  0.38573021,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00804829,  0.25000003,  0.27868852, ...,  0.39565927,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.26229507, ...,  0.40558836,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.00905433,  0.2647059 ,  0.29508194, ...,  0.37732211,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.27868852, ...,  0.38573021,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00804829,  0.25000003,  0.27868852, ...,  0.39565927,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.26229507, ...,  0.40558836,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.26229507, ...,  0.41399646,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.01006036,  0.2647059 ,  0.27868852, ...,  0.38573021,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00804829,  0.25000003,  0.27868852, ...,  0.39565927,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.26229507, ...,  0.40558836,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01006036,  0.2647059 ,  0.26229507, ...,  0.41399646,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00804829,  0.2647059 ,  0.24590163, ...,  0.42086649,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_X = np.array([scaled_X[i:i+xlen] for i in range(0, len(scaled_X) - xlen - (foresight - 1) - (ylen - 1))])\n",
    "print('X Shape:', seq_X.shape)\n",
    "seq_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Shape: (43795, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.10965794],\n",
       "       [ 0.1056338 ],\n",
       "       [ 0.12474848],\n",
       "       ..., \n",
       "       [ 0.01006036],\n",
       "       [ 0.00804829],\n",
       "       [ 0.01207243]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_Y = np.array([scaled_Y[i:i+ylen][0] for i in range(xlen + (foresight - 1), len(scaled_Y))])\n",
    "print('Y Shape:', seq_Y.shape)\n",
    "seq_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting : Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_X\t: (30656, 5, 8)\n",
      "Train_Y\t: (30656, 1)\n",
      "Test_X\t: (13139, 5, 8)\n",
      "Test_Y\t: (13139, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = .3\n",
    "\n",
    "(train_X, test_X,\n",
    " train_Y, test_Y)  = train_test_split(seq_X, seq_Y,\n",
    "                                      test_size=test_size,\n",
    "                                      shuffle=False,\n",
    "                                      random_state=99)\n",
    "\n",
    "print('Train_X\\t: %s\\nTrain_Y\\t: %s\\nTest_X\\t: %s\\nTest_Y\\t: %s\\n' % \n",
    "      (train_X.shape, train_Y.shape, test_X.shape, test_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.weights = []\n",
    "\n",
    "#    def on_batch_begin(self, batch, logs={}):\n",
    "#        self.weights.append([{'begin_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.weights.append([{'end_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[0].get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model : Single Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'lstm_2/kernel:0' shape=(8, 64) dtype=float32_ref>,\n",
      " <tf.Variable 'lstm_2/recurrent_kernel:0' shape=(16, 64) dtype=float32_ref>,\n",
      " <tf.Variable 'lstm_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'dense_2/kernel:0' shape=(16, 1) dtype=float32_ref>,\n",
      " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "(None, 5, 8)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 16)                1600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,617\n",
      "Trainable params: 1,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_len, timestepX, ndimX = train_X.shape\n",
    "#_, timestepY, ndimY = trainY.shape\n",
    "_, ndimY = train_Y.shape\n",
    "\n",
    "HIDDEN_SIZE = 16\n",
    "\n",
    "# simple lstm network learning\n",
    "model = Sequential()\n",
    "\"\"\"\n",
    "2D: (batch_size, units)\n",
    "3D: (batch_size, timesteps, input_dim)\n",
    "\"\"\"\n",
    "model.add(LSTM(HIDDEN_SIZE,  # Network Node\n",
    "               input_shape=(timestepX, ndimX),  # Time-step, Feature Number\n",
    "               #dropout=.3,  # Drop-Out Ratio; Among the Input\n",
    "               #recurrent_dropout=.3,  # Recurrent Drop-out Ratio; Among the Recurrent Network\n",
    "               #return_sequences=False,  # If LSTM Returns the sequence;the same dimension of the input.\n",
    "               #kernel_initializer=keras.initializers.Zeros(),\n",
    "               #recurrent_initializer='zeros',\n",
    "               #bias_initializer='zeros',\n",
    "               #use_bias=True\n",
    "              ))\n",
    "model.add(Dense(ndimY,  # Network Node\n",
    "                #input_shape=(ylen, ndimX),  # Time-step, Feature Number\n",
    "                #activation='linear',\n",
    "                #kernel_initializer='zeros',\n",
    "                #bias_initializer='zeros',\n",
    "               ))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "pprint(model.weights)\n",
    "print(model.input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24524 samples, validate on 6132 samples\n",
      "Epoch 1/300\n",
      "24524/24524 [==============================] - 2s 87us/step - loss: 0.0338 - val_loss: 0.0257\n",
      "Epoch 2/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0203 - val_loss: 0.0226\n",
      "Epoch 3/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0186 - val_loss: 0.0208\n",
      "Epoch 4/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0168 - val_loss: 0.0213\n",
      "Epoch 5/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0155 - val_loss: 0.0190\n",
      "Epoch 6/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0149 - val_loss: 0.0180\n",
      "Epoch 7/300\n",
      "24524/24524 [==============================] - 2s 81us/step - loss: 0.0145 - val_loss: 0.0166\n",
      "Epoch 8/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 9/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 10/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 11/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 12/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 13/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 14/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 15/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 16/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 17/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 18/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 19/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 20/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 21/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 22/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 23/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 24/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 25/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 26/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 27/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 28/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 29/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 30/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 31/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 32/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 33/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 34/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 35/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 36/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 37/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 38/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 39/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 40/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 41/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 42/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 43/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 44/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 45/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 46/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 47/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 48/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 49/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 50/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 51/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 52/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 53/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 54/300\n",
      "24524/24524 [==============================] - 2s 82us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 55/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 56/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 57/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 58/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 59/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 60/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 61/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 62/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 63/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 64/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 65/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 66/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 67/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 68/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 69/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 70/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 71/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 72/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 73/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 74/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 75/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 76/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 77/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 78/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 79/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 80/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 81/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 82/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 83/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 84/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 85/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 86/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 87/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 88/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 89/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 90/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 91/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 92/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 93/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 94/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 95/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 96/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 97/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 98/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 99/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 100/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 101/300\n",
      "24524/24524 [==============================] - 2s 82us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 102/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 103/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 104/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 105/300\n",
      "24524/24524 [==============================] - 2s 82us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 106/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 107/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 108/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 109/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 110/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 111/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 112/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 113/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 114/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 115/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 116/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 117/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 118/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 119/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 120/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 121/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 122/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 123/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 124/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 125/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 126/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 127/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 128/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 129/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 130/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 131/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 132/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 133/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 134/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 135/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 136/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 137/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 138/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 139/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 140/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 141/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 142/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 143/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 144/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 145/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 146/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 147/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 148/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 149/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 150/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 151/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 152/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 154/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 155/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 156/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 157/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 158/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 159/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 160/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 161/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 162/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 163/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 164/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 165/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 166/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 167/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 168/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 169/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 170/300\n",
      "24524/24524 [==============================] - 2s 82us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 171/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 172/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 173/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 174/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 175/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 176/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 177/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 178/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 179/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 180/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 181/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 182/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 183/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 184/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 185/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 186/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 187/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 188/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 189/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 190/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 191/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 192/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 193/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 194/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 195/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 196/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 197/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 198/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 199/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 200/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 201/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 202/300\n",
      "24524/24524 [==============================] - 2s 82us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 203/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 204/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 205/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 206/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 207/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 208/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 209/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 210/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 211/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 212/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 213/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 214/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 215/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 216/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 217/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 218/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 219/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 220/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 221/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 222/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 223/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 224/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 225/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 226/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 227/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 228/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 230/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 231/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 232/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 233/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 234/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 235/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 236/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 237/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 238/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 239/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 240/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 241/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 242/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 243/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 244/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 245/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 246/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 247/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 248/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 249/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 250/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 251/300\n",
      "24524/24524 [==============================] - 2s 83us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 252/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 253/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 254/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 255/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 256/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 257/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 258/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 259/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 260/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 261/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 262/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 263/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 264/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 265/300\n",
      "24524/24524 [==============================] - 2s 80us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 266/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 267/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 268/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 269/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 270/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 271/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 272/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 273/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 274/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 275/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 276/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 277/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 278/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 279/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 280/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 281/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 282/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 283/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 284/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 285/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 286/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 287/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 288/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 289/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 290/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 291/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 292/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 293/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 294/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 295/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 296/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 297/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 298/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 299/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 300/300\n",
      "24524/24524 [==============================] - 2s 79us/step - loss: 0.0126 - val_loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 300\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=EPOCH_NUM,     # How many times to run back_propagation\n",
    "                   batch_size=BATCH_SIZE,  # How many data to deal with at one epoch\n",
    "                   verbose=1,       # 1: progress bar, 2: one line per epoch\n",
    "                   validation_split=.2,\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=False,\n",
    "                   callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18334484, 0.076655127, 0.14146312]\n",
      "[[{'end_lstm_2': [array([[  8.45291167e-02,  -1.38753587e-02,   1.35443285e-01,\n",
      "          1.87175408e-01,  -3.26788635e-03,  -2.56988943e-01,\n",
      "          2.14865252e-01,  -4.97867092e-02,  -1.10149883e-01,\n",
      "         -2.87254341e-04,   1.36951715e-01,  -1.04082219e-01,\n",
      "          2.37383440e-01,  -8.70037973e-02,  -1.24991432e-01,\n",
      "          1.56815991e-01,   3.30224223e-02,  -1.73776612e-01,\n",
      "         -9.60739404e-02,   5.20283543e-02,  -1.86261311e-01,\n",
      "         -3.33466940e-02,   9.29693729e-02,   1.56575844e-01,\n",
      "          1.88969344e-01,  -2.49689788e-01,   1.65411979e-01,\n",
      "          6.64016008e-02,   2.58740604e-01,   4.99444902e-02,\n",
      "          2.02056170e-01,   2.38705397e-01,   1.58963323e-01,\n",
      "         -1.92576155e-01,  -9.24885496e-02,  -4.73724082e-02,\n",
      "          2.05910176e-01,  -2.34887287e-01,  -2.54458934e-01,\n",
      "         -2.76200086e-01,   6.75333142e-02,  -3.18728350e-02,\n",
      "          2.49737397e-01,  -1.49152085e-01,   1.24835901e-01,\n",
      "          1.28145933e-01,   8.29398409e-02,  -2.55033612e-01,\n",
      "         -1.59814119e-01,  -9.87534598e-02,   1.47144049e-01,\n",
      "         -2.44407430e-01,   1.03623509e-01,  -2.11055577e-01,\n",
      "         -1.03299245e-01,   1.36875868e-01,   1.65503860e-01,\n",
      "         -2.82050192e-01,   1.77252978e-01,   4.82492857e-02,\n",
      "          6.44819364e-02,  -2.80966014e-01,  -2.56946087e-01,\n",
      "         -1.51097164e-01],\n",
      "       [  8.12636912e-02,   1.51243404e-01,   2.35974282e-01,\n",
      "          1.08527608e-01,   2.06408471e-01,  -1.35461643e-01,\n",
      "          6.50664270e-02,  -6.00103624e-02,   2.08135605e-01,\n",
      "         -5.19917458e-02,   7.28184730e-02,  -1.40890092e-01,\n",
      "         -1.27438173e-01,  -1.26820102e-01,   9.35053527e-02,\n",
      "         -1.61284730e-01,   5.72687238e-02,   2.25658435e-02,\n",
      "          1.75543040e-01,   9.71969664e-02,   1.69386208e-01,\n",
      "          1.68927118e-01,   2.83698350e-01,  -1.11291580e-01,\n",
      "         -6.00745827e-02,   1.63757488e-01,  -5.99705428e-02,\n",
      "          3.02530304e-02,  -1.55117124e-01,   2.00285420e-01,\n",
      "          6.61223456e-02,   1.19695172e-01,   5.90953454e-02,\n",
      "          2.04540819e-01,   7.51678878e-03,   1.89745463e-02,\n",
      "          8.38440731e-02,   2.63482302e-01,  -1.78182479e-02,\n",
      "         -2.53373772e-01,   1.84713826e-01,   2.63637275e-01,\n",
      "         -1.74160361e-01,  -8.43800753e-02,  -5.12752160e-02,\n",
      "          1.30894348e-01,  -1.43946484e-01,   2.43349209e-01,\n",
      "         -1.05309956e-01,   5.00435457e-02,   1.56384379e-01,\n",
      "          2.49126211e-01,   2.33334988e-01,  -2.18152076e-01,\n",
      "          1.12368993e-01,   2.12060943e-01,  -2.36867160e-01,\n",
      "          1.51405051e-01,   2.73417026e-01,  -1.84634794e-02,\n",
      "         -1.52564451e-01,   1.51801854e-01,  -1.61613617e-02,\n",
      "          2.58192927e-01],\n",
      "       [ -2.21944913e-01,   1.62997231e-01,  -1.74454749e-01,\n",
      "          2.05161870e-02,  -1.45612940e-01,   2.20993429e-01,\n",
      "         -2.33240593e-02,  -2.47831181e-01,  -2.67578691e-01,\n",
      "          3.46627980e-02,  -8.38875547e-02,   1.27752081e-01,\n",
      "          1.78238615e-01,  -4.66145724e-02,  -2.08355129e-01,\n",
      "         -2.77753234e-01,   4.49854769e-02,   1.22103401e-01,\n",
      "         -3.24805379e-02,   1.75685629e-01,   1.12299286e-01,\n",
      "         -5.67829572e-02,   1.92084573e-02,   1.94447786e-01,\n",
      "         -5.71039580e-02,   1.57764241e-01,   2.14421540e-01,\n",
      "         -2.79989243e-01,   1.48755983e-01,  -2.56223142e-01,\n",
      "         -1.73270494e-01,  -7.90943727e-02,   1.86911285e-01,\n",
      "          1.64759248e-01,   4.89067994e-02,  -2.47707188e-01,\n",
      "         -1.49851382e-01,  -1.37643754e-01,   6.27459434e-04,\n",
      "         -1.23450331e-01,   2.74243325e-01,  -2.20062435e-01,\n",
      "         -1.70935728e-02,   2.35850558e-01,  -8.08001310e-02,\n",
      "          1.12365656e-01,  -1.07796453e-01,   1.97320402e-01,\n",
      "         -2.82605857e-01,   2.73403585e-01,   2.58497983e-01,\n",
      "         -1.20922565e-01,   2.71659970e-01,   2.82896832e-02,\n",
      "          2.72647560e-01,  -1.94890723e-01,   1.30173385e-01,\n",
      "         -2.44134903e-01,  -4.93138805e-02,   9.99577045e-02,\n",
      "          2.06985444e-01,   5.83165362e-02,   1.53924882e-01,\n",
      "          1.02119632e-01],\n",
      "       [ -5.10672107e-03,   1.55873671e-01,  -4.22800593e-02,\n",
      "         -1.51259810e-01,   1.98408723e-01,  -2.06203520e-01,\n",
      "         -1.75492242e-01,   7.54927024e-02,   9.22482535e-02,\n",
      "         -2.41645157e-01,   2.81727761e-01,  -2.63507608e-02,\n",
      "         -1.82318557e-02,  -1.05974860e-02,  -1.34854168e-01,\n",
      "         -2.04474673e-01,   2.03970462e-01,   4.35754806e-02,\n",
      "          7.45324697e-03,  -1.81249723e-01,   1.82258129e-01,\n",
      "         -1.76761776e-01,  -1.32300407e-01,  -1.22315072e-01,\n",
      "         -2.41987243e-01,   1.16981648e-01,  -3.71706150e-02,\n",
      "          2.88236141e-01,   2.11430356e-01,   2.70330966e-01,\n",
      "         -1.09042905e-01,  -8.49503502e-02,   1.69821158e-02,\n",
      "          1.28685340e-01,   7.89815560e-02,   2.37494692e-01,\n",
      "         -1.87926486e-01,  -4.18813638e-02,   1.64303631e-01,\n",
      "         -1.76916257e-01,  -1.74744338e-01,  -1.05611928e-01,\n",
      "          2.03848630e-01,  -2.35120475e-01,  -1.34584576e-01,\n",
      "          8.91089160e-03,  -3.15303989e-02,   4.53354307e-02,\n",
      "          1.39508918e-01,   5.95325939e-02,  -2.37140670e-01,\n",
      "          1.19494118e-01,  -7.06988424e-02,  -4.97059301e-02,\n",
      "         -3.28678600e-02,   1.64583743e-01,  -9.31933597e-02,\n",
      "          1.98360279e-01,   1.17632672e-01,  -4.31649461e-02,\n",
      "          1.99474946e-01,   2.11624801e-01,   6.67288154e-02,\n",
      "          7.78801441e-02],\n",
      "       [  1.43185988e-01,  -2.66181529e-01,  -1.26303256e-01,\n",
      "         -1.82464242e-01,  -1.92016870e-01,   2.32631639e-01,\n",
      "          2.65948206e-01,   2.73469359e-01,  -1.30417034e-01,\n",
      "          1.38810113e-01,  -6.73712268e-02,  -2.58171503e-02,\n",
      "          1.73272386e-01,  -1.60377368e-01,  -1.88413352e-01,\n",
      "         -2.22907037e-01,   4.10467274e-02,  -3.40588875e-02,\n",
      "          2.43299767e-01,  -1.13276199e-01,   2.50623003e-02,\n",
      "          1.95202336e-01,  -2.42422655e-01,   1.39395878e-01,\n",
      "          2.05744937e-01,  -8.72429833e-02,   2.82381296e-01,\n",
      "          1.69189572e-02,  -2.47123554e-01,   1.48754641e-01,\n",
      "         -5.56864031e-03,  -3.29563282e-02,  -2.57640541e-01,\n",
      "          2.46485636e-01,   4.57158461e-02,  -1.96298257e-01,\n",
      "          5.35116307e-02,  -2.00735390e-01,   4.86102104e-02,\n",
      "          1.40720651e-01,   2.18856469e-01,  -1.68856516e-01,\n",
      "          2.70848304e-01,   1.26417339e-01,  -2.57541627e-01,\n",
      "          7.64633529e-04,   1.62723079e-01,   1.92935660e-01,\n",
      "         -2.69378722e-01,  -5.10524586e-02,  -1.81774363e-01,\n",
      "         -9.66786891e-02,  -2.33656779e-01,   4.26570140e-03,\n",
      "         -1.71044871e-01,  -8.52088854e-02,   3.77336033e-02,\n",
      "         -9.30178910e-03,   2.43686065e-01,   4.68653254e-02,\n",
      "         -1.81689635e-01,   4.33029979e-02,   1.03647999e-01,\n",
      "         -1.70043752e-01],\n",
      "       [ -1.38527304e-01,   6.74737096e-02,   8.59535486e-02,\n",
      "         -1.47359431e-01,  -2.06237182e-01,  -2.81522453e-01,\n",
      "          1.49059743e-01,   2.08942309e-01,   1.72405735e-01,\n",
      "          2.54088789e-01,   3.96239422e-02,   3.23204068e-03,\n",
      "          2.15420425e-01,   1.84433945e-02,  -2.81199906e-02,\n",
      "         -2.91695027e-03,  -9.88548771e-02,   8.88351426e-02,\n",
      "         -1.56793103e-01,   2.17351273e-01,   1.32996932e-01,\n",
      "         -2.91391145e-02,  -2.27603331e-01,  -4.01855484e-02,\n",
      "          7.68977702e-02,  -7.27561116e-02,  -9.21950936e-02,\n",
      "         -2.36756995e-01,  -2.82626033e-01,   1.35759100e-01,\n",
      "         -1.59891620e-01,   9.78347883e-02,   1.03495970e-01,\n",
      "         -1.08493939e-01,   2.38010883e-01,  -1.24537468e-01,\n",
      "         -1.59214765e-01,   1.47964507e-01,  -3.89740206e-02,\n",
      "         -9.94308367e-02,   1.56285256e-01,  -1.47247791e-01,\n",
      "         -4.04608808e-02,   1.95918947e-01,   1.33356571e-01,\n",
      "         -5.02430424e-02,   1.45016667e-02,  -1.40341133e-01,\n",
      "          2.73024410e-01,   1.16717428e-01,   1.79868296e-01,\n",
      "         -2.84798741e-01,  -5.61100319e-02,  -1.89778998e-01,\n",
      "         -2.26082742e-01,  -2.38494471e-01,   1.37147039e-01,\n",
      "         -2.76502371e-01,  -7.64066726e-02,  -7.36397272e-03,\n",
      "          2.78651770e-02,   4.50645983e-02,  -3.72674316e-02,\n",
      "         -4.81046140e-02],\n",
      "       [ -9.87020507e-02,  -2.67098308e-01,   2.03797117e-01,\n",
      "         -2.79082268e-01,   1.79454684e-01,   2.20165372e-01,\n",
      "         -1.92016438e-01,   6.01679571e-02,  -2.07313091e-01,\n",
      "         -6.50239270e-03,  -1.57319129e-01,  -9.28082988e-02,\n",
      "         -2.16439903e-01,  -1.98348731e-01,  -7.52205178e-02,\n",
      "         -1.34228438e-01,  -1.54793272e-02,   1.44759137e-02,\n",
      "         -8.84986669e-02,   1.31617367e-01,  -2.73559362e-01,\n",
      "          1.51917953e-02,   2.64867216e-01,   2.42316231e-01,\n",
      "         -1.66033298e-01,   2.52175778e-01,  -2.18217179e-01,\n",
      "          2.29388997e-01,   2.06073582e-01,  -8.87575671e-02,\n",
      "         -2.78419498e-02,   1.30302161e-01,  -5.17470529e-03,\n",
      "         -1.56462565e-01,   4.93673459e-02,   2.84859031e-01,\n",
      "         -4.23202589e-02,   2.67255872e-01,  -7.72107542e-02,\n",
      "          2.05482200e-01,  -5.82362339e-02,  -6.01377413e-02,\n",
      "         -4.20696735e-02,   1.51687607e-01,   2.24957079e-01,\n",
      "          1.61723346e-01,  -1.37164637e-01,   3.24818715e-02,\n",
      "          7.04444870e-02,  -1.08673535e-01,  -1.53668076e-01,\n",
      "         -8.92945752e-03,   1.29525065e-01,   1.08682483e-01,\n",
      "          3.86541449e-02,   2.11489499e-01,  -1.91678151e-01,\n",
      "         -1.01367354e-01,   1.43266767e-01,   2.83856809e-01,\n",
      "         -4.20908257e-03,   2.65825987e-01,   2.05234602e-01,\n",
      "         -2.77453303e-01],\n",
      "       [ -2.07685232e-02,  -2.02241838e-02,   1.66073829e-01,\n",
      "          1.20879561e-01,   4.00519669e-02,   1.48763806e-01,\n",
      "         -2.13661790e-01,  -8.12501758e-02,  -1.76876783e-04,\n",
      "          2.86876917e-01,  -2.56270438e-01,  -1.31530792e-01,\n",
      "         -2.15680510e-01,  -2.95152068e-02,   4.20774519e-02,\n",
      "          1.89716429e-01,  -1.68205500e-02,  -1.24609217e-01,\n",
      "          2.54237354e-02,  -2.33490005e-01,  -4.27014828e-02,\n",
      "         -3.97361368e-02,  -1.69822067e-01,   1.47417784e-01,\n",
      "         -2.85891563e-01,   2.39583492e-01,   1.36604935e-01,\n",
      "          2.71327078e-01,   1.00434810e-01,  -6.53653145e-02,\n",
      "          1.55360192e-01,  -1.06591791e-01,   2.23684311e-01,\n",
      "          7.44423270e-03,  -8.66273046e-02,  -2.44444013e-02,\n",
      "         -2.78455615e-02,  -5.51560521e-03,   2.78023422e-01,\n",
      "         -2.66369045e-01,  -1.39772639e-01,  -5.54782450e-02,\n",
      "         -6.13790005e-02,  -1.06328607e-01,  -2.73412257e-01,\n",
      "         -1.50650740e-02,  -2.31306583e-01,   2.25378513e-01,\n",
      "          1.38667017e-01,  -1.41849458e-01,  -6.35934025e-02,\n",
      "          1.77474767e-01,   5.81905246e-03,   2.54075110e-01,\n",
      "         -2.37137899e-01,   2.14334667e-01,  -8.97002220e-02,\n",
      "         -1.34769231e-01,   1.50257736e-01,   1.03051662e-02,\n",
      "          8.41620266e-02,   1.96771950e-01,  -4.69058752e-04,\n",
      "         -1.42777428e-01]], dtype=float32),\n",
      "                  array([[ 0.07128213,  0.24148288, -0.02580987, ...,  0.05278025,\n",
      "        -0.02536289, -0.10098575],\n",
      "       [ 0.0668947 , -0.10380873,  0.04422551, ...,  0.06833006,\n",
      "        -0.16152076, -0.06881718],\n",
      "       [-0.10477043, -0.08678851, -0.06616439, ..., -0.0728991 ,\n",
      "         0.05307846, -0.21335071],\n",
      "       ..., \n",
      "       [ 0.11677712,  0.03657651,  0.10789979, ...,  0.28303987,\n",
      "         0.00192865, -0.28289095],\n",
      "       [-0.05362725,  0.05980552,  0.15730236, ...,  0.04946657,\n",
      "        -0.03918228,  0.04446902],\n",
      "       [ 0.02623124,  0.01097682,  0.02294551, ...,  0.11747561,\n",
      "         0.00989664,  0.07883003]], dtype=float32),\n",
      "                  array([  7.43401644e-04,   7.44124816e-04,  -7.43923476e-04,\n",
      "         7.43172073e-04,  -7.44117366e-04,  -7.42526492e-04,\n",
      "         7.43885757e-04,   7.44133722e-04,  -7.44123885e-04,\n",
      "        -7.44111254e-04,   7.44108867e-04,   7.43715849e-04,\n",
      "        -7.44129939e-04,   7.44054036e-04,  -7.44104094e-04,\n",
      "        -7.44137214e-04,   9.99256492e-01,   1.00074410e+00,\n",
      "         9.99256074e-01,   1.00073755e+00,   9.99255896e-01,\n",
      "         9.99258399e-01,   1.00074399e+00,   1.00074410e+00,\n",
      "         9.99255896e-01,   9.99255896e-01,   1.00074410e+00,\n",
      "         1.00074363e+00,   9.99255896e-01,   1.00074410e+00,\n",
      "         9.99255896e-01,   9.99255836e-01,   7.23847945e-04,\n",
      "         7.44143908e-04,  -7.44133722e-04,  -7.44127610e-04,\n",
      "         7.44144781e-04,   7.44140474e-04,   7.44138379e-04,\n",
      "        -7.44144781e-04,  -7.44144607e-04,   7.44144665e-04,\n",
      "         7.44142919e-04,  -7.44141464e-04,   7.44144141e-04,\n",
      "         7.44136865e-04,   7.44144956e-04,  -7.44144374e-04,\n",
      "         7.43449200e-04,   7.44125631e-04,  -7.43947399e-04,\n",
      "         7.43121549e-04,  -7.44118355e-04,  -7.42402335e-04,\n",
      "         7.43898447e-04,   7.44134071e-04,  -7.44125573e-04,\n",
      "        -7.44110090e-04,   7.44110439e-04,   7.43739714e-04,\n",
      "        -7.44131161e-04,   7.44043267e-04,  -7.44096877e-04,\n",
      "        -7.44136516e-04], dtype=float32)]},\n",
      "  {'end_dense_2': [array([[ 0.12863651],\n",
      "       [ 0.29658589],\n",
      "       [-0.06109651],\n",
      "       [-0.0012621 ],\n",
      "       [ 0.53919536],\n",
      "       [ 0.01448114],\n",
      "       [ 0.14830777],\n",
      "       [-0.34770679],\n",
      "       [-0.5699864 ],\n",
      "       [ 0.58823711],\n",
      "       [ 0.2599766 ],\n",
      "       [-0.09501975],\n",
      "       [ 0.34789303],\n",
      "       [ 0.07877574],\n",
      "       [ 0.5708952 ],\n",
      "       [-0.55204731]], dtype=float32),\n",
      "                   array([ 0.00074415], dtype=float32)]}],\n",
      " [{'end_lstm_2': [array([[  8.52975696e-02,  -1.31044509e-02,   1.34649292e-01,\n",
      "          1.87521011e-01,  -4.12663072e-03,  -2.57841200e-01,\n",
      "          2.15714440e-01,  -4.89616469e-02,  -1.10660404e-01,\n",
      "         -1.12107664e-03,   1.37758791e-01,  -1.03290878e-01,\n",
      "          2.36573860e-01,  -8.62620324e-02,  -1.25616789e-01,\n",
      "          1.56043053e-01,   3.24698277e-02,  -1.72993898e-01,\n",
      "         -9.68663394e-02,   5.19543290e-02,  -1.87120289e-01,\n",
      "         -3.42002101e-02,   9.38174352e-02,   1.57402426e-01,\n",
      "          1.88413724e-01,  -2.50489622e-01,   1.66213661e-01,\n",
      "          6.71733618e-02,   2.57933170e-01,   5.06815203e-02,\n",
      "          2.01353490e-01,   2.37935811e-01,   1.58114329e-01,\n",
      "         -1.91750929e-01,  -9.32852551e-02,  -4.81984019e-02,\n",
      "          2.06719831e-01,  -2.34081507e-01,  -2.53682375e-01,\n",
      "         -2.77000606e-01,   6.67152703e-02,  -3.10654230e-02,\n",
      "          2.50546753e-01,  -1.49969041e-01,   1.25658438e-01,\n",
      "          1.28977001e-01,   8.37498605e-02,  -2.55861223e-01,\n",
      "         -1.59045070e-01,  -9.79777649e-02,   1.46346673e-01,\n",
      "         -2.44066477e-01,   1.02764346e-01,  -2.11907402e-01,\n",
      "         -1.02446206e-01,   1.37703329e-01,   1.64999589e-01,\n",
      "         -2.82882154e-01,   1.78073972e-01,   4.90320139e-02,\n",
      "          6.36762753e-02,  -2.80212611e-01,  -2.57617503e-01,\n",
      "         -1.51871711e-01],\n",
      "       [  8.20360705e-02,   1.52021885e-01,   2.35170916e-01,\n",
      "          1.08671017e-01,   2.05549523e-01,  -1.36237487e-01,\n",
      "          6.59181774e-02,  -5.91708981e-02,   2.07669973e-01,\n",
      "         -5.28235398e-02,   7.36288652e-02,  -1.40134498e-01,\n",
      "         -1.28253862e-01,  -1.26076505e-01,   9.28177908e-02,\n",
      "         -1.62064940e-01,   5.68117760e-02,   2.33546663e-02,\n",
      "          1.74742773e-01,   9.67731923e-02,   1.68527216e-01,\n",
      "          1.68142870e-01,   2.84549743e-01,  -1.10452667e-01,\n",
      "         -6.05986975e-02,   1.62956282e-01,  -5.91642931e-02,\n",
      "          3.09947915e-02,  -1.55930191e-01,   2.01022908e-01,\n",
      "          6.53889477e-02,   1.18921556e-01,   5.84213585e-02,\n",
      "          2.05371261e-01,   6.71488745e-03,   1.81387942e-02,\n",
      "          8.46608430e-02,   2.64295399e-01,  -1.70399789e-02,\n",
      "         -2.54180521e-01,   1.83891281e-01,   2.64450788e-01,\n",
      "         -1.73345149e-01,  -8.52042809e-02,  -5.04478030e-02,\n",
      "          1.31728381e-01,  -1.43129393e-01,   2.42516816e-01,\n",
      "         -1.04531616e-01,   5.08212298e-02,   1.55582979e-01,\n",
      "          2.49268636e-01,   2.32475460e-01,  -2.18926266e-01,\n",
      "          1.13220699e-01,   2.12899745e-01,  -2.37322018e-01,\n",
      "          1.50581583e-01,   2.74236202e-01,  -1.77074466e-02,\n",
      "         -1.53372616e-01,   1.52552575e-01,  -1.68780014e-02,\n",
      "          2.57416666e-01],\n",
      "       [ -2.21199274e-01,   1.63753688e-01,  -1.75236046e-01,\n",
      "          2.07783189e-02,  -1.46467775e-01,   2.20145926e-01,\n",
      "         -2.24823020e-02,  -2.47009739e-01,  -2.68065631e-01,\n",
      "          3.38437855e-02,  -8.30991790e-02,   1.28549606e-01,\n",
      "          1.77445292e-01,  -4.58863042e-02,  -2.09089816e-01,\n",
      "         -2.78515220e-01,   4.45847176e-02,   1.22868925e-01,\n",
      "         -3.32589969e-02,   1.75407246e-01,   1.11443929e-01,\n",
      "         -5.76361045e-02,   2.00484172e-02,   1.95266679e-01,\n",
      "         -5.76277561e-02,   1.56982929e-01,   2.15202957e-01,\n",
      "         -2.79203922e-01,   1.47967070e-01,  -2.55501866e-01,\n",
      "         -1.74054682e-01,  -7.98487663e-02,   1.86165631e-01,\n",
      "          1.65572971e-01,   4.81231287e-02,  -2.48524338e-01,\n",
      "         -1.49052873e-01,  -1.36849463e-01,   1.38925482e-03,\n",
      "         -1.24237612e-01,   2.73439109e-01,  -2.19268218e-01,\n",
      "         -1.62954889e-02,   2.35044032e-01,  -7.99898803e-02,\n",
      "          1.13182545e-01,  -1.06998116e-01,   1.96505353e-01,\n",
      "         -2.81838953e-01,   2.74158150e-01,   2.57716835e-01,\n",
      "         -1.20681301e-01,   2.70802706e-01,   2.74419133e-02,\n",
      "          2.73491412e-01,  -1.94071129e-01,   1.29708633e-01,\n",
      "         -2.44945988e-01,  -4.85174172e-02,   1.00753650e-01,\n",
      "          2.06201032e-01,   5.90493008e-02,   1.53157473e-01,\n",
      "          1.01361386e-01],\n",
      "       [ -4.25387360e-03,   1.56728774e-01,  -4.31393981e-02,\n",
      "         -1.51521355e-01,   1.97581902e-01,  -2.06947803e-01,\n",
      "         -1.74651563e-01,   7.63425604e-02,   9.19902176e-02,\n",
      "         -2.42499366e-01,   2.82586992e-01,  -2.56308392e-02,\n",
      "         -1.90907046e-02,  -9.75734647e-03,  -1.35672763e-01,\n",
      "         -2.05331072e-01,   2.03747496e-01,   4.44336496e-02,\n",
      "          6.59389747e-03,  -1.81828782e-01,   1.81432292e-01,\n",
      "         -1.77506804e-01,  -1.31460056e-01,  -1.21464506e-01,\n",
      "         -2.42415503e-01,   1.16122045e-01,  -3.63111719e-02,\n",
      "          2.88951993e-01,   2.10571259e-01,   2.71167278e-01,\n",
      "         -1.09885797e-01,  -8.58047679e-02,   1.63794439e-02,\n",
      "          1.29539728e-01,   7.81219453e-02,   2.36642540e-01,\n",
      "         -1.87068328e-01,  -4.10226062e-02,   1.65160015e-01,\n",
      "         -1.77775681e-01,  -1.75601646e-01,  -1.04753099e-01,\n",
      "          2.04707339e-01,  -2.35976994e-01,  -1.33729294e-01,\n",
      "          9.76437051e-03,  -3.06722671e-02,   4.44818623e-02,\n",
      "          1.40361413e-01,   6.03872016e-02,  -2.38000050e-01,\n",
      "          1.19235978e-01,  -7.15231746e-02,  -5.04468344e-02,\n",
      "         -3.20243277e-02,   1.65434957e-01,  -9.34444293e-02,\n",
      "          1.97503120e-01,   1.18490741e-01,  -4.24432792e-02,\n",
      "          1.98615372e-01,   2.12468445e-01,   6.58939406e-02,\n",
      "          7.70251527e-02],\n",
      "       [  1.43970713e-01,  -2.65384436e-01,  -1.27084211e-01,\n",
      "         -1.81856558e-01,  -1.92855731e-01,   2.31908977e-01,\n",
      "          2.66791224e-01,   2.74278492e-01,  -1.31048709e-01,\n",
      "          1.37968093e-01,  -6.65535331e-02,  -2.50758640e-02,\n",
      "          1.72452003e-01,  -1.59645304e-01,  -1.88685626e-01,\n",
      "         -2.23687768e-01,   4.04489934e-02,  -3.32801975e-02,\n",
      "          2.42525697e-01,  -1.13497250e-01,   2.42143236e-02,\n",
      "          1.94440186e-01,  -2.41583958e-01,   1.40217334e-01,\n",
      "          2.05154896e-01,  -8.80322903e-02,   2.83175588e-01,\n",
      "          1.76538657e-02,  -2.47924447e-01,   1.49480477e-01,\n",
      "         -6.14747498e-03,  -3.37168239e-02,  -2.58313894e-01,\n",
      "          2.47289807e-01,   4.49437387e-02,  -1.97120026e-01,\n",
      "          5.43032363e-02,  -1.99945793e-01,   4.93666194e-02,\n",
      "          1.39932781e-01,   2.18053341e-01,  -1.68064535e-01,\n",
      "          2.71637440e-01,   1.25615239e-01,  -2.56742299e-01,\n",
      "          1.58277329e-03,   1.63516164e-01,   1.92128345e-01,\n",
      "         -2.68544316e-01,  -5.02718873e-02,  -1.82549864e-01,\n",
      "         -9.62126330e-02,  -2.34506175e-01,   3.52742546e-03,\n",
      "         -1.70204073e-01,  -8.43914077e-02,   3.71626951e-02,\n",
      "         -1.01202726e-02,   2.44499415e-01,   4.76261638e-02,\n",
      "         -1.82494551e-01,   4.40439545e-02,   1.03193715e-01,\n",
      "         -1.70810685e-01],\n",
      "       [ -1.37742400e-01,   6.82667568e-02,   8.51228908e-02,\n",
      "         -1.47691056e-01,  -2.07095668e-01,  -2.81655341e-01,\n",
      "          1.49894446e-01,   2.09800825e-01,   1.71993271e-01,\n",
      "          2.53245294e-01,   4.04421873e-02,   3.93722393e-03,\n",
      "          2.14591399e-01,   1.91928949e-02,  -2.87845954e-02,\n",
      "         -3.70412134e-03,  -9.90391299e-02,   8.96418616e-02,\n",
      "         -1.57621279e-01,   2.16620997e-01,   1.32137477e-01,\n",
      "         -2.94549186e-02,  -2.26755023e-01,  -3.93309258e-02,\n",
      "          7.63475373e-02,  -7.35873058e-02,  -9.13734362e-02,\n",
      "         -2.35991865e-01,  -2.83450335e-01,   1.36507168e-01,\n",
      "         -1.60599247e-01,   9.70505923e-02,   1.03212819e-01,\n",
      "         -1.07647754e-01,   2.37198487e-01,  -1.25395566e-01,\n",
      "         -1.58377588e-01,   1.48805514e-01,  -3.82170305e-02,\n",
      "         -1.00262895e-01,   1.55445874e-01,  -1.46415740e-01,\n",
      "         -3.96353155e-02,   1.95072204e-01,   1.34201363e-01,\n",
      "         -4.93981428e-02,   1.53415175e-02,  -1.41189456e-01,\n",
      "          2.73780853e-01,   1.17486730e-01,   1.79054841e-01,\n",
      "         -2.85059333e-01,  -5.69694452e-02,  -1.90162882e-01,\n",
      "         -2.25283667e-01,  -2.37641081e-01,   1.36723474e-01,\n",
      "         -2.77324289e-01,  -7.56045505e-02,  -6.57958305e-03,\n",
      "          2.70604044e-02,   4.58105356e-02,  -3.79546471e-02,\n",
      "         -4.88735363e-02],\n",
      "       [ -9.81288627e-02,  -2.66523182e-01,   2.03222558e-01,\n",
      "         -2.79653847e-01,   1.78879559e-01,   2.20740139e-01,\n",
      "         -1.91442594e-01,   6.07430227e-02,  -2.07888246e-01,\n",
      "         -7.07753887e-03,  -1.56744033e-01,  -9.33831334e-02,\n",
      "         -2.17015043e-01,  -1.97773769e-01,  -7.57956952e-02,\n",
      "         -1.34803623e-01,  -1.60530880e-02,   1.50510594e-02,\n",
      "         -8.90732408e-02,   1.31046623e-01,  -2.74134487e-01,\n",
      "          1.57663189e-02,   2.65441686e-01,   2.42891327e-01,\n",
      "         -1.66608468e-01,   2.51600593e-01,  -2.17642039e-01,\n",
      "          2.28814214e-01,   2.05498427e-01,  -8.81826058e-02,\n",
      "         -2.84170900e-02,   1.29726976e-01,  -4.60000616e-03,\n",
      "         -1.55887350e-01,   4.87921610e-02,   2.84283906e-01,\n",
      "         -4.17450406e-02,   2.67831087e-01,  -7.66355544e-02,\n",
      "          2.04906985e-01,  -5.88114522e-02,  -5.95625229e-02,\n",
      "         -4.14944626e-02,   1.51112407e-01,   2.25532293e-01,\n",
      "          1.62298530e-01,  -1.36589423e-01,   3.19066532e-02,\n",
      "          7.10177869e-02,  -1.08098410e-01,  -1.54242739e-01,\n",
      "         -9.49618593e-03,   1.28949940e-01,   1.09257214e-01,\n",
      "          3.92282009e-02,   2.12064594e-01,  -1.92253307e-01,\n",
      "         -1.01942502e-01,   1.43841863e-01,   2.83282042e-01,\n",
      "         -4.78423480e-03,   2.66400903e-01,   2.04659447e-01,\n",
      "         -2.78028488e-01],\n",
      "       [ -2.07685232e-02,  -2.02241838e-02,   1.66073829e-01,\n",
      "          1.20879561e-01,   4.00519669e-02,   1.48763806e-01,\n",
      "         -2.13661790e-01,  -8.12501758e-02,  -1.76876783e-04,\n",
      "          2.86876917e-01,  -2.56270438e-01,  -1.31530792e-01,\n",
      "         -2.15680510e-01,  -2.95152068e-02,   4.20774519e-02,\n",
      "          1.89716429e-01,  -1.68205500e-02,  -1.24609217e-01,\n",
      "          2.54237354e-02,  -2.33490005e-01,  -4.27014828e-02,\n",
      "         -3.97361368e-02,  -1.69822067e-01,   1.47417784e-01,\n",
      "         -2.85891563e-01,   2.39583492e-01,   1.36604935e-01,\n",
      "          2.71327078e-01,   1.00434810e-01,  -6.53653145e-02,\n",
      "          1.55360192e-01,  -1.06591791e-01,   2.23684311e-01,\n",
      "          7.44423270e-03,  -8.66273046e-02,  -2.44444013e-02,\n",
      "         -2.78455615e-02,  -5.51560521e-03,   2.78023422e-01,\n",
      "         -2.66369045e-01,  -1.39772639e-01,  -5.54782450e-02,\n",
      "         -6.13790005e-02,  -1.06328607e-01,  -2.73412257e-01,\n",
      "         -1.50650740e-02,  -2.31306583e-01,   2.25378513e-01,\n",
      "          1.38667017e-01,  -1.41849458e-01,  -6.35934025e-02,\n",
      "          1.77474767e-01,   5.81905246e-03,   2.54075110e-01,\n",
      "         -2.37137899e-01,   2.14334667e-01,  -8.97002220e-02,\n",
      "         -1.34769231e-01,   1.50257736e-01,   1.03051662e-02,\n",
      "          8.41620266e-02,   1.96771950e-01,  -4.69058752e-04,\n",
      "         -1.42777428e-01]], dtype=float32),\n",
      "                  array([[ 0.07207572,  0.24083029, -0.02546201, ...,  0.05222709,\n",
      "        -0.02548706, -0.10042717],\n",
      "       [ 0.06693847, -0.10299598,  0.04338918, ...,  0.06911612,\n",
      "        -0.16222733, -0.06962846],\n",
      "       [-0.1044272 , -0.08595794, -0.06701644, ..., -0.07209286,\n",
      "         0.05231621, -0.21418221],\n",
      "       ..., \n",
      "       [ 0.11658346,  0.03734214,  0.10710452, ...,  0.28376997,\n",
      "         0.00127891, -0.28365296],\n",
      "       [-0.05436084,  0.05908272,  0.15809076, ...,  0.04882063,\n",
      "        -0.03841667,  0.04517405],\n",
      "       [ 0.02631106,  0.01177813,  0.02211487, ...,  0.11825364,\n",
      "         0.00919118,  0.07802552]], dtype=float32),\n",
      "                  array([  1.57714239e-03,   1.58440205e-03,  -1.59814034e-03,\n",
      "         5.55670180e-04,  -1.58820162e-03,  -1.47417677e-03,\n",
      "         1.59741379e-03,   1.60255388e-03,  -1.07459538e-03,\n",
      "        -1.60368788e-03,   1.60053233e-03,   1.46680675e-03,\n",
      "        -1.60174537e-03,   1.55908312e-03,  -1.52222847e-03,\n",
      "        -1.58641720e-03,   9.98956859e-01,   1.00159156e+00,\n",
      "         9.98402894e-01,   1.00016284e+00,   9.98412371e-01,\n",
      "         9.98532534e-01,   1.00159752e+00,   1.00160277e+00,\n",
      "         9.98793900e-01,   9.98402655e-01,   1.00159967e+00,\n",
      "         1.00146067e+00,   9.98398662e-01,   1.00155354e+00,\n",
      "         9.98444915e-01,   9.98417616e-01,   8.62566521e-05,\n",
      "         1.60377380e-03,  -1.59806525e-03,  -1.60343572e-03,\n",
      "         1.60239672e-03,   1.60148682e-03,   1.58604677e-03,\n",
      "        -1.59970950e-03,  -1.60314923e-03,   1.60157215e-03,\n",
      "         1.60190091e-03,  -1.60345668e-03,   1.60370674e-03,\n",
      "         1.60368241e-03,   1.60241593e-03,  -1.60373934e-03,\n",
      "         1.57716940e-03,   1.58397458e-03,  -1.59716501e-03,\n",
      "         5.59322361e-04,  -1.58559938e-03,  -1.46582036e-03,\n",
      "         1.59865839e-03,   1.60291092e-03,  -1.06606376e-03,\n",
      "        -1.60284224e-03,   1.60259614e-03,   1.46883749e-03,\n",
      "        -1.59955933e-03,   1.56448002e-03,  -1.54341245e-03,\n",
      "        -1.58361637e-03], dtype=float32)]},\n",
      "  {'end_dense_2': [array([[ 0.12835574],\n",
      "       [ 0.29742771],\n",
      "       [-0.06023944],\n",
      "       [-0.00114776],\n",
      "       [ 0.5383532 ],\n",
      "       [ 0.01375803],\n",
      "       [ 0.14915562],\n",
      "       [-0.34856576],\n",
      "       [-0.5696308 ],\n",
      "       [ 0.5873791 ],\n",
      "       [ 0.26083317],\n",
      "       [-0.09573268],\n",
      "       [ 0.34703672],\n",
      "       [ 0.07958349],\n",
      "       [ 0.57010871],\n",
      "       [-0.55120587]], dtype=float32),\n",
      "                   array([ 0.00160261], dtype=float32)]}],\n",
      " [{'end_lstm_2': [array([[  8.61523226e-02,  -1.22573040e-02,   1.33778036e-01,\n",
      "          1.88144326e-01,  -5.01196925e-03,  -2.58619666e-01,\n",
      "          2.16603860e-01,  -4.80942726e-02,  -1.11344166e-01,\n",
      "         -2.01717392e-03,   1.38611317e-01,  -1.02500342e-01,\n",
      "          2.35709399e-01,  -8.54256824e-02,  -1.25327900e-01,\n",
      "          1.55187398e-01,   3.17352861e-02,  -1.72140673e-01,\n",
      "         -9.77369323e-02,   5.22126853e-02,  -1.88028097e-01,\n",
      "         -3.49634998e-02,   9.46987793e-02,   1.58268914e-01,\n",
      "          1.87694520e-01,  -2.51362562e-01,   1.67065322e-01,\n",
      "          6.79639801e-02,   2.57072687e-01,   5.15176468e-02,\n",
      "          2.01650888e-01,   2.37082183e-01,   1.57232195e-01,\n",
      "         -1.90874115e-01,  -9.41581726e-02,  -4.90722209e-02,\n",
      "          2.07592949e-01,  -2.33205020e-01,  -2.52829373e-01,\n",
      "         -2.77868509e-01,   6.58437237e-02,  -3.01940832e-02,\n",
      "          2.51417726e-01,  -1.50843650e-01,   1.26538202e-01,\n",
      "          1.29839048e-01,   8.46227258e-02,  -2.56737739e-01,\n",
      "         -1.58189774e-01,  -9.71320495e-02,   1.45473003e-01,\n",
      "         -2.43445948e-01,   1.01871058e-01,  -2.12673485e-01,\n",
      "         -1.01564340e-01,   1.38570264e-01,   1.64317921e-01,\n",
      "         -2.83774972e-01,   1.78916886e-01,   4.98220138e-02,\n",
      "          6.28199726e-02,  -2.79374063e-01,  -2.57333577e-01,\n",
      "         -1.52727187e-01],\n",
      "       [  8.28625858e-02,   1.52880594e-01,   2.34324232e-01,\n",
      "          1.09021202e-01,   2.04663217e-01,  -1.37055948e-01,\n",
      "          6.68258518e-02,  -5.82707971e-02,   2.07129434e-01,\n",
      "         -5.36843240e-02,   7.45095834e-02,  -1.39301062e-01,\n",
      "         -1.29136816e-01,  -1.25247255e-01,   9.23708230e-02,\n",
      "         -1.62918806e-01,   5.62759265e-02,   2.42199488e-02,\n",
      "          1.73897222e-01,   9.63777974e-02,   1.67631730e-01,\n",
      "          1.67337939e-01,   2.85457432e-01,  -1.09552890e-01,\n",
      "         -6.12002648e-02,   1.62107646e-01,  -5.82867414e-02,\n",
      "          3.18246186e-02,  -1.56812176e-01,   2.01843724e-01,\n",
      "          6.48699850e-02,   1.18073396e-01,   5.76200821e-02,\n",
      "          2.06263632e-01,   5.85690932e-03,   1.72423534e-02,\n",
      "          8.55419636e-02,   2.65167922e-01,  -1.61852185e-02,\n",
      "         -2.55053073e-01,   1.83004379e-01,   2.65329063e-01,\n",
      "         -1.72463819e-01,  -8.60920772e-02,  -4.95600402e-02,\n",
      "          1.32625282e-01,  -1.42248496e-01,   2.41623506e-01,\n",
      "         -1.03696547e-01,   5.16800769e-02,   1.54739231e-01,\n",
      "          2.49603912e-01,   2.31588304e-01,  -2.19737485e-01,\n",
      "          1.14128448e-01,   2.13799492e-01,  -2.37848833e-01,\n",
      "          1.49727643e-01,   2.75123775e-01,  -1.68719348e-02,\n",
      "         -1.54251471e-01,   1.53389633e-01,  -1.73725374e-02,\n",
      "          2.56566465e-01],\n",
      "       [ -2.20420688e-01,   1.64594814e-01,  -1.76067621e-01,\n",
      "          2.11829469e-02,  -1.47368610e-01,   2.19279915e-01,\n",
      "         -2.15808265e-02,  -2.46120691e-01,  -2.68606693e-01,\n",
      "          3.29873376e-02,  -8.22356269e-02,   1.29397959e-01,\n",
      "          1.76579595e-01,  -4.50695232e-02,  -2.09735557e-01,\n",
      "         -2.79354930e-01,   4.42244783e-02,   1.23716086e-01,\n",
      "         -3.40889245e-02,   1.75082773e-01,   1.10539168e-01,\n",
      "         -5.84984794e-02,   2.09488627e-02,   1.96154162e-01,\n",
      "         -5.82056530e-02,   1.56153113e-01,   2.16060117e-01,\n",
      "         -2.78358340e-01,   1.47103891e-01,  -2.54694283e-01,\n",
      "         -1.74815446e-01,  -8.06810483e-02,   1.85351387e-01,\n",
      "          1.66454643e-01,   4.72789891e-02,  -2.49408156e-01,\n",
      "         -1.48184165e-01,  -1.35990083e-01,   2.23157229e-03,\n",
      "         -1.25095740e-01,   2.72564977e-01,  -2.18403578e-01,\n",
      "         -1.54258767e-02,   2.34167546e-01,  -7.91130438e-02,\n",
      "          1.14068598e-01,  -1.06130369e-01,   1.95623636e-01,\n",
      "         -2.81042695e-01,   2.74998039e-01,   2.56888598e-01,\n",
      "         -1.20314844e-01,   2.69900769e-01,   2.65794694e-02,\n",
      "          2.74394065e-01,  -1.93183213e-01,   1.29199177e-01,\n",
      "         -2.45790124e-01,  -4.76461835e-02,   1.01604380e-01,\n",
      "          2.05341280e-01,   5.98717295e-02,   1.52438745e-01,\n",
      "          1.00526147e-01],\n",
      "       [ -3.35429143e-03,   1.57638833e-01,  -4.40293774e-02,\n",
      "         -1.51518539e-01,   1.96740881e-01,  -2.07781851e-01,\n",
      "         -1.73756197e-01,   7.72492290e-02,   9.15691853e-02,\n",
      "         -2.43374512e-01,   2.83499628e-01,  -2.48038247e-02,\n",
      "         -2.00023912e-02,  -8.85673426e-03,  -1.36192277e-01,\n",
      "         -2.06240922e-01,   2.03341722e-01,   4.53456789e-02,\n",
      "          5.70238521e-03,  -1.82357550e-01,   1.80580392e-01,\n",
      "         -1.78332373e-01,  -1.30562901e-01,  -1.20557405e-01,\n",
      "         -2.42991835e-01,   1.15226023e-01,  -3.53984460e-02,\n",
      "          2.89775342e-01,   2.09659025e-01,   2.72064894e-01,\n",
      "         -1.10481620e-01,  -8.67130905e-02,   1.56336352e-02,\n",
      "          1.30446106e-01,   7.72200823e-02,   2.35737264e-01,\n",
      "         -1.86159357e-01,  -4.01173458e-02,   1.66070178e-01,\n",
      "         -1.78685620e-01,  -1.76510796e-01,  -1.03844009e-01,\n",
      "          2.05617398e-01,  -2.36885309e-01,  -1.32824734e-01,\n",
      "          1.06730703e-02,  -2.97636800e-02,   4.35767919e-02,\n",
      "          1.41264930e-01,   6.12969622e-02,  -2.38888413e-01,\n",
      "          1.19231410e-01,  -7.23599419e-02,  -5.12771346e-02,\n",
      "         -3.11269853e-02,   1.66342348e-01,  -9.38517079e-02,\n",
      "          1.96626216e-01,   1.19402736e-01,  -4.16158289e-02,\n",
      "          1.97702706e-01,   2.13371336e-01,   6.53218701e-02,\n",
      "          7.61166960e-02],\n",
      "       [  1.44827709e-01,  -2.64510423e-01,  -1.27916500e-01,\n",
      "         -1.81101456e-01,  -1.93641096e-01,   2.31128260e-01,\n",
      "          2.67693579e-01,   2.75159121e-01,  -1.31810233e-01,\n",
      "          1.37066707e-01,  -6.56689256e-02,  -2.42629051e-02,\n",
      "          1.71563655e-01,  -1.58822536e-01,  -1.88342765e-01,\n",
      "         -2.24547952e-01,   3.97180915e-02,  -3.24206538e-02,\n",
      "          2.41702273e-01,  -1.13395594e-01,   2.33485550e-02,\n",
      "          1.93660513e-01,  -2.40684345e-01,   1.41106352e-01,\n",
      "          2.04467833e-01,  -8.88833404e-02,   2.84047574e-01,\n",
      "          1.84670575e-02,  -2.48799801e-01,   1.50293693e-01,\n",
      "         -6.15451718e-03,  -3.45566384e-02,  -2.59113848e-01,\n",
      "          2.48162597e-01,   4.41088751e-02,  -1.98008448e-01,\n",
      "          5.51659055e-02,  -1.99090764e-01,   5.02066761e-02,\n",
      "          1.39070705e-01,   2.17179045e-01,  -1.67200372e-01,\n",
      "          2.72499084e-01,   1.24743134e-01,  -2.55876184e-01,\n",
      "          2.46980856e-03,   1.64380312e-01,   1.91252455e-01,\n",
      "         -2.67650038e-01,  -4.94084768e-02,  -1.83374181e-01,\n",
      "         -9.55228955e-02,  -2.35341161e-01,   2.74657388e-03,\n",
      "         -1.69303194e-01,  -8.35048109e-02,   3.64752896e-02,\n",
      "         -1.09947780e-02,   2.45381758e-01,   4.84499261e-02,\n",
      "         -1.83373392e-01,   4.48762551e-02,   1.03367992e-01,\n",
      "         -1.71657428e-01],\n",
      "       [ -1.37075976e-01,   6.89738169e-02,   8.44062194e-02,\n",
      "         -1.48004889e-01,  -2.07847044e-01,  -2.81867892e-01,\n",
      "          1.50640145e-01,   2.10579872e-01,   1.71657249e-01,\n",
      "          2.52531767e-01,   4.11575772e-02,   4.64565074e-03,\n",
      "          2.13857576e-01,   1.98600199e-02,  -2.93967854e-02,\n",
      "         -4.40421561e-03,  -9.91226360e-02,   9.03607011e-02,\n",
      "         -1.58335999e-01,   2.15955824e-01,   1.31384522e-01,\n",
      "         -2.98863519e-02,  -2.25997984e-01,  -3.85604948e-02,\n",
      "          7.58858696e-02,  -7.42975399e-02,  -9.06507000e-02,\n",
      "         -2.35241950e-01,  -2.84181595e-01,   1.37173012e-01,\n",
      "         -1.61251247e-01,   9.63543579e-02,   1.02903955e-01,\n",
      "         -1.06893398e-01,   2.36485824e-01,  -1.26155496e-01,\n",
      "         -1.57631934e-01,   1.49548158e-01,  -3.75450514e-02,\n",
      "         -1.00997359e-01,   1.54701382e-01,  -1.45678461e-01,\n",
      "         -3.89015600e-02,   1.94316953e-01,   1.34951055e-01,\n",
      "         -4.86458912e-02,   1.60861090e-02,  -1.41942427e-01,\n",
      "          2.74405450e-01,   1.18171036e-01,   1.78354740e-01,\n",
      "         -2.85314679e-01,  -5.77180348e-02,  -1.90614581e-01,\n",
      "         -2.24576220e-01,  -2.36871898e-01,   1.36377379e-01,\n",
      "         -2.78019667e-01,  -7.48998299e-02,  -5.80790965e-03,\n",
      "          2.63496768e-02,   4.64746952e-02,  -3.85876372e-02,\n",
      "         -4.95547503e-02],\n",
      "       [ -9.76593420e-02,  -2.66052067e-01,   2.02751920e-01,\n",
      "         -2.80122042e-01,   1.78408459e-01,   2.21210957e-01,\n",
      "         -1.90972537e-01,   6.12140819e-02,  -2.08359376e-01,\n",
      "         -7.54866423e-03,  -1.56272948e-01,  -9.38540027e-02,\n",
      "         -2.17486173e-01,  -1.97302803e-01,  -7.62668476e-02,\n",
      "         -1.35274783e-01,  -1.65230781e-02,   1.55221839e-02,\n",
      "         -8.95439014e-02,   1.30579114e-01,  -2.74605602e-01,\n",
      "          1.62369329e-02,   2.65912265e-01,   2.43362412e-01,\n",
      "         -1.67079613e-01,   2.51129448e-01,  -2.17170924e-01,\n",
      "          2.28343382e-01,   2.05027297e-01,  -8.77116323e-02,\n",
      "         -2.88882107e-02,   1.29255816e-01,  -4.12924727e-03,\n",
      "         -1.55416176e-01,   4.83210050e-02,   2.83812791e-01,\n",
      "         -4.12738547e-02,   2.68302262e-01,  -7.61643872e-02,\n",
      "          2.04435796e-01,  -5.92826381e-02,  -5.90913370e-02,\n",
      "         -4.10232842e-02,   1.50641233e-01,   2.26003483e-01,\n",
      "          1.62769690e-01,  -1.36118233e-01,   3.14354710e-02,\n",
      "          7.14873970e-02,  -1.07627302e-01,  -1.54713467e-01,\n",
      "         -9.96041205e-03,   1.28478840e-01,   1.09728001e-01,\n",
      "          3.96984331e-02,   2.12535679e-01,  -1.92724437e-01,\n",
      "         -1.02413625e-01,   1.44312948e-01,   2.82811224e-01,\n",
      "         -5.25536481e-03,   2.66871840e-01,   2.04188317e-01,\n",
      "         -2.78499663e-01],\n",
      "       [ -2.07685232e-02,  -2.02241838e-02,   1.66073829e-01,\n",
      "          1.20879561e-01,   4.00519669e-02,   1.48763806e-01,\n",
      "         -2.13661790e-01,  -8.12501758e-02,  -1.76876783e-04,\n",
      "          2.86876917e-01,  -2.56270438e-01,  -1.31530792e-01,\n",
      "         -2.15680510e-01,  -2.95152068e-02,   4.20774519e-02,\n",
      "          1.89716429e-01,  -1.68205500e-02,  -1.24609217e-01,\n",
      "          2.54237354e-02,  -2.33490005e-01,  -4.27014828e-02,\n",
      "         -3.97361368e-02,  -1.69822067e-01,   1.47417784e-01,\n",
      "         -2.85891563e-01,   2.39583492e-01,   1.36604935e-01,\n",
      "          2.71327078e-01,   1.00434810e-01,  -6.53653145e-02,\n",
      "          1.55360192e-01,  -1.06591791e-01,   2.23684311e-01,\n",
      "          7.44423270e-03,  -8.66273046e-02,  -2.44444013e-02,\n",
      "         -2.78455615e-02,  -5.51560521e-03,   2.78023422e-01,\n",
      "         -2.66369045e-01,  -1.39772639e-01,  -5.54782450e-02,\n",
      "         -6.13790005e-02,  -1.06328607e-01,  -2.73412257e-01,\n",
      "         -1.50650740e-02,  -2.31306583e-01,   2.25378513e-01,\n",
      "          1.38667017e-01,  -1.41849458e-01,  -6.35934025e-02,\n",
      "          1.77474767e-01,   5.81905246e-03,   2.54075110e-01,\n",
      "         -2.37137899e-01,   2.14334667e-01,  -8.97002220e-02,\n",
      "         -1.34769231e-01,   1.50257736e-01,   1.03051662e-02,\n",
      "          8.41620266e-02,   1.96771950e-01,  -4.69058752e-04,\n",
      "         -1.42777428e-01]], dtype=float32),\n",
      "                  array([[ 0.07293838,  0.24005057, -0.02503732, ...,  0.05154717,\n",
      "        -0.02603755, -0.09974248],\n",
      "       [ 0.06682525, -0.10211234,  0.04250245, ...,  0.06998238,\n",
      "        -0.16231562, -0.0705094 ],\n",
      "       [-0.10413297, -0.08507072, -0.06788533, ..., -0.07122792,\n",
      "         0.05175311, -0.21506199],\n",
      "       ..., \n",
      "       [ 0.11629958,  0.03819153,  0.10625728, ...,  0.28458196,\n",
      "         0.00087209, -0.28448945],\n",
      "       [-0.05517356,  0.05897988,  0.15869194, ...,  0.04850961,\n",
      "        -0.03756379,  0.04550446],\n",
      "       [ 0.02630842,  0.01265305,  0.0212376 , ...,  0.11910998,\n",
      "         0.00884006,  0.07715315]], dtype=float32),\n",
      "                  array([  2.45855562e-03,   2.48517981e-03,  -2.48372159e-03,\n",
      "         6.47660054e-04,  -2.44500628e-03,  -2.29427312e-03,\n",
      "         2.50327075e-03,   2.51477445e-03,  -1.54242397e-03,\n",
      "        -2.48309830e-03,   2.51142448e-03,   2.29655160e-03,\n",
      "        -2.51274952e-03,   2.44266680e-03,  -2.00705719e-03,\n",
      "        -2.48617306e-03,   9.98494029e-01,   1.00249660e+00,\n",
      "         9.97516692e-01,   9.99651849e-01,   9.97544348e-01,\n",
      "         9.97726798e-01,   1.00250483e+00,   1.00251508e+00,\n",
      "         9.98204529e-01,   9.97512043e-01,   1.00250995e+00,\n",
      "         1.00228679e+00,   9.97487485e-01,   1.00243175e+00,\n",
      "         9.97896194e-01,   9.97520983e-01,  -6.85642706e-04,\n",
      "         2.51428387e-03,  -2.49522738e-03,  -2.51432694e-03,\n",
      "         2.51152273e-03,   2.50547891e-03,   2.48619891e-03,\n",
      "        -2.50675622e-03,  -2.51377211e-03,   2.50981259e-03,\n",
      "         2.51148595e-03,  -2.51396117e-03,   2.51181517e-03,\n",
      "         2.51653907e-03,   2.51121307e-03,  -2.51369108e-03,\n",
      "         2.46308022e-03,   2.48450716e-03,  -2.48047989e-03,\n",
      "         6.44450367e-04,  -2.43869424e-03,  -2.27868883e-03,\n",
      "         2.50561279e-03,   2.51535745e-03,  -1.52130146e-03,\n",
      "        -2.48177303e-03,   2.51475326e-03,   2.29977723e-03,\n",
      "        -2.50967033e-03,   2.45214486e-03,  -2.07226328e-03,\n",
      "        -2.48092646e-03], dtype=float32)]},\n",
      "  {'end_dense_2': [array([[ 0.12789519],\n",
      "       [ 0.29832932],\n",
      "       [-0.05934092],\n",
      "       [-0.00135468],\n",
      "       [ 0.53749615],\n",
      "       [ 0.01294917],\n",
      "       [ 0.15005665],\n",
      "       [-0.34947833],\n",
      "       [-0.56913853],\n",
      "       [ 0.58649164],\n",
      "       [ 0.2617442 ],\n",
      "       [-0.09655651],\n",
      "       [ 0.34612596],\n",
      "       [ 0.08045787],\n",
      "       [ 0.56959099],\n",
      "       [-0.5503065 ]], dtype=float32),\n",
      "                   array([ 0.00251231], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.losses[:3])\n",
    "pprint(history.weights[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_built': True,\n",
       " '_initial_weights': None,\n",
       " '_losses': [],\n",
       " '_non_trainable_weights': [],\n",
       " '_num_constants': None,\n",
       " '_per_input_losses': {},\n",
       " '_per_input_updates': {},\n",
       " '_states': None,\n",
       " '_trainable_weights': [],\n",
       " '_updates': [],\n",
       " 'activity_regularizer': None,\n",
       " 'batch_input_shape': (None, 5, 8),\n",
       " 'cell': <keras.layers.recurrent.LSTMCell at 0x7f28a5494fd0>,\n",
       " 'constants_spec': None,\n",
       " 'dtype': 'float32',\n",
       " 'go_backwards': False,\n",
       " 'inbound_nodes': [<keras.engine.topology.Node at 0x7f28a5c51ef0>],\n",
       " 'input_spec': [<keras.engine.topology.InputSpec at 0x7f28a5494668>],\n",
       " 'name': 'lstm_2',\n",
       " 'outbound_nodes': [<keras.engine.topology.Node at 0x7f28a3183da0>],\n",
       " 'return_sequences': False,\n",
       " 'return_state': False,\n",
       " 'state_spec': [<keras.engine.topology.InputSpec at 0x7f28a314a4e0>,\n",
       "  <keras.engine.topology.InputSpec at 0x7f28a30cd0b8>],\n",
       " 'stateful': False,\n",
       " 'supports_masking': True,\n",
       " 'trainable': True,\n",
       " 'unroll': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.033779236167071403,\n",
      "          0.020337651275758196,\n",
      "          0.018585273281743565,\n",
      "          0.016788585761495455,\n",
      "          0.015512988904299365,\n",
      "          0.014880644734459743,\n",
      "          0.014457475617916835,\n",
      "          0.014052360878670669,\n",
      "          0.013862090543473919,\n",
      "          0.01367403797761561,\n",
      "          0.013674114581517714,\n",
      "          0.01360940321510689,\n",
      "          0.013572111293488801,\n",
      "          0.013568208657862544,\n",
      "          0.013552160903840621,\n",
      "          0.013526221296136773,\n",
      "          0.013509968294478166,\n",
      "          0.013588693705050947,\n",
      "          0.013552341040553773,\n",
      "          0.013526971474571828,\n",
      "          0.013551200544539078,\n",
      "          0.013481090156398829,\n",
      "          0.01345430823418799,\n",
      "          0.013449736921105468,\n",
      "          0.013432743517544331,\n",
      "          0.013411532365644839,\n",
      "          0.013373456222721111,\n",
      "          0.013333336712801326,\n",
      "          0.013353437148222933,\n",
      "          0.013318323605752967,\n",
      "          0.013354707857139094,\n",
      "          0.013316238623478832,\n",
      "          0.013256517218711752,\n",
      "          0.013311490914467653,\n",
      "          0.013270131578598165,\n",
      "          0.013264996175083225,\n",
      "          0.013245240212048252,\n",
      "          0.01325705403176777,\n",
      "          0.013256880135872862,\n",
      "          0.013201801770457416,\n",
      "          0.013219437745277186,\n",
      "          0.013210220465655623,\n",
      "          0.01320624580299061,\n",
      "          0.013182922398124351,\n",
      "          0.013186973495774374,\n",
      "          0.013167517062545776,\n",
      "          0.013152714382751967,\n",
      "          0.013170583431261571,\n",
      "          0.013115455704686342,\n",
      "          0.013108585857412706,\n",
      "          0.013125236242610971,\n",
      "          0.013128643207126856,\n",
      "          0.013103809119877409,\n",
      "          0.01311479935362082,\n",
      "          0.013099753316853374,\n",
      "          0.013106991862445277,\n",
      "          0.013071429628475982,\n",
      "          0.013067691784842409,\n",
      "          0.013067493662408253,\n",
      "          0.01305618645664948,\n",
      "          0.01307010872718211,\n",
      "          0.013051316775217509,\n",
      "          0.013046079893543151,\n",
      "          0.013031471517320422,\n",
      "          0.013059965506635936,\n",
      "          0.013015573840667928,\n",
      "          0.013003949374884071,\n",
      "          0.013020977699927726,\n",
      "          0.013013504898226332,\n",
      "          0.01296805203218597,\n",
      "          0.013014342852484886,\n",
      "          0.013009872593446202,\n",
      "          0.012992268492006066,\n",
      "          0.012991394563875042,\n",
      "          0.012984200940812088,\n",
      "          0.012962929389810625,\n",
      "          0.012961443865744972,\n",
      "          0.012958280830576473,\n",
      "          0.012941999968838252,\n",
      "          0.012945179623504425,\n",
      "          0.012941994649772639,\n",
      "          0.012962321740945932,\n",
      "          0.012936220774884287,\n",
      "          0.012924629615541092,\n",
      "          0.012928437311253935,\n",
      "          0.012926792936155621,\n",
      "          0.012923516223124784,\n",
      "          0.012927402756334109,\n",
      "          0.012895648812325564,\n",
      "          0.012918025049525418,\n",
      "          0.012907109652434587,\n",
      "          0.012896289787074614,\n",
      "          0.012901916907642409,\n",
      "          0.012886912011605378,\n",
      "          0.012885343668339226,\n",
      "          0.012889151956477128,\n",
      "          0.012877042440700892,\n",
      "          0.012874650945599871,\n",
      "          0.012868275812138471,\n",
      "          0.012866385030140788,\n",
      "          0.012865570144002638,\n",
      "          0.012868222769436702,\n",
      "          0.012855073214707436,\n",
      "          0.012865608521298004,\n",
      "          0.012869840972107301,\n",
      "          0.012862851390260562,\n",
      "          0.012841910748453752,\n",
      "          0.012856465159310658,\n",
      "          0.012846784852110937,\n",
      "          0.012854098418159094,\n",
      "          0.012856583151242664,\n",
      "          0.012842168679995282,\n",
      "          0.012827777696730573,\n",
      "          0.012840230845776512,\n",
      "          0.012825565948861202,\n",
      "          0.012822635641953156,\n",
      "          0.012825796943898595,\n",
      "          0.012827225767721303,\n",
      "          0.012846049604002617,\n",
      "          0.012817260858915288,\n",
      "          0.012814237179437872,\n",
      "          0.012817125133422688,\n",
      "          0.012803351235290547,\n",
      "          0.012795291070877544,\n",
      "          0.012802924022085806,\n",
      "          0.012795936051331421,\n",
      "          0.012786219075754774,\n",
      "          0.012800012574649775,\n",
      "          0.012805947841010967,\n",
      "          0.0127740171131113,\n",
      "          0.012770081619768387,\n",
      "          0.012782967127914277,\n",
      "          0.012778936428826194,\n",
      "          0.01275944253215586,\n",
      "          0.012762998500992299,\n",
      "          0.01276435852634092,\n",
      "          0.012753050141808182,\n",
      "          0.012772551766739372,\n",
      "          0.012748623752604687,\n",
      "          0.012757865458974791,\n",
      "          0.012762552647057102,\n",
      "          0.012753172686298915,\n",
      "          0.012744777914743656,\n",
      "          0.012760342437366233,\n",
      "          0.012753987216678224,\n",
      "          0.012746606223544043,\n",
      "          0.01275488170469309,\n",
      "          0.012739124777297701,\n",
      "          0.012746536208320025,\n",
      "          0.012738506255458413,\n",
      "          0.012734335331789162,\n",
      "          0.012746148302973707,\n",
      "          0.012745116330723333,\n",
      "          0.012738872734461264,\n",
      "          0.012752325221643403,\n",
      "          0.012734274150989919,\n",
      "          0.012760746831572906,\n",
      "          0.012740858767471467,\n",
      "          0.012746021687155679,\n",
      "          0.012724113441144559,\n",
      "          0.012726566277759107,\n",
      "          0.012739496016967571,\n",
      "          0.012729682778394877,\n",
      "          0.012716221161486857,\n",
      "          0.01272179070775689,\n",
      "          0.012742761100238774,\n",
      "          0.012751505452707529,\n",
      "          0.012724985582278556,\n",
      "          0.01272740787041895,\n",
      "          0.012734268358591875,\n",
      "          0.012719209137784484,\n",
      "          0.012706258495997068,\n",
      "          0.012708656742009501,\n",
      "          0.01271904018727169,\n",
      "          0.012730985282004472,\n",
      "          0.012742625068204182,\n",
      "          0.01273726921664076,\n",
      "          0.012725233248157129,\n",
      "          0.0127298171279423,\n",
      "          0.012709839333622281,\n",
      "          0.012710590635538296,\n",
      "          0.012712179651097145,\n",
      "          0.012715608992267055,\n",
      "          0.012727621032550622,\n",
      "          0.012706719781541743,\n",
      "          0.012720844313281139,\n",
      "          0.012707974415383667,\n",
      "          0.012714246397312712,\n",
      "          0.012704276949011701,\n",
      "          0.01271477133452484,\n",
      "          0.012705991583595441,\n",
      "          0.0127032050628065,\n",
      "          0.012707055748527367,\n",
      "          0.012706181907285351,\n",
      "          0.012709986266277973,\n",
      "          0.012703587065168762,\n",
      "          0.012698704843161605,\n",
      "          0.012711358374363543,\n",
      "          0.01270678678937311,\n",
      "          0.01270796980145578,\n",
      "          0.012696938215227972,\n",
      "          0.012695285016034346,\n",
      "          0.012694281412437716,\n",
      "          0.012699690622055322,\n",
      "          0.012683947966331526,\n",
      "          0.012679846117601389,\n",
      "          0.012694163633778732,\n",
      "          0.01269580361217168,\n",
      "          0.012689475057295127,\n",
      "          0.012685167641322583,\n",
      "          0.012685934046128118,\n",
      "          0.012692068329637211,\n",
      "          0.012687950409174724,\n",
      "          0.012693082432828745,\n",
      "          0.012686744952688908,\n",
      "          0.012690481623928478,\n",
      "          0.012679359120201508,\n",
      "          0.012669793457276493,\n",
      "          0.01265985967114123,\n",
      "          0.012668235824143998,\n",
      "          0.012679578372158986,\n",
      "          0.012696662156391038,\n",
      "          0.012689310616200364,\n",
      "          0.012680406748575266,\n",
      "          0.012677366367875897,\n",
      "          0.012692549549221818,\n",
      "          0.012670823504904942,\n",
      "          0.012667709964571623,\n",
      "          0.012672207085377744,\n",
      "          0.012662430365100962,\n",
      "          0.012663878380457528,\n",
      "          0.012657928932048023,\n",
      "          0.012672048803984565,\n",
      "          0.012654900519853898,\n",
      "          0.012652752030220978,\n",
      "          0.012660909670430457,\n",
      "          0.012647051707486152,\n",
      "          0.012656928280551035,\n",
      "          0.012672116906435158,\n",
      "          0.012659604087121976,\n",
      "          0.012660079509143805,\n",
      "          0.012652863203188642,\n",
      "          0.012638656557690279,\n",
      "          0.012641971994964902,\n",
      "          0.012653385658291673,\n",
      "          0.012657124575277932,\n",
      "          0.012655364678812016,\n",
      "          0.012642211130834038,\n",
      "          0.012630704870862822,\n",
      "          0.012632418138159905,\n",
      "          0.012632796632302486,\n",
      "          0.012637836538113033,\n",
      "          0.012639822811131336,\n",
      "          0.012623999439771714,\n",
      "          0.012629589237256942,\n",
      "          0.012639481303300462,\n",
      "          0.012630432298827125,\n",
      "          0.012603272621182181,\n",
      "          0.012599293037135865,\n",
      "          0.012626751897031148,\n",
      "          0.01261902378747172,\n",
      "          0.012589404196011322,\n",
      "          0.012606898288674988,\n",
      "          0.012652748605700325,\n",
      "          0.012583738799316131,\n",
      "          0.012621335449498351,\n",
      "          0.012596149277655963,\n",
      "          0.012595277938574354,\n",
      "          0.01262174805198208,\n",
      "          0.012609421299404993,\n",
      "          0.012604882166244101,\n",
      "          0.012593136095950605,\n",
      "          0.012606431718546878,\n",
      "          0.012587157353489031,\n",
      "          0.012604426906573707,\n",
      "          0.012615105771579491,\n",
      "          0.012596250071944197,\n",
      "          0.012586270901340341,\n",
      "          0.012590022359357496,\n",
      "          0.012615728147219745,\n",
      "          0.012572593380587853,\n",
      "          0.0126206175287597,\n",
      "          0.012583672418392,\n",
      "          0.012613476205284824,\n",
      "          0.012614493138445296,\n",
      "          0.01257205949563067,\n",
      "          0.012599401758071397,\n",
      "          0.012585349335398843,\n",
      "          0.012599894910008128,\n",
      "          0.012574977531137172,\n",
      "          0.0125866577264983,\n",
      "          0.012590081645004162,\n",
      "          0.012609215129711873,\n",
      "          0.012567816055184611,\n",
      "          0.012566572897375611,\n",
      "          0.012574009968858327,\n",
      "          0.012563987985822062,\n",
      "          0.012573999446629749,\n",
      "          0.012560126385808749,\n",
      "          0.012575677770873964],\n",
      " 'val_loss': [0.02572060943825993,\n",
      "              0.022566854083802445,\n",
      "              0.020783766310732504,\n",
      "              0.021324937148608961,\n",
      "              0.018964749625449622,\n",
      "              0.018010246100248033,\n",
      "              0.016641537202625435,\n",
      "              0.016230914242376087,\n",
      "              0.016046303581380799,\n",
      "              0.01575470103627704,\n",
      "              0.015504120243379126,\n",
      "              0.015337001309965221,\n",
      "              0.01526110997546248,\n",
      "              0.015231958743542025,\n",
      "              0.015183509964755914,\n",
      "              0.015052917692263532,\n",
      "              0.015046511986945978,\n",
      "              0.014923918464349246,\n",
      "              0.015201188485998969,\n",
      "              0.015159289365961165,\n",
      "              0.015007699166035154,\n",
      "              0.014926520869408023,\n",
      "              0.01486848548312282,\n",
      "              0.014856447765830873,\n",
      "              0.014830381769883773,\n",
      "              0.014805024029870517,\n",
      "              0.014752526940694061,\n",
      "              0.014759588453235847,\n",
      "              0.01471334351840279,\n",
      "              0.014736413529819511,\n",
      "              0.014761588185058454,\n",
      "              0.014772695570027448,\n",
      "              0.01478809345724998,\n",
      "              0.014812411423906227,\n",
      "              0.014757557718638532,\n",
      "              0.014742153661479884,\n",
      "              0.014724609957836612,\n",
      "              0.014714913230707696,\n",
      "              0.014783753802670579,\n",
      "              0.014722372770955845,\n",
      "              0.014670061516780249,\n",
      "              0.01471491131581614,\n",
      "              0.014680304421769274,\n",
      "              0.014740690703164186,\n",
      "              0.014680349630706465,\n",
      "              0.014693044773646219,\n",
      "              0.014729460861123199,\n",
      "              0.014671476792352152,\n",
      "              0.014676035868474182,\n",
      "              0.014684187420883834,\n",
      "              0.01472534004973086,\n",
      "              0.014727506274448566,\n",
      "              0.014728260722888581,\n",
      "              0.014768537153372637,\n",
      "              0.01473019203804166,\n",
      "              0.014769117634036303,\n",
      "              0.014790587952823439,\n",
      "              0.014770683021432267,\n",
      "              0.014804152520926303,\n",
      "              0.014816900879261312,\n",
      "              0.01479855344545118,\n",
      "              0.014827080193690747,\n",
      "              0.014860636575313968,\n",
      "              0.014866695875412525,\n",
      "              0.015103112517407107,\n",
      "              0.014886555987284491,\n",
      "              0.014899415748931385,\n",
      "              0.014933355263782457,\n",
      "              0.014968045363269518,\n",
      "              0.014969383699932443,\n",
      "              0.014975923083149096,\n",
      "              0.015009127020840736,\n",
      "              0.015000489184393536,\n",
      "              0.015019946216453117,\n",
      "              0.015009294794380314,\n",
      "              0.015035689061183169,\n",
      "              0.015086499677056086,\n",
      "              0.015236261078999155,\n",
      "              0.015106042102829778,\n",
      "              0.015112650858946704,\n",
      "              0.015118125994402407,\n",
      "              0.015145944727892123,\n",
      "              0.015125861469187226,\n",
      "              0.015214849186882581,\n",
      "              0.015227858746267578,\n",
      "              0.015269321630072804,\n",
      "              0.015196771308079858,\n",
      "              0.01525276753533843,\n",
      "              0.015270350922557628,\n",
      "              0.015349489363944382,\n",
      "              0.015306623590610732,\n",
      "              0.01527511380158428,\n",
      "              0.015273430049346502,\n",
      "              0.015364524215795173,\n",
      "              0.015332576429346226,\n",
      "              0.015269188770498238,\n",
      "              0.015300810214348346,\n",
      "              0.015308636451469321,\n",
      "              0.015312154486347707,\n",
      "              0.015339484279130847,\n",
      "              0.015363788940571371,\n",
      "              0.015388058645520735,\n",
      "              0.015320211695112284,\n",
      "              0.015341931824017722,\n",
      "              0.015434962097708492,\n",
      "              0.015334877718315355,\n",
      "              0.015386949983453992,\n",
      "              0.015374178808019664,\n",
      "              0.015424818256159118,\n",
      "              0.01546128558824829,\n",
      "              0.015423748567481681,\n",
      "              0.015334433058868493,\n",
      "              0.01535229438482082,\n",
      "              0.015409121695670207,\n",
      "              0.015449841031093887,\n",
      "              0.015397431927296319,\n",
      "              0.015363127657802216,\n",
      "              0.015433217898808268,\n",
      "              0.015508685522243156,\n",
      "              0.015336404169380509,\n",
      "              0.015388419563090458,\n",
      "              0.015442248624588489,\n",
      "              0.015431235984832885,\n",
      "              0.015428401761860219,\n",
      "              0.015409961133825957,\n",
      "              0.015322800611485396,\n",
      "              0.015401519952853443,\n",
      "              0.015406561240223366,\n",
      "              0.015499640655304705,\n",
      "              0.01535421272403204,\n",
      "              0.015355198076681342,\n",
      "              0.015366143834353738,\n",
      "              0.015449179488915247,\n",
      "              0.015322487260623843,\n",
      "              0.015397518704932691,\n",
      "              0.01544422269249013,\n",
      "              0.015347975493327939,\n",
      "              0.015452038298682379,\n",
      "              0.015373801019113202,\n",
      "              0.015406310863292303,\n",
      "              0.015422010911532617,\n",
      "              0.015492104043101494,\n",
      "              0.01547174363907983,\n",
      "              0.015479455941975778,\n",
      "              0.015488601057010776,\n",
      "              0.015459341222428841,\n",
      "              0.01542121838092979,\n",
      "              0.015475541720165588,\n",
      "              0.015505031464452534,\n",
      "              0.015485321198312465,\n",
      "              0.015542417516797023,\n",
      "              0.015591131149021458,\n",
      "              0.015579413365030787,\n",
      "              0.015569257938144492,\n",
      "              0.01574485664561498,\n",
      "              0.015636464069364746,\n",
      "              0.015598434395359104,\n",
      "              0.015599758660120663,\n",
      "              0.015605889687245373,\n",
      "              0.01555552130439899,\n",
      "              0.01571800759328263,\n",
      "              0.015608942668960325,\n",
      "              0.015532737892468576,\n",
      "              0.015535193313197497,\n",
      "              0.015625615808954833,\n",
      "              0.01565615093701234,\n",
      "              0.015593387972045901,\n",
      "              0.015631039055831006,\n",
      "              0.015604517685671063,\n",
      "              0.01566223846292834,\n",
      "              0.01565092716752433,\n",
      "              0.015590153274898504,\n",
      "              0.015656174984332284,\n",
      "              0.015805260765512669,\n",
      "              0.015668343919082086,\n",
      "              0.015678357603897165,\n",
      "              0.015787204367880798,\n",
      "              0.015524056291150565,\n",
      "              0.015574023072271858,\n",
      "              0.015607968957539447,\n",
      "              0.015630047316969764,\n",
      "              0.015594901677417896,\n",
      "              0.015710371417046294,\n",
      "              0.015746518751437455,\n",
      "              0.01563758060119837,\n",
      "              0.015845165026009043,\n",
      "              0.01566006676631081,\n",
      "              0.015589010742579849,\n",
      "              0.015717828170009399,\n",
      "              0.015638569979251053,\n",
      "              0.015600793895938003,\n",
      "              0.015713811183769914,\n",
      "              0.015679663561760836,\n",
      "              0.01575705452183649,\n",
      "              0.015640762245157383,\n",
      "              0.015772958551591235,\n",
      "              0.015586521408465354,\n",
      "              0.01576359734420324,\n",
      "              0.015664585575641213,\n",
      "              0.015656950167913065,\n",
      "              0.015644337135061515,\n",
      "              0.015665883802251729,\n",
      "              0.015735933367607646,\n",
      "              0.015640294312973934,\n",
      "              0.015671820267403117,\n",
      "              0.015690349606190798,\n",
      "              0.015697315061891381,\n",
      "              0.015715947523543009,\n",
      "              0.015781639392298766,\n",
      "              0.015740089679825795,\n",
      "              0.015773855301017513,\n",
      "              0.015748211273781357,\n",
      "              0.015781297615139373,\n",
      "              0.015762681044293087,\n",
      "              0.015745036791832673,\n",
      "              0.015754085125866974,\n",
      "              0.015843561215026076,\n",
      "              0.015716923449361004,\n",
      "              0.015713509919446277,\n",
      "              0.015739846596128593,\n",
      "              0.015797091873371166,\n",
      "              0.015738954483874662,\n",
      "              0.015786311223456577,\n",
      "              0.015743245453915797,\n",
      "              0.015899123269177619,\n",
      "              0.015699316893898033,\n",
      "              0.015759500177347497,\n",
      "              0.015860128608901014,\n",
      "              0.015728845288375586,\n",
      "              0.015805169264436623,\n",
      "              0.015789141457476844,\n",
      "              0.016008186214819153,\n",
      "              0.015875412208323999,\n",
      "              0.01586625551645731,\n",
      "              0.015631561920858447,\n",
      "              0.015859037277453372,\n",
      "              0.015649186579093814,\n",
      "              0.015736904187858183,\n",
      "              0.015762841578667763,\n",
      "              0.015748601872777712,\n",
      "              0.015704740910497429,\n",
      "              0.015906488616444749,\n",
      "              0.015669758495402662,\n",
      "              0.015794861147426852,\n",
      "              0.015729293606285947,\n",
      "              0.015719374660609093,\n",
      "              0.015623631576697031,\n",
      "              0.0156914889162427,\n",
      "              0.015681438120683462,\n",
      "              0.0156177940638098,\n",
      "              0.015658446184231303,\n",
      "              0.015580450271518108,\n",
      "              0.015624022514079999,\n",
      "              0.015645634882949143,\n",
      "              0.015701149883743836,\n",
      "              0.015528705381148599,\n",
      "              0.015715071915685937,\n",
      "              0.015485104418858468,\n",
      "              0.015639973446527535,\n",
      "              0.015599992764726116,\n",
      "              0.01555930762761318,\n",
      "              0.015597092298777447,\n",
      "              0.015711761261375995,\n",
      "              0.015647571374141578,\n",
      "              0.015528380973489356,\n",
      "              0.015619183120190786,\n",
      "              0.015694488031912378,\n",
      "              0.015487208950290163,\n",
      "              0.015515094386645764,\n",
      "              0.015544931683142591,\n",
      "              0.015552541943946192,\n",
      "              0.015513345212794096,\n",
      "              0.015736483945101208,\n",
      "              0.015563866774814625,\n",
      "              0.015490575929264071,\n",
      "              0.015668651630976818,\n",
      "              0.015515862567993021,\n",
      "              0.015651945543547742,\n",
      "              0.015531104659468461,\n",
      "              0.015541153353021102,\n",
      "              0.015593412914844952,\n",
      "              0.015562661139772014,\n",
      "              0.015544516398326602,\n",
      "              0.015602422839872641,\n",
      "              0.01559467396266948,\n",
      "              0.015709574528121124,\n",
      "              0.015753555745834123,\n",
      "              0.015762119389953796,\n",
      "              0.01578960423974414,\n",
      "              0.015836164852226393,\n",
      "              0.01574498816014833,\n",
      "              0.015859960128212395,\n",
      "              0.015646422632398242,\n",
      "              0.015740081144220985,\n",
      "              0.015716633771589317,\n",
      "              0.015664837640252716,\n",
      "              0.01570143701541447,\n",
      "              0.015677609346656338,\n",
      "              0.015833265931191821,\n",
      "              0.015784357831766616]}\n",
      "{'batch_size': 64,\n",
      " 'do_validation': True,\n",
      " 'epochs': 300,\n",
      " 'metrics': ['loss', 'val_loss'],\n",
      " 'samples': 24524,\n",
      " 'steps': None,\n",
      " 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint(fitted.history)\n",
    "pprint(fitted.params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# apt-get install -y graphviz libgraphviz-dev\n",
    "keras.utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADFCAYAAABAWxtPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIuf/ALBBs2OLaSmWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f284dda1780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 3))\n",
    "ax.plot(fitted.history['loss'], label='train')\n",
    "if 'val_loss' in fitted.history.keys():\n",
    "    ax.plot(fitted.history['val_loss'], label='validation')\n",
    "ax.legend()\n",
    "ax.set_xticks(np.arange(EPOCH_NUM))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 27.554 RMSE\n"
     ]
    }
   ],
   "source": [
    "train_Y_real = scalerY.inverse_transform(train_Y)\n",
    "train_Y_hat = scalerY.inverse_transform(fitted.model.predict(train_X))\n",
    "\n",
    "train_score = np.sqrt(mean_squared_error(train_Y_real, train_Y_hat))\n",
    "print('Training Score: %.3f RMSE' % train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 23.322 RMSE\n",
      "Real\t:\n",
      " 12.0,\n",
      "Predict\t:\n",
      " 9.59765\n"
     ]
    }
   ],
   "source": [
    "test_Y_real = scalerY.inverse_transform(test_Y)\n",
    "test_Y_hat = scalerY.inverse_transform(fitted.model.predict(test_X))\n",
    "\n",
    "test_score = np.sqrt(mean_squared_error(test_Y_real, test_Y_hat))\n",
    "print('Test Score: %.3f RMSE' % test_score)\n",
    "print('Real\\t:\\n %s,\\nPredict\\t:\\n %s' % (test_Y_real[-1][0], test_Y_hat[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "gist": {
   "data": {
    "description": "tensorflow/konlpy.ipynb",
    "public": false
   },
   "id": "5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "kernelspec": {
   "display_name": "Tensorflow: Python3.6 (conda env)",
   "language": "python",
   "name": "tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "906px",
    "left": "0px",
    "right": "1789px",
    "top": "135px",
    "width": "259px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": 16,
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
