{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_code_flow_test.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "u2IfD-Gvxvhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da60db0f-ed7c-4706-8bde-6ec91d738702"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import datetime as dt\n",
        "import itertools as it\n",
        "from glob import glob\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import (regularizers, constraints,\n",
        "                   initializers, activations)\n",
        "from keras.layers.recurrent import Recurrent\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import (SimpleRNN, RNN, LSTM, GRU,\n",
        "                          Input, Dense, Activation, Lambda,\n",
        "                          Reshape, Flatten, Permute,\n",
        "                          Embedding, RepeatVector,\n",
        "                          TimeDistributed, Bidirectional,\n",
        "                          dot, multiply, concatenate, merge)\n",
        "from keras.engine import InputSpec\n",
        "from keras.callbacks import Callback, LambdaCallback\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras.utils import multi_gpu_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AbQ7AdStxvhs",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "np.set_printoptions(precision=10)"
      ]
    },
    {
      "metadata": {
        "id": "TjGAWTEWxvht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "uP2zagKNxvht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "925b5eec-fc25-4baf-c0be-6a24bc445663"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RK1M33Sxvhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras"
      ]
    },
    {
      "metadata": {
        "id": "d_KAtKsBxvhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "272388b8-b633-4c17-fb6d-588983561d31"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x, derivative=False):\n",
        "    return x*(1-x) if derivative else 1/(1+np.exp(-x))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGFPxMJYxvhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9a9452fe-be5c-42fb-9796-2d1ca2b751cd"
      },
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return np.sinh(x)/np.cosh(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wjacj4Sgxvh1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## RNN Code Flow"
      ]
    },
    {
      "metadata": {
        "id": "WByw9ULYxvh1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Forward-Propagation"
      ]
    },
    {
      "metadata": {
        "id": "qWzzvi0Nxvh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0201a9f0-678b-413c-e6d6-0c79bd993092"
      },
      "cell_type": "code",
      "source": [
        "units = 1\n",
        "input_dim = 5\n",
        "\n",
        "if input_dim == 1:\n",
        "    data_X = np.array([[.3],\n",
        "                       [.7],\n",
        "                       [.4]\n",
        "                      ]).reshape(1, 3, 1).astype('float32')\n",
        "elif input_dim == 2:\n",
        "    data_X = np.array([[.3, .8],\n",
        "                       [.7, .6],\n",
        "                       [.4, 0.]\n",
        "                      ]).reshape(1, 3, 2).astype('float32')\n",
        "\n",
        "else:\n",
        "    data_X = np.array([[.3, .8, .1, .7, .2],\n",
        "                       [.7, .6, .2, .4, .5],\n",
        "                       [.4, 0., .9, .3, .4]\n",
        "                      ]).reshape(1, 3, 5).astype('float32')\n",
        "\n",
        "print(data_X.shape)\n",
        "pprint(data_X)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 5)\n",
            "array([[[0.3, 0.8, 0.1, 0.7, 0.2],\n",
            "        [0.7, 0.6, 0.2, 0.4, 0.5],\n",
            "        [0.4, 0. , 0.9, 0.3, 0.4]]], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p-Y76fbTxvh5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=False`"
      ]
    },
    {
      "metadata": {
        "id": "abR1QdSVxvh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1c88618d-1313-420f-d681-1167ec708e5d"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "#init_state = np.zeros((1, units), dtype=np.float32)\n",
        "#init_state = [K.zeros(init_state.shape, dtype=np.float32, name=None)]\n",
        "\n",
        "if len(data_X.shape) == 3:\n",
        "    n_sample, seq_len, input_dim = data_X.shape\n",
        "else:\n",
        "    n_sample, seq_len, input_dim, _ = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = SimpleRNN(units, return_sequences=False,\n",
        "                       return_state=True,\n",
        "                       name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer/kernel:0' shape=(5, 1) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer/recurrent_kernel:0' shape=(1, 1) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer/bias:0' shape=(1,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 5)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (SimpleRNN)        [(None, 1), (None, 1)]    7         \n",
            "=================================================================\n",
            "Total params: 7\n",
            "Trainable params: 7\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gtvzgj71xvh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a41e483-2e7f-4306-d089-ff94bbcc096a"
      },
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 1), (None, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "-X_feQnlxvh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42ae53ca-36a2-477f-8083-e3d5b07fd14a"
      },
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Tob1Dzq2xviD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Create Session Error Exception"
      ]
    },
    {
      "metadata": {
        "id": "oLcZgxHlxviE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "850ea535-011a-460d-b833-52166d068603"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model.get_weights()\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5NuYcSBaxviG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8442b793-c7f7-462e-caee-b4927aa2b89d"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "print('Kernel_shape:', kernel.shape)\n",
        "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
        "print('Bias_shape:', bias.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.7197337 ]\n",
            " [ 0.91148114]\n",
            " [-0.6833987 ]\n",
            " [-0.52902746]\n",
            " [ 0.04637766]]\n",
            "[[1.]]\n",
            "[0.]\n",
            "Kernel_shape: (5, 1)\n",
            "Recurrent_Kernel_shape: (1, 1)\n",
            "Bias_shape: (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FWYlS0zExviJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0831772-a4e1-4974-c97d-71f171f4afce"
      },
      "cell_type": "code",
      "source": [
        "_rnn_layer.get_initial_state(data_X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Tile:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "18mozgQDxviL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4565b657-52d5-4a23-b75e-3d03ff6e9a9f"
      },
      "cell_type": "code",
      "source": [
        "weight = ['h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight))\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight))\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), )\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]]\n",
            "[[-0.05]]\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tffd1C1HxviN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        },
        "outputId": "def31fcf-afe5-41b5-b8bd-9ec123ba575c"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = False\n",
        "return_state = True\n",
        "\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('input ---------')\n",
        "    wi = np.dot(inputs, kernel) + bias\n",
        "    wi = wi.astype(np.float32)\n",
        "    print(wi.shape)\n",
        "    pprint(wi)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h]\n",
        "    prev_h = states[0]\n",
        "    print('prev h --------')\n",
        "    print(prev_h.shape)\n",
        "    pprint(prev_h)\n",
        "    #print('\\nprev:', prev_output)\n",
        "\n",
        "    #print('w. prev h -----')\n",
        "    wh = np.dot(prev_h, recurrent_kernel)\n",
        "    wh = wh.astype(np.float32)\n",
        "    print(wh.shape)\n",
        "    pprint(wh)\n",
        "\n",
        "    print('h --------')\n",
        "    h = tanh(wh + wi)\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "\n",
        "    print('output ---')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h\\t\\t:', prev_h)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]]\n",
            "[[-0.05]]\n",
            "[0.]\n",
            "inputs\n",
            "(5,)\n",
            "array([0.3, 0.8, 0.1, 0.7, 0.2], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.81], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.], dtype=float32)\n",
            "(1,)\n",
            "array([-0.], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.3 0.8 0.1 0.7 0.2]\n",
            "prev h\t\t: [0.]\n",
            "h\t\t: [0.66959035]\n",
            "output(0)\t: [0.66959035]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(5,)\n",
            "array([0.7, 0.6, 0.2, 0.4, 0.5], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.90000004], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "(1,)\n",
            "array([-0.03347952], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.7 0.6 0.2 0.4 0.5]\n",
            "prev h\t\t: [0.66959035]\n",
            "h\t\t: [0.699602]\n",
            "output(1)\t: [0.699602]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(5,)\n",
            "array([0.4, 0. , 0.9, 0.3, 0.4], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.83], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "(1,)\n",
            "array([-0.0349801], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.6612434], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.6612434], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4 0.  0.9 0.3 0.4]\n",
            "prev h\t\t: [0.699602]\n",
            "h\t\t: [0.6612434]\n",
            "output(2)\t: [0.6612434]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[0.6612434]], dtype=float32), array([[0.6612434]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[0.66124344]], dtype=float32), array([[0.66124344]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ll_TqasTxviQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=True`"
      ]
    },
    {
      "metadata": {
        "id": "a8ZA8oCQxviQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "d4310dc5-d1c9-4e06-d921-b0183a5b7cf8"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "#units = 3\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = SimpleRNN(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "_output_layer = Activation('softmax', name='Output_layer')\n",
        "_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "#model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model = Model(inputs=_input_layer, outputs=[_outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer_1/kernel:0' shape=(5, 1) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_1/recurrent_kernel:0' shape=(1, 1) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_1/bias:0' shape=(1,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 5)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (SimpleRNN)        [(None, 3, 1), (None, 1)] 7         \n",
            "_________________________________________________________________\n",
            "Output_layer (Activation)    (None, 3, 1)              0         \n",
            "=================================================================\n",
            "Total params: 7\n",
            "Trainable params: 7\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uYUe9xpbxviU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "98b4a6c2-a3ed-462b-89fe-7023af1a529e"
      },
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 3, 1), (None, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "8Dw1guwNxviX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b90b6efc-5918-485c-e4af-ea552d542c4e"
      },
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "e_gNZkILxvia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3f92fe1c-cf71-440c-e194-6ef85cb71c04"
      },
      "cell_type": "code",
      "source": [
        "weight = ['h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]]\n",
            "[[-0.05]]\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wf4esBpmxvib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        },
        "outputId": "c3f2c4b1-88c1-4abf-e8ab-9ab5df828c6a"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = True\n",
        "return_state = True\n",
        "\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('input ---------')\n",
        "    wi = np.dot(inputs, kernel) + bias\n",
        "    wi = wi.astype(np.float32)\n",
        "    print(wi.shape)\n",
        "    pprint(wi)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h]\n",
        "    prev_h = states[0]\n",
        "    print('prev h --------')\n",
        "    print(prev_h.shape)\n",
        "    pprint(prev_h)\n",
        "    #print('\\nprev:', prev_output)\n",
        "\n",
        "    #print('w. prev h -----')\n",
        "    wh = np.dot(prev_h, recurrent_kernel)\n",
        "    wh = wh.astype(np.float32)\n",
        "    print(wh.shape)\n",
        "    pprint(wh)\n",
        "\n",
        "    print('h --------')\n",
        "    h = tanh(wh + wi)\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "\n",
        "    print('output ---')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "\n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h\\t\\t:', prev_h)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]]\n",
            "[[-0.05]]\n",
            "[0.]\n",
            "inputs\n",
            "(5,)\n",
            "array([0.3, 0.8, 0.1, 0.7, 0.2], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.81], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.], dtype=float32)\n",
            "(1,)\n",
            "array([-0.], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.3 0.8 0.1 0.7 0.2]\n",
            "prev h\t\t: [0.]\n",
            "h\t\t: [0.66959035]\n",
            "output(0)\t: [0.66959035]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(5,)\n",
            "array([0.7, 0.6, 0.2, 0.4, 0.5], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.90000004], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.66959035], dtype=float32)\n",
            "(1,)\n",
            "array([-0.03347952], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.7 0.6 0.2 0.4 0.5]\n",
            "prev h\t\t: [0.66959035]\n",
            "h\t\t: [0.699602]\n",
            "output(1)\t: [0.699602]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(5,)\n",
            "array([0.4, 0. , 0.9, 0.3, 0.4], dtype=float32)\n",
            "input ---------\n",
            "(1,)\n",
            "array([0.83], dtype=float32)\n",
            "prev h --------\n",
            "(1,)\n",
            "array([0.699602], dtype=float32)\n",
            "(1,)\n",
            "array([-0.0349801], dtype=float32)\n",
            "h --------\n",
            "(1,)\n",
            "array([0.6612434], dtype=float32)\n",
            "output ---\n",
            "(1,)\n",
            "array([0.6612434], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4 0.  0.9 0.3 0.4]\n",
            "prev h\t\t: [0.699602]\n",
            "h\t\t: [0.6612434]\n",
            "output(2)\t: [0.6612434]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[[0.66959035],\n",
            "        [0.699602  ],\n",
            "        [0.6612434 ]]], dtype=float32), array([[0.6612434]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[[1.],\n",
            "        [1.],\n",
            "        [1.]]], dtype=float32), array([[0.66124344]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lq6PuD8Hxvie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Back-Propagation"
      ]
    },
    {
      "metadata": {
        "id": "aZtCvkRsxvif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "180204be-69d4-455c-c1cb-0d4a670edfac"
      },
      "cell_type": "code",
      "source": [
        "from scipy.integrate import odeint\n",
        "from scipy.misc import derivative"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FeISl56txvih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f616a11e-78d6-4c37-b082-6eaf360857fe"
      },
      "cell_type": "code",
      "source": [
        "x = .2\n",
        "f = lambda x: -.3*x + .1\n",
        "g = lambda x: .4*x - .4\n",
        "\n",
        "y = g(x)\n",
        "z = f(g(x))\n",
        "\n",
        "print('X: %s, Y: %s, Z: %s' % (x, y, z))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: 0.2, Y: -0.32, Z: 0.196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D0HXR3Tnxvik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d5c0f54-cb4a-4067-9fb7-ad1c59e8b0a1"
      },
      "cell_type": "code",
      "source": [
        "derivative(f, x)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "oWMioggFxvin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "513ba82b-0099-4d16-c506-449d73e0ce93"
      },
      "cell_type": "code",
      "source": [
        "x = 5\n",
        "f = lambda x: 3*(x**2) - 1\n",
        "\n",
        "y = f(x)\n",
        "\n",
        "print('X: %s, Y: %s' % (x, y))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: 5, Y: 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtP8qXwBxviq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e03f97d-8041-4e21-c1f2-8b2ea9a19b52"
      },
      "cell_type": "code",
      "source": [
        "derivative(f, x)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "4jgqu7Cnxvis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bd20b780-9e3a-408c-944f-5ba21f6b13c7"
      },
      "cell_type": "code",
      "source": [
        "def sigmo(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3fH_i4Hxviu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d991ef4d-fead-4282-d534-c130ea008e5b"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQbx8miqxviw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38f9cfb9-618d-4bdf-935f-c6a1caf35844"
      },
      "cell_type": "code",
      "source": [
        "odeint(f, y, .2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[74.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "WGwQ1eq_xviy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## LSTM Code Flow"
      ]
    },
    {
      "metadata": {
        "id": "8zTlolj6xviz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9cbf2001-a117-4343-def4-d7db6f18defb"
      },
      "cell_type": "code",
      "source": [
        "units = 1\n",
        "input_dim = 1\n",
        "\n",
        "if input_dim == 1:\n",
        "    data_X = np.array([[.2],\n",
        "                       [.5],\n",
        "                       [.4]\n",
        "                      ]).reshape(1, 3, 1).astype('float32')\n",
        "else:\n",
        "    data_X = np.array([[.2, .1],\n",
        "                       [.5, .3],\n",
        "                       [.4, 0.]\n",
        "                      ]).reshape(1, 3, 2).astype('float32')\n",
        "\n",
        "print(data_X.shape)\n",
        "pprint(data_X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 1)\n",
            "array([[[0.2],\n",
            "        [0.5],\n",
            "        [0.4]]], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "efEzrnlIxvi2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=False`"
      ]
    },
    {
      "metadata": {
        "id": "677lNeuQxvi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "3647821b-a209-4982-da19-adcb4ec9cbff"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = LSTM(units, return_sequences=False, return_state=True, name='RNN_layer')\n",
        "outputs, state_h, state_c = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, state_h, state_c])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer_2/kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_2/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_2/bias:0' shape=(4,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 1)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (LSTM)             [(None, 1), (None, 1), (N 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwqmJRXWxvi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c5690a22-8241-4167-b429-39affd54722f"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "print('Kernel_shape:', kernel.shape)\n",
        "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
        "print('Bias_shape:', bias.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.0404475   0.85997784  0.6231929  -0.30608314]]\n",
            "[[-0.07972494  0.8828801  -0.33344343  0.32090828]]\n",
            "[0. 1. 0. 0.]\n",
            "Kernel_shape: (1, 4)\n",
            "Recurrent_Kernel_shape: (1, 4)\n",
            "Bias_shape: (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4xqSyH5xvi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "15bf2dab-168d-4629-b4e4-78ecdb6e2085"
      },
      "cell_type": "code",
      "source": [
        "weight = ['i', 'f', 'c', 'o']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5]]\n",
            "[[-0.05 -0.04 -0.03 -0.02]]\n",
            "[0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BpvBD5Irxvi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "3432ffe3-d7a7-4591-f061-c6563cc5cb52"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = False\n",
        "return_state = True\n",
        "\n",
        "\"\"\"\n",
        "activation = np.tanh\n",
        "recurrent_activation = sigmoid\n",
        "\"\"\"\n",
        "\n",
        "kernel_i = kernel[:,           :units * 1]\n",
        "kernel_f = kernel[:, units * 1: units * 2]\n",
        "kernel_c = kernel[:, units * 2: units * 3]\n",
        "kernel_o = kernel[:, units * 3:]\n",
        "\n",
        "recurrent_kernel_i = recurrent_kernel[:,          : units * 1]\n",
        "recurrent_kernel_f = recurrent_kernel[:, units * 1: units * 2]\n",
        "recurrent_kernel_c = recurrent_kernel[:, units * 2: units * 3]\n",
        "recurrent_kernel_o = recurrent_kernel[:, units * 3:]\n",
        "\n",
        "bias_i = bias[         : units * 1]\n",
        "bias_f = bias[units * 1: units * 2]\n",
        "bias_c = bias[units * 2: units * 3]\n",
        "bias_o = bias[units * 3:          ]\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('x -----------')\n",
        "    print('dropout(input) time')\n",
        "    x_i = np.dot(inputs, kernel_i) + bias_i\n",
        "    x_f = np.dot(inputs, kernel_f) + bias_f\n",
        "    x_c = np.dot(inputs, kernel_c) + bias_c\n",
        "    x_o = np.dot(inputs, kernel_o) + bias_o\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)] * 2\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h, c]\n",
        "    h_tm1 = prev_h = states[0]\n",
        "    c_tm1 = prev_c = states[1]\n",
        "    print('prev --------')\n",
        "    print(prev_h.shape, prev_c.shape)\n",
        "    pprint((prev_h, prev_c))\n",
        "    #print('\\nprev:', prev_output)\n",
        "    \n",
        "    print('gate --------')\n",
        "    print('recurrent dropout(h_tm1) time')\n",
        "    i = sigmoid(x_i + np.dot(h_tm1, recurrent_kernel_i))\n",
        "    f = sigmoid(x_f + np.dot(h_tm1, recurrent_kernel_f))\n",
        "    c = f * c_tm1 +\\\n",
        "        i * sigmoid(x_c + np.dot(h_tm1, recurrent_kernel_c))\n",
        "    o = np.tanh(x_o + np.dot(h_tm1, recurrent_kernel_o))\n",
        "    \n",
        "    h = o * np.tanh(c)\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h, prev_c\\t:', prev_h, prev_c)\n",
        "    print('h, c\\t\\t:', h, c)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "\n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = [h, c]\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5]]\n",
            "[[-0.05 -0.04 -0.03 -0.02]]\n",
            "[0. 0. 0. 0.]\n",
            "inputs\n",
            "(1,)\n",
            "array([0.2], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.], dtype=float32), array([0.], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.02582867], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.02582867], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.2]\n",
            "prev h, prev_c\t: [0.] [0.]\n",
            "h, c\t\t: [0.02582867] [0.26519388]\n",
            "output(0)\t: [0.02582867]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(1,)\n",
            "array([0.5], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.02582867], dtype=float32), array([0.26519388], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.09924313], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.09924313], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.5]\n",
            "prev h, prev_c\t: [0.02582867] [0.26519388]\n",
            "h, c\t\t: [0.09924313] [0.4308287]\n",
            "output(1)\t: [0.09924313]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(1,)\n",
            "array([0.4], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.09924313], dtype=float32), array([0.4308287], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.09149212], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.09149212], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4]\n",
            "prev h, prev_c\t: [0.09924313] [0.4308287]\n",
            "h, c\t\t: [0.09149212] [0.5075951]\n",
            "output(2)\t: [0.09149212]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[0.09149212]], dtype=float32), array([[[0.09149212],\n",
            "        [0.5075951 ]]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[0.07799154]], dtype=float32), array([[0.07799154]], dtype=float32), array([[0.1455198]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Hnd0znnxvi_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=True`"
      ]
    },
    {
      "metadata": {
        "id": "o5nhzrZ6xvi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "95a5f0e6-21c3-4e95-f428-9072a7c3ea85"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = LSTM(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
        "outputs, state_h, state_c = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, state_h, state_c])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer_3/kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_3/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_3/bias:0' shape=(4,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 1)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (LSTM)             [(None, 3, 1), (None, 1), 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AWwjGGV3xvjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ecb89e58-378c-4166-9194-0d09619a928c"
      },
      "cell_type": "code",
      "source": [
        "weight = ['i', 'f', 'c', 'o']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5]]\n",
            "[[-0.05 -0.04 -0.03 -0.02]]\n",
            "[0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7z5GTqNxvjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        },
        "outputId": "7fd88a31-3d28-4182-8a71-ed9177869b51"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = True\n",
        "return_state = True\n",
        "\n",
        "\"\"\"\n",
        "activation = np.tanh\n",
        "recurrent_activation = sigmoid\n",
        "\"\"\"\n",
        "\n",
        "kernel_i = kernel[:,           :units * 1]\n",
        "kernel_f = kernel[:, units * 1: units * 2]\n",
        "kernel_c = kernel[:, units * 2: units * 3]\n",
        "kernel_o = kernel[:, units * 3:]\n",
        "\n",
        "recurrent_kernel_i = recurrent_kernel[:,          : units * 1]\n",
        "recurrent_kernel_f = recurrent_kernel[:, units * 1: units * 2]\n",
        "recurrent_kernel_c = recurrent_kernel[:, units * 2: units * 3]\n",
        "recurrent_kernel_o = recurrent_kernel[:, units * 3:]\n",
        "\n",
        "bias_i = bias[         : units * 1]\n",
        "bias_f = bias[units * 1: units * 2]\n",
        "bias_c = bias[units * 2: units * 3]\n",
        "bias_o = bias[units * 3:          ]\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('x -----------')\n",
        "    print('dropout(input) time')\n",
        "    x_i = np.dot(inputs, kernel_i) + bias_i\n",
        "    x_f = np.dot(inputs, kernel_f) + bias_f\n",
        "    x_c = np.dot(inputs, kernel_c) + bias_c\n",
        "    x_o = np.dot(inputs, kernel_o) + bias_o\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)] * 2\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h, c]\n",
        "    h_tm1 = prev_h = states[0]\n",
        "    c_tm1 = prev_c = states[1]\n",
        "    print('prev --------')\n",
        "    print(prev_h.shape, prev_c.shape)\n",
        "    pprint((prev_h, prev_c))\n",
        "    #print('\\nprev:', prev_output)\n",
        "    \n",
        "    print('gate --------')\n",
        "    print('recurrent dropout(h_tm1) time')\n",
        "    i = sigmoid(x_i + np.dot(h_tm1, recurrent_kernel_i))\n",
        "    f = sigmoid(x_f + np.dot(h_tm1, recurrent_kernel_f))\n",
        "    c = f * c_tm1 +\\\n",
        "        i * sigmoid(x_c + np.dot(h_tm1, recurrent_kernel_c))\n",
        "    o = np.tanh(x_o + np.dot(h_tm1, recurrent_kernel_o))\n",
        "    \n",
        "    h = o * np.tanh(c)\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h, prev_c\\t:', prev_h, prev_c)\n",
        "    print('h, c\\t\\t:', h, c)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "\n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = [h, c]\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5]]\n",
            "[[-0.05 -0.04 -0.03 -0.02]]\n",
            "[0. 0. 0. 0.]\n",
            "inputs\n",
            "(1,)\n",
            "array([0.2], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.], dtype=float32), array([0.], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.02582867], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.02582867], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.2]\n",
            "prev h, prev_c\t: [0.] [0.]\n",
            "h, c\t\t: [0.02582867] [0.26519388]\n",
            "output(0)\t: [0.02582867]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(1,)\n",
            "array([0.5], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.02582867], dtype=float32), array([0.26519388], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.09924313], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.09924313], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.5]\n",
            "prev h, prev_c\t: [0.02582867] [0.26519388]\n",
            "h, c\t\t: [0.09924313] [0.4308287]\n",
            "output(1)\t: [0.09924313]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(1,)\n",
            "array([0.4], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(1,) (1,)\n",
            "(array([0.09924313], dtype=float32), array([0.4308287], dtype=float32))\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(1,)\n",
            "array([0.09149212], dtype=float32)\n",
            "output ------\n",
            "(1,)\n",
            "array([0.09149212], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4]\n",
            "prev h, prev_c\t: [0.09924313] [0.4308287]\n",
            "h, c\t\t: [0.09149212] [0.5075951]\n",
            "output(2)\t: [0.09149212]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[[0.02582867],\n",
            "        [0.09924313],\n",
            "        [0.09149212]]], dtype=float32), array([[[0.09149212],\n",
            "        [0.5075951 ]]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[[0.02107628],\n",
            "        [0.06771449],\n",
            "        [0.07799154]]], dtype=float32), array([[0.07799154]], dtype=float32), array([[0.1455198]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MbxQczxcxvjI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## GRU Code Flow"
      ]
    },
    {
      "metadata": {
        "id": "0dm4DayDxvjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "718c8877-185f-400e-b661-a290d5868181"
      },
      "cell_type": "code",
      "source": [
        "units = 2\n",
        "input_dim = 2\n",
        "\n",
        "if input_dim == 1:\n",
        "    data_X = np.array([[.2],\n",
        "                       [.5],\n",
        "                       [.4]\n",
        "                      ]).reshape(1, 3, 1).astype('float32')\n",
        "else:\n",
        "    data_X = np.array([[.2, .1],\n",
        "                       [.5, .3],\n",
        "                       [.4, 0.]\n",
        "                      ]).reshape(1, 3, 2).astype('float32')\n",
        "\n",
        "print(data_X.shape)\n",
        "pprint(data_X)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 2)\n",
            "array([[[0.2, 0.1],\n",
            "        [0.5, 0.3],\n",
            "        [0.4, 0. ]]], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mg2mvC2AxvjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=False`"
      ]
    },
    {
      "metadata": {
        "id": "96y8o_01xvjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "0fbea7aa-9887-44e1-d885-4ae9ce488486"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = GRU(units, return_sequences=False, return_state=True, name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer_4/kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_4/recurrent_kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_4/bias:0' shape=(6,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 2)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (GRU)              [(None, 2), (None, 2)]    30        \n",
            "=================================================================\n",
            "Total params: 30\n",
            "Trainable params: 30\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bSwcUnTZxvjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "43fc0a36-1706-4d35-ba37-f4f03a72ba8e"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "print('Kernel_shape:', kernel.shape)\n",
        "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
        "print('Bias_shape:', bias.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.41855976  0.3677618  -0.3848508   0.7734948   0.45289642 -0.17317474]\n",
            " [ 0.2334637   0.8425657  -0.19799095  0.68902105 -0.00720972  0.38214308]]\n",
            "[[ 0.13291705 -0.22553636 -0.05503934 -0.07933751  0.5430779   0.7919653 ]\n",
            " [ 0.14899194 -0.62268245 -0.06711234 -0.41141158  0.38886312 -0.51486886]]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "Kernel_shape: (2, 6)\n",
            "Recurrent_Kernel_shape: (2, 6)\n",
            "Bias_shape: (6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "46EwZ-vXxvjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5f0a22a7-2275-4797-8413-7f8ae0d65ddc"
      },
      "cell_type": "code",
      "source": [
        "weight = ['z', 'r', 'h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
            " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
            "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
            " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
            "[0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9eKSgsixvjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "db2c2af8-4ec8-45bd-def6-87ae95a51040"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = False\n",
        "return_state = True\n",
        "\n",
        "\"\"\"\n",
        "activation = np.tanh\n",
        "recurrent_activation = sigmoid\n",
        "\"\"\"\n",
        "\n",
        "kernel_z = kernel[:,          : units * 1]\n",
        "kernel_r = kernel[:, units * 1: units * 2]\n",
        "kernel_h = kernel[:, units * 2:]\n",
        "\n",
        "recurrent_kernel_z = recurrent_kernel[:,          : units * 1]\n",
        "recurrent_kernel_r = recurrent_kernel[:, units * 1: units * 2]\n",
        "recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
        "\n",
        "bias_z = bias[         : units * 1]\n",
        "bias_r = bias[units    : units * 2]\n",
        "bias_h = bias[units * 2:]\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('x -----------')\n",
        "    print('dropout(input) time')\n",
        "    x_z = np.dot(inputs, kernel_z) + bias_z\n",
        "    x_r = np.dot(inputs, kernel_r) + bias_r\n",
        "    x_h = np.dot(inputs, kernel_h) + bias_h\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h]\n",
        "    h_tm1 = prev_h = states[0]\n",
        "    print('prev --------')\n",
        "    print(prev_h.shape)\n",
        "    pprint(prev_h)\n",
        "    #print('\\nprev:', prev_output)\n",
        "    \n",
        "    print('gate --------')\n",
        "    print('recurrent dropout(h_tm1) time')\n",
        "    z = sigmoid(x_z + np.dot(h_tm1, recurrent_kernel_z))\n",
        "    r = sigmoid(x_r + np.dot(h_tm1, recurrent_kernel_r))\n",
        "    hh = np.tanh(x_h + np.dot(h_tm1, recurrent_kernel_h))\n",
        "    \n",
        "    h = z * h_tm1 + (1 - z) * hh\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h\\t\\t:', prev_h)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
            " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
            "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
            " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "inputs\n",
            "(2,)\n",
            "array([0.2, 0.1], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0., 0.], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.2 0.1]\n",
            "prev h\t\t: [0. 0.]\n",
            "h\t\t: [0.11069148 0.12194498]\n",
            "output(0)\t: [0.11069148 0.12194498]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(2,)\n",
            "array([0.5, 0.3], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.5 0.3]\n",
            "prev h\t\t: [0.11069148 0.12194498]\n",
            "h\t\t: [0.3070247  0.32504663]\n",
            "output(1)\t: [0.3070247  0.32504663]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(2,)\n",
            "array([0.4, 0. ], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.2784692, 0.3089273], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.2784692, 0.3089273], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4 0. ]\n",
            "prev h\t\t: [0.3070247  0.32504663]\n",
            "h\t\t: [0.2784692 0.3089273]\n",
            "output(2)\t: [0.2784692 0.3089273]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[0.2784692, 0.3089273]], dtype=float32), array([[0.2784692, 0.3089273]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[0.27963528, 0.31039596]], dtype=float32), array([[0.27963528, 0.31039596]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxH7KRwGxvjX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=True`"
      ]
    },
    {
      "metadata": {
        "id": "iL-q0wk2xvjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "1726ec8c-554c-4668-ab11-2ceb8f5d1cdd"
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = GRU(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'RNN_layer_5/kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_5/recurrent_kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
            " <tf.Variable 'RNN_layer_5/bias:0' shape=(6,) dtype=float32_ref>]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     (None, 3, 2)              0         \n",
            "_________________________________________________________________\n",
            "RNN_layer (GRU)              [(None, 3, 2), (None, 2)] 30        \n",
            "=================================================================\n",
            "Total params: 30\n",
            "Trainable params: 30\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "phKyHW2axvja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ad70f0ef-838f-4afa-e58d-f582f16ba614"
      },
      "cell_type": "code",
      "source": [
        "weight = ['z', 'r', 'h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
            " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
            "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
            " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
            "[0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R4GyrPeQxvjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1499
        },
        "outputId": "9c57fc91-342e-49de-d743-c576a977b207"
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = True\n",
        "return_state = True\n",
        "\n",
        "\"\"\"\n",
        "activation = np.tanh\n",
        "recurrent_activation = sigmoid\n",
        "\"\"\"\n",
        "\n",
        "kernel_z = kernel[:,          : units * 1]\n",
        "kernel_r = kernel[:, units * 1: units * 2]\n",
        "kernel_h = kernel[:, units * 2:]\n",
        "\n",
        "recurrent_kernel_z = recurrent_kernel[:,          : units * 1]\n",
        "recurrent_kernel_r = recurrent_kernel[:, units * 1: units * 2]\n",
        "recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
        "\n",
        "bias_z = bias[         : units * 1]\n",
        "bias_r = bias[units    : units * 2]\n",
        "bias_h = bias[units * 2:]\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('x -----------')\n",
        "    print('dropout(input) time')\n",
        "    x_z = np.dot(inputs, kernel_z) + bias_z\n",
        "    x_r = np.dot(inputs, kernel_r) + bias_r\n",
        "    x_h = np.dot(inputs, kernel_h) + bias_h\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h]\n",
        "    h_tm1 = prev_h = states[0]\n",
        "    print('prev --------')\n",
        "    print(prev_h.shape)\n",
        "    pprint(prev_h)\n",
        "    #print('\\nprev:', prev_output)\n",
        "    \n",
        "    print('gate --------')\n",
        "    print('recurrent dropout(h_tm1) time')\n",
        "    z = sigmoid(x_z + np.dot(h_tm1, recurrent_kernel_z))\n",
        "    r = sigmoid(x_r + np.dot(h_tm1, recurrent_kernel_r))\n",
        "    hh = np.tanh(x_h + np.dot(h_tm1, recurrent_kernel_h))\n",
        "    \n",
        "    h = z * h_tm1 + (1 - z) * hh\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('input\\t\\t:', inputs)\n",
        "    print('prev h\\t\\t:', prev_h)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
            " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
            "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
            " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "inputs\n",
            "(2,)\n",
            "array([0.2, 0.1], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0., 0.], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "\n",
            "step (0)=====================================\n",
            "input\t\t: [0.2 0.1]\n",
            "prev h\t\t: [0. 0.]\n",
            "h\t\t: [0.11069148 0.12194498]\n",
            "output(0)\t: [0.11069148 0.12194498]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(2,)\n",
            "array([0.5, 0.3], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0.11069148, 0.12194498], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "\n",
            "step (1)=====================================\n",
            "input\t\t: [0.5 0.3]\n",
            "prev h\t\t: [0.11069148 0.12194498]\n",
            "h\t\t: [0.3070247  0.32504663]\n",
            "output(1)\t: [0.3070247  0.32504663]\n",
            "=============================================\n",
            "\n",
            "inputs\n",
            "(2,)\n",
            "array([0.4, 0. ], dtype=float32)\n",
            "x -----------\n",
            "dropout(input) time\n",
            "prev --------\n",
            "(2,)\n",
            "array([0.3070247 , 0.32504663], dtype=float32)\n",
            "gate --------\n",
            "recurrent dropout(h_tm1) time\n",
            "(2,)\n",
            "array([0.2784692, 0.3089273], dtype=float32)\n",
            "output ------\n",
            "(2,)\n",
            "array([0.2784692, 0.3089273], dtype=float32)\n",
            "\n",
            "step (2)=====================================\n",
            "input\t\t: [0.4 0. ]\n",
            "prev h\t\t: [0.3070247  0.32504663]\n",
            "h\t\t: [0.2784692 0.3089273]\n",
            "output(2)\t: [0.2784692 0.3089273]\n",
            "=============================================\n",
            "\n",
            "\n",
            "Result: [Output, State]\n",
            "\n",
            "=== Numpy ===\n",
            "[array([[[0.11069148, 0.12194498],\n",
            "        [0.3070247 , 0.32504663],\n",
            "        [0.2784692 , 0.3089273 ]]], dtype=float32), array([[0.2784692, 0.3089273]], dtype=float32)]\n",
            "\n",
            "=== Keras ===\n",
            "[array([[[0.11209598, 0.12390368],\n",
            "        [0.31483552, 0.33543658],\n",
            "        [0.27963528, 0.31039596]]], dtype=float32), array([[0.27963528, 0.31039596]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W3TSjWPExvjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## RNN with Word Embedding"
      ]
    },
    {
      "metadata": {
        "id": "uq4sFSajxvje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c51abe1-377d-4371-9d57-454793684c19"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22, 43], [39, 43], [48, 38], [22, 43], [27], [37], [16, 38], [18, 39], [16, 43], [46, 32, 43, 38]]\n",
            "[[22 43  0  0]\n",
            " [39 43  0  0]\n",
            " [48 38  0  0]\n",
            " [22 43  0  0]\n",
            " [27  0  0  0]\n",
            " [37  0  0  0]\n",
            " [16 38  0  0]\n",
            " [18 39  0  0]\n",
            " [16 43  0  0]\n",
            " [46 32 43 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwatSAL90KtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e62eab81-8790-4a2e-b7b2-5680c421729b"
      },
      "cell_type": "code",
      "source": [
        "re.sub(r'!.', ' ', ' '.join(docs).lower()).split()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['well',\n",
              " 'done',\n",
              " 'good',\n",
              " 'work',\n",
              " 'great',\n",
              " 'effort',\n",
              " 'nice',\n",
              " 'work',\n",
              " 'excellent',\n",
              " 'weak',\n",
              " 'poor',\n",
              " 'effort',\n",
              " 'not',\n",
              " 'good',\n",
              " 'poor',\n",
              " 'work',\n",
              " 'could',\n",
              " 'have',\n",
              " 'done',\n",
              " 'better.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "1C7Ni7B4xvjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "844710a1-84b4-48ec-ab13-4fc16d6c90f2"
      },
      "cell_type": "code",
      "source": [
        "padded_docs.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "e0X0DfhWxvjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c630aaa5-71cc-4507-8333-1ca81fca5dc1"
      },
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(SimpleRNN(1, return_sequences=True, return_state=False))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 4, 1)              10        \n",
            "=================================================================\n",
            "Total params: 410\n",
            "Trainable params: 410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svzZCq4Dxvji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "403b3f7d-af56-4695-e593-65d840ccaa78"
      },
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "ID0U0Rzmxvjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ae8d7d-c5f4-4749-a083-bc61c2b29e8e"
      },
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "I3un5f4Qxvjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "e4c3ab0e-44b0-4192-a0a6-c65910d6778f"
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2e1680d52d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected simple_rnn_1 to have 3 dimensions, but got array with shape (10, 1)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fKnRTBxaxvjp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Forward-Propagation"
      ]
    },
    {
      "metadata": {
        "id": "QEtpgWFCxvjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "units = 2\n",
        "input_dim = 2\n",
        "\n",
        "if input_dim == 1:\n",
        "    data_X = np.array([[.3],\n",
        "                       [.7],\n",
        "                       [.4]\n",
        "                      ]).reshape(1, 3, 1).astype('float32')\n",
        "else:\n",
        "    data_X = np.array([[.3, .8],\n",
        "                       [.7, .6],\n",
        "                       [.4, 0.]\n",
        "                      ]).reshape(1, 3, 2).astype('float32')\n",
        "\n",
        "print(data_X.shape)\n",
        "pprint(data_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHIV1WpJxvjs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=False`"
      ]
    },
    {
      "metadata": {
        "id": "E_c135-Yxvjs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "#init_state = np.zeros((1, units), dtype=np.float32)\n",
        "#init_state = [K.zeros(init_state.shape, dtype=np.float32, name=None)]\n",
        "\n",
        "if len(data_X.shape) == 3:\n",
        "    n_sample, seq_len, input_dim = data_X.shape\n",
        "else:\n",
        "    n_sample, seq_len, input_dim, _ = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = SimpleRNN(units, return_sequences=False,\n",
        "                       return_state=True,\n",
        "                       name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzSRjp9Dxvjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcikP1cJxvju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fADCHOJtxvjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Create Session Error Exception"
      ]
    },
    {
      "metadata": {
        "id": "s4qDpUZhxvjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model.get_weights()\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SVb9kEjYxvjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "print('Kernel_shape:', kernel.shape)\n",
        "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
        "print('Bias_shape:', bias.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjjLM5nKxvjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_rnn_layer.get_initial_state(data_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGrL-Mmsxvj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight = ['h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight))\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight))\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), )\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYkBRx6axvj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = False\n",
        "return_state = True\n",
        "\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('h -----------')\n",
        "    h = np.dot(inputs, kernel) + bias\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [h]\n",
        "    prev_output = states[0]\n",
        "    print('prev --------')\n",
        "    print(prev_output.shape)\n",
        "    pprint(prev_output)\n",
        "    #print('\\nprev:', prev_output)\n",
        "\n",
        "    print('a -----------')\n",
        "    a = np.dot(prev_output, recurrent_kernel)\n",
        "    a = a.astype(np.float32)\n",
        "    print(a.shape)\n",
        "    pprint(a)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h + a\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('prev\\t\\t:', prev_output)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TU6SQnSxvj4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### `return_sequences=True`"
      ]
    },
    {
      "metadata": {
        "id": "MkjF20ntxvj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "units = units\n",
        "n_sample, seq_len, input_dim = data_X.shape\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
        "\n",
        "_rnn_layer = SimpleRNN(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
        "outputs, states = _rnn_layer(_input_layer)\n",
        "\n",
        "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
        "#_output_layer = Activation('softmax', name='Output_layer')\n",
        "#_outputs = _output_layer(outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "pprint(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oYYz87pxvj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.output_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pplhmDerxvj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GsQkrn-9xvj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight = ['h']\n",
        "\n",
        "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
        "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
        "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
        "\n",
        "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
        "\n",
        "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYkIBmsjxvj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kernel, recurrent_kernel, bias = model.get_weights()\n",
        "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
        "\n",
        "return_sequence = True\n",
        "return_state = True\n",
        "\n",
        "\n",
        "sequence = []\n",
        "for _ in range(len(data_X[0])):\n",
        "    \n",
        "    inputs = data_X[0][_]\n",
        "    inputs = inputs.astype(np.float32)\n",
        "    print('inputs')\n",
        "    print(inputs.shape)\n",
        "    pprint(inputs)\n",
        "\n",
        "    print('h -----------')\n",
        "    h = np.dot(inputs, kernel) + bias\n",
        "    h = h.astype(np.float32)\n",
        "    print(h.shape)\n",
        "    pprint(h)\n",
        "    #print('\\nh:', h)\n",
        "\n",
        "    if _ == 0:\n",
        "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
        "        states = initial_state\n",
        "    else:\n",
        "        states = [output]\n",
        "    prev_output = states[0]\n",
        "    print('prev --------')\n",
        "    print(prev_output.shape)\n",
        "    pprint(prev_output)\n",
        "    #print('\\nprev:', prev_output)\n",
        "\n",
        "    print('a -----------')\n",
        "    a = np.dot(prev_output, recurrent_kernel)\n",
        "    a = a.astype(np.float32)\n",
        "    print(a.shape)\n",
        "    pprint(a)\n",
        "\n",
        "    print('output ------')\n",
        "    output = h + a\n",
        "    output = output.astype(np.float32)\n",
        "    print(output.shape)\n",
        "    pprint(output)\n",
        "    \n",
        "    \n",
        "    print('\\nstep (%s)' % _ + '='*37)\n",
        "    print('h\\t\\t:', h)\n",
        "    print('prev\\t\\t:', prev_output)\n",
        "    print('output(%s)\\t: %s' % (_, output))\n",
        "    print('='*45 + '\\n')\n",
        "    \n",
        "    sequence.append(output)\n",
        "    \n",
        "    if return_sequence:\n",
        "        result = sequence\n",
        "    else:\n",
        "        result = sequence[-1]\n",
        "    \n",
        "    if return_state:\n",
        "        state = output\n",
        "    else:\n",
        "        state = []\n",
        "        \n",
        "        \n",
        "result = np.expand_dims(np.stack(result), axis=0)\n",
        "state = np.expand_dims(np.array(state), axis=0)\n",
        "\n",
        "print('\\nResult: [Output, State]')\n",
        "print('\\n=== Numpy ===')\n",
        "print([result, state])\n",
        "print('\\n=== Keras ===')\n",
        "print(model.predict(data_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pl9qoursxvkA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Done."
      ]
    }
  ]
}