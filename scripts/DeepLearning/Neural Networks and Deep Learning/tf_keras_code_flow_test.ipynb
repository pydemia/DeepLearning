{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.714663Z",
     "start_time": "2018-06-23T08:21:04.778994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import (regularizers, constraints,\n",
    "                   initializers, activations)\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (SimpleRNN, RNN, LSTM, GRU,\n",
    "                          Input, Dense, Activation, Lambda,\n",
    "                          Reshape, Flatten, Permute,\n",
    "                          Embedding, RepeatVector,\n",
    "                          TimeDistributed, Bidirectional,\n",
    "                          dot, multiply, concatenate, merge)\n",
    "from keras.engine import InputSpec\n",
    "from keras.callbacks import Callback, LambdaCallback\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.717501Z",
     "start_time": "2018-06-23T08:21:05.715723Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    return x*(1-x) if derivative else 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.727315Z",
     "start_time": "2018-06-23T08:21:05.718479Z"
    }
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.sinh(x)/np.cosh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RNN Code Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.736422Z",
     "start_time": "2018-06-23T08:21:05.728388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5)\n",
      "array([[[0.3, 0.8, 0.1, 0.7, 0.2],\n",
      "        [0.7, 0.6, 0.2, 0.4, 0.5],\n",
      "        [0.4, 0. , 0.9, 0.3, 0.4]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "units = 1\n",
    "input_dim = 5\n",
    "\n",
    "if input_dim == 1:\n",
    "    data_X = np.array([[.3],\n",
    "                       [.7],\n",
    "                       [.4]\n",
    "                      ]).reshape(1, 3, 1).astype('float32')\n",
    "elif input_dim == 2:\n",
    "    data_X = np.array([[.3, .8],\n",
    "                       [.7, .6],\n",
    "                       [.4, 0.]\n",
    "                      ]).reshape(1, 3, 2).astype('float32')\n",
    "\n",
    "else:\n",
    "    data_X = np.array([[.3, .8, .1, .7, .2],\n",
    "                       [.7, .6, .2, .4, .5],\n",
    "                       [.4, 0., .9, .3, .4]\n",
    "                      ]).reshape(1, 3, 5).astype('float32')\n",
    "\n",
    "print(data_X.shape)\n",
    "pprint(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.845018Z",
     "start_time": "2018-06-23T08:21:05.737481Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer/kernel:0' shape=(5, 1) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer/recurrent_kernel:0' shape=(1, 1) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (SimpleRNN)        [(None, 1), (None, 1)]    7         \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "#init_state = np.zeros((1, units), dtype=np.float32)\n",
    "#init_state = [K.zeros(init_state.shape, dtype=np.float32, name=None)]\n",
    "\n",
    "if len(data_X.shape) == 3:\n",
    "    n_sample, seq_len, input_dim = data_X.shape\n",
    "else:\n",
    "    n_sample, seq_len, input_dim, _ = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = SimpleRNN(units, return_sequences=False,\n",
    "                       return_state=True,\n",
    "                       name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.849656Z",
     "start_time": "2018-06-23T08:21:05.846250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1), (None, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:05.858347Z",
     "start_time": "2018-06-23T08:21:05.850747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Session Error Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.148423Z",
     "start_time": "2018-06-23T08:21:05.859421Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.get_weights()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.153387Z",
     "start_time": "2018-06-23T08:21:06.149646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68241835]\n",
      " [-0.49033356]\n",
      " [-0.07335067]\n",
      " [-0.28062916]\n",
      " [ 0.0865953 ]]\n",
      "[[1.]]\n",
      "[0.]\n",
      "Kernel_shape: (5, 1)\n",
      "Recurrent_Kernel_shape: (1, 1)\n",
      "Bias_shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "print('Kernel_shape:', kernel.shape)\n",
    "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
    "print('Bias_shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.165046Z",
     "start_time": "2018-06-23T08:21:06.154927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Tile:0' shape=(1, 1) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rnn_layer.get_initial_state(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.182422Z",
     "start_time": "2018-06-23T08:21:06.166377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]]\n",
      "[[-0.05]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight))\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight))\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), )\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.308729Z",
     "start_time": "2018-06-23T08:21:06.183598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]]\n",
      "[[-0.05]]\n",
      "[0.]\n",
      "inputs\n",
      "(5,)\n",
      "array([0.3, 0.8, 0.1, 0.7, 0.2], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.81], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.], dtype=float32)\n",
      "(1,)\n",
      "array([-0.], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.3 0.8 0.1 0.7 0.2]\n",
      "prev h\t\t: [0.]\n",
      "h\t\t: [0.66959035]\n",
      "output(0)\t: [0.66959035]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(5,)\n",
      "array([0.7, 0.6, 0.2, 0.4, 0.5], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.90000004], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "(1,)\n",
      "array([-0.03347952], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.7 0.6 0.2 0.4 0.5]\n",
      "prev h\t\t: [0.66959035]\n",
      "h\t\t: [0.699602]\n",
      "output(1)\t: [0.699602]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(5,)\n",
      "array([0.4, 0. , 0.9, 0.3, 0.4], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.83], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "(1,)\n",
      "array([-0.0349801], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.6612434], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.6612434], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4 0.  0.9 0.3 0.4]\n",
      "prev h\t\t: [0.699602]\n",
      "h\t\t: [0.6612434]\n",
      "output(2)\t: [0.6612434]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[0.6612434]], dtype=float32), array([[0.6612434]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[0.66124344]], dtype=float32), array([[0.66124344]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = False\n",
    "return_state = True\n",
    "\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('input ---------')\n",
    "    wi = np.dot(inputs, kernel) + bias\n",
    "    wi = wi.astype(np.float32)\n",
    "    print(wi.shape)\n",
    "    pprint(wi)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h]\n",
    "    prev_h = states[0]\n",
    "    print('prev h --------')\n",
    "    print(prev_h.shape)\n",
    "    pprint(prev_h)\n",
    "    #print('\\nprev:', prev_output)\n",
    "\n",
    "    #print('w. prev h -----')\n",
    "    wh = np.dot(prev_h, recurrent_kernel)\n",
    "    wh = wh.astype(np.float32)\n",
    "    print(wh.shape)\n",
    "    pprint(wh)\n",
    "\n",
    "    print('h --------')\n",
    "    h = tanh(wh + wi)\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "\n",
    "    print('output ---')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h\\t\\t:', prev_h)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.376847Z",
     "start_time": "2018-06-23T08:21:06.310124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer_1/kernel:0' shape=(5, 1) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_1/recurrent_kernel:0' shape=(1, 1) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_1/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (SimpleRNN)        [(None, 3, 1), (None, 1)] 7         \n",
      "_________________________________________________________________\n",
      "Output_layer (Activation)    (None, 3, 1)              0         \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "#units = 3\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = SimpleRNN(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "_output_layer = Activation('softmax', name='Output_layer')\n",
    "_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "#model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model = Model(inputs=_input_layer, outputs=[_outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.381980Z",
     "start_time": "2018-06-23T08:21:06.378755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 3, 1), (None, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.397016Z",
     "start_time": "2018-06-23T08:21:06.383439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.436023Z",
     "start_time": "2018-06-23T08:21:06.398062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]]\n",
      "[[-0.05]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.461152Z",
     "start_time": "2018-06-23T08:21:06.437161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]\n",
      " [0.5]\n",
      " [0.6]]\n",
      "[[-0.05]]\n",
      "[0.]\n",
      "inputs\n",
      "(5,)\n",
      "array([0.3, 0.8, 0.1, 0.7, 0.2], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.81], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.], dtype=float32)\n",
      "(1,)\n",
      "array([-0.], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.3 0.8 0.1 0.7 0.2]\n",
      "prev h\t\t: [0.]\n",
      "h\t\t: [0.66959035]\n",
      "output(0)\t: [0.66959035]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(5,)\n",
      "array([0.7, 0.6, 0.2, 0.4, 0.5], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.90000004], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.66959035], dtype=float32)\n",
      "(1,)\n",
      "array([-0.03347952], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.7 0.6 0.2 0.4 0.5]\n",
      "prev h\t\t: [0.66959035]\n",
      "h\t\t: [0.699602]\n",
      "output(1)\t: [0.699602]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(5,)\n",
      "array([0.4, 0. , 0.9, 0.3, 0.4], dtype=float32)\n",
      "input ---------\n",
      "(1,)\n",
      "array([0.83], dtype=float32)\n",
      "prev h --------\n",
      "(1,)\n",
      "array([0.699602], dtype=float32)\n",
      "(1,)\n",
      "array([-0.0349801], dtype=float32)\n",
      "h --------\n",
      "(1,)\n",
      "array([0.6612434], dtype=float32)\n",
      "output ---\n",
      "(1,)\n",
      "array([0.6612434], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4 0.  0.9 0.3 0.4]\n",
      "prev h\t\t: [0.699602]\n",
      "h\t\t: [0.6612434]\n",
      "output(2)\t: [0.6612434]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[[0.66959035],\n",
      "        [0.699602  ],\n",
      "        [0.6612434 ]]], dtype=float32), array([[0.6612434]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[[1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), array([[0.66124344]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = True\n",
    "return_state = True\n",
    "\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('input ---------')\n",
    "    wi = np.dot(inputs, kernel) + bias\n",
    "    wi = wi.astype(np.float32)\n",
    "    print(wi.shape)\n",
    "    pprint(wi)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h]\n",
    "    prev_h = states[0]\n",
    "    print('prev h --------')\n",
    "    print(prev_h.shape)\n",
    "    pprint(prev_h)\n",
    "    #print('\\nprev:', prev_output)\n",
    "\n",
    "    #print('w. prev h -----')\n",
    "    wh = np.dot(prev_h, recurrent_kernel)\n",
    "    wh = wh.astype(np.float32)\n",
    "    print(wh.shape)\n",
    "    pprint(wh)\n",
    "\n",
    "    print('h --------')\n",
    "    h = tanh(wh + wi)\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "\n",
    "    print('output ---')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "\n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h\\t\\t:', prev_h)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.464227Z",
     "start_time": "2018-06-23T08:21:06.462371Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "from scipy.misc import derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.472732Z",
     "start_time": "2018-06-23T08:21:06.465209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0.2, Y: -0.32, Z: 0.196\n"
     ]
    }
   ],
   "source": [
    "x = .2\n",
    "f = lambda x: -.3*x + .1\n",
    "g = lambda x: .4*x - .4\n",
    "\n",
    "y = g(x)\n",
    "z = f(g(x))\n",
    "\n",
    "print('X: %s, Y: %s, Z: %s' % (x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.481725Z",
     "start_time": "2018-06-23T08:21:06.473720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivative(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.489832Z",
     "start_time": "2018-06-23T08:21:06.482690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 5, Y: 74\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "f = lambda x: 3*(x**2) - 1\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "print('X: %s, Y: %s' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.501734Z",
     "start_time": "2018-06-23T08:21:06.490823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivative(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.509648Z",
     "start_time": "2018-06-23T08:21:06.502799Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmo(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.518561Z",
     "start_time": "2018-06-23T08:21:06.510808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odeint(f, y, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LSTM Code Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.527239Z",
     "start_time": "2018-06-23T08:21:06.519710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 1)\n",
      "array([[[0.2],\n",
      "        [0.5],\n",
      "        [0.4]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "units = 1\n",
    "input_dim = 1\n",
    "\n",
    "if input_dim == 1:\n",
    "    data_X = np.array([[.2],\n",
    "                       [.5],\n",
    "                       [.4]\n",
    "                      ]).reshape(1, 3, 1).astype('float32')\n",
    "else:\n",
    "    data_X = np.array([[.2, .1],\n",
    "                       [.5, .3],\n",
    "                       [.4, 0.]\n",
    "                      ]).reshape(1, 3, 2).astype('float32')\n",
    "\n",
    "print(data_X.shape)\n",
    "pprint(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.651983Z",
     "start_time": "2018-06-23T08:21:06.528358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer_2/kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_2/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_2/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (LSTM)             [(None, 1), (None, 1), (N 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = LSTM(units, return_sequences=False, return_state=True, name='RNN_layer')\n",
    "outputs, state_h, state_c = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, state_h, state_c])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.689111Z",
     "start_time": "2018-06-23T08:21:06.653070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00122416  0.15380776  0.8817742  -0.2496478 ]]\n",
      "[[-0.67465925 -0.6976076   0.23320703 -0.06158761]]\n",
      "[0. 1. 0. 0.]\n",
      "Kernel_shape: (1, 4)\n",
      "Recurrent_Kernel_shape: (1, 4)\n",
      "Bias_shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "print('Kernel_shape:', kernel.shape)\n",
    "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
    "print('Bias_shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.707499Z",
     "start_time": "2018-06-23T08:21:06.690569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5]]\n",
      "[[-0.05 -0.04 -0.03 -0.02]]\n",
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['i', 'f', 'c', 'o']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.745607Z",
     "start_time": "2018-06-23T08:21:06.709098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5]]\n",
      "[[-0.05 -0.04 -0.03 -0.02]]\n",
      "[0. 0. 0. 0.]\n",
      "inputs\n",
      "(1,)\n",
      "array([0.2], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.], dtype=float32), array([0.], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.02582867], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.02582867], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.2]\n",
      "prev h, prev_c\t: [0.] [0.]\n",
      "h, c\t\t: [0.02582867] [0.26519388]\n",
      "output(0)\t: [0.02582867]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(1,)\n",
      "array([0.5], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.02582867], dtype=float32), array([0.26519388], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.09924313], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.09924313], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.5]\n",
      "prev h, prev_c\t: [0.02582867] [0.26519388]\n",
      "h, c\t\t: [0.09924313] [0.4308287]\n",
      "output(1)\t: [0.09924313]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(1,)\n",
      "array([0.4], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.09924313], dtype=float32), array([0.4308287], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.09149212], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.09149212], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4]\n",
      "prev h, prev_c\t: [0.09924313] [0.4308287]\n",
      "h, c\t\t: [0.09149212] [0.5075951]\n",
      "output(2)\t: [0.09149212]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[0.09149212]], dtype=float32), array([[[0.09149212],\n",
      "        [0.5075951 ]]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[0.07799154]], dtype=float32), array([[0.07799154]], dtype=float32), array([[0.1455198]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = False\n",
    "return_state = True\n",
    "\n",
    "\"\"\"\n",
    "activation = np.tanh\n",
    "recurrent_activation = sigmoid\n",
    "\"\"\"\n",
    "\n",
    "kernel_i = kernel[:,           :units * 1]\n",
    "kernel_f = kernel[:, units * 1: units * 2]\n",
    "kernel_c = kernel[:, units * 2: units * 3]\n",
    "kernel_o = kernel[:, units * 3:]\n",
    "\n",
    "recurrent_kernel_i = recurrent_kernel[:,          : units * 1]\n",
    "recurrent_kernel_f = recurrent_kernel[:, units * 1: units * 2]\n",
    "recurrent_kernel_c = recurrent_kernel[:, units * 2: units * 3]\n",
    "recurrent_kernel_o = recurrent_kernel[:, units * 3:]\n",
    "\n",
    "bias_i = bias[         : units * 1]\n",
    "bias_f = bias[units * 1: units * 2]\n",
    "bias_c = bias[units * 2: units * 3]\n",
    "bias_o = bias[units * 3:          ]\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('x -----------')\n",
    "    print('dropout(input) time')\n",
    "    x_i = np.dot(inputs, kernel_i) + bias_i\n",
    "    x_f = np.dot(inputs, kernel_f) + bias_f\n",
    "    x_c = np.dot(inputs, kernel_c) + bias_c\n",
    "    x_o = np.dot(inputs, kernel_o) + bias_o\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)] * 2\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h, c]\n",
    "    h_tm1 = prev_h = states[0]\n",
    "    c_tm1 = prev_c = states[1]\n",
    "    print('prev --------')\n",
    "    print(prev_h.shape, prev_c.shape)\n",
    "    pprint((prev_h, prev_c))\n",
    "    #print('\\nprev:', prev_output)\n",
    "    \n",
    "    print('gate --------')\n",
    "    print('recurrent dropout(h_tm1) time')\n",
    "    i = sigmoid(x_i + np.dot(h_tm1, recurrent_kernel_i))\n",
    "    f = sigmoid(x_f + np.dot(h_tm1, recurrent_kernel_f))\n",
    "    c = f * c_tm1 +\\\n",
    "        i * sigmoid(x_c + np.dot(h_tm1, recurrent_kernel_c))\n",
    "    o = np.tanh(x_o + np.dot(h_tm1, recurrent_kernel_o))\n",
    "    \n",
    "    h = o * np.tanh(c)\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h, prev_c\\t:', prev_h, prev_c)\n",
    "    print('h, c\\t\\t:', h, c)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "\n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = [h, c]\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.864961Z",
     "start_time": "2018-06-23T08:21:06.746699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer_3/kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_3/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_3/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (LSTM)             [(None, 3, 1), (None, 1), 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = LSTM(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
    "outputs, state_h, state_c = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, state_h, state_c])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.926079Z",
     "start_time": "2018-06-23T08:21:06.865985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5]]\n",
      "[[-0.05 -0.04 -0.03 -0.02]]\n",
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['i', 'f', 'c', 'o']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.968803Z",
     "start_time": "2018-06-23T08:21:06.927386Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5]]\n",
      "[[-0.05 -0.04 -0.03 -0.02]]\n",
      "[0. 0. 0. 0.]\n",
      "inputs\n",
      "(1,)\n",
      "array([0.2], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.], dtype=float32), array([0.], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.02582867], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.02582867], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.2]\n",
      "prev h, prev_c\t: [0.] [0.]\n",
      "h, c\t\t: [0.02582867] [0.26519388]\n",
      "output(0)\t: [0.02582867]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(1,)\n",
      "array([0.5], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.02582867], dtype=float32), array([0.26519388], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.09924313], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.09924313], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.5]\n",
      "prev h, prev_c\t: [0.02582867] [0.26519388]\n",
      "h, c\t\t: [0.09924313] [0.4308287]\n",
      "output(1)\t: [0.09924313]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(1,)\n",
      "array([0.4], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(1,) (1,)\n",
      "(array([0.09924313], dtype=float32), array([0.4308287], dtype=float32))\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(1,)\n",
      "array([0.09149212], dtype=float32)\n",
      "output ------\n",
      "(1,)\n",
      "array([0.09149212], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4]\n",
      "prev h, prev_c\t: [0.09924313] [0.4308287]\n",
      "h, c\t\t: [0.09149212] [0.5075951]\n",
      "output(2)\t: [0.09149212]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[[0.02582867],\n",
      "        [0.09924313],\n",
      "        [0.09149212]]], dtype=float32), array([[[0.09149212],\n",
      "        [0.5075951 ]]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[[0.02107628],\n",
      "        [0.06771449],\n",
      "        [0.07799154]]], dtype=float32), array([[0.07799154]], dtype=float32), array([[0.1455198]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = True\n",
    "return_state = True\n",
    "\n",
    "\"\"\"\n",
    "activation = np.tanh\n",
    "recurrent_activation = sigmoid\n",
    "\"\"\"\n",
    "\n",
    "kernel_i = kernel[:,           :units * 1]\n",
    "kernel_f = kernel[:, units * 1: units * 2]\n",
    "kernel_c = kernel[:, units * 2: units * 3]\n",
    "kernel_o = kernel[:, units * 3:]\n",
    "\n",
    "recurrent_kernel_i = recurrent_kernel[:,          : units * 1]\n",
    "recurrent_kernel_f = recurrent_kernel[:, units * 1: units * 2]\n",
    "recurrent_kernel_c = recurrent_kernel[:, units * 2: units * 3]\n",
    "recurrent_kernel_o = recurrent_kernel[:, units * 3:]\n",
    "\n",
    "bias_i = bias[         : units * 1]\n",
    "bias_f = bias[units * 1: units * 2]\n",
    "bias_c = bias[units * 2: units * 3]\n",
    "bias_o = bias[units * 3:          ]\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('x -----------')\n",
    "    print('dropout(input) time')\n",
    "    x_i = np.dot(inputs, kernel_i) + bias_i\n",
    "    x_f = np.dot(inputs, kernel_f) + bias_f\n",
    "    x_c = np.dot(inputs, kernel_c) + bias_c\n",
    "    x_o = np.dot(inputs, kernel_o) + bias_o\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)] * 2\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h, c]\n",
    "    h_tm1 = prev_h = states[0]\n",
    "    c_tm1 = prev_c = states[1]\n",
    "    print('prev --------')\n",
    "    print(prev_h.shape, prev_c.shape)\n",
    "    pprint((prev_h, prev_c))\n",
    "    #print('\\nprev:', prev_output)\n",
    "    \n",
    "    print('gate --------')\n",
    "    print('recurrent dropout(h_tm1) time')\n",
    "    i = sigmoid(x_i + np.dot(h_tm1, recurrent_kernel_i))\n",
    "    f = sigmoid(x_f + np.dot(h_tm1, recurrent_kernel_f))\n",
    "    c = f * c_tm1 +\\\n",
    "        i * sigmoid(x_c + np.dot(h_tm1, recurrent_kernel_c))\n",
    "    o = np.tanh(x_o + np.dot(h_tm1, recurrent_kernel_o))\n",
    "    \n",
    "    h = o * np.tanh(c)\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h, prev_c\\t:', prev_h, prev_c)\n",
    "    print('h, c\\t\\t:', h, c)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "\n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = [h, c]\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GRU Code Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:06.973515Z",
     "start_time": "2018-06-23T08:21:06.969984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "array([[[0.2, 0.1],\n",
      "        [0.5, 0.3],\n",
      "        [0.4, 0. ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "units = 2\n",
    "input_dim = 2\n",
    "\n",
    "if input_dim == 1:\n",
    "    data_X = np.array([[.2],\n",
    "                       [.5],\n",
    "                       [.4]\n",
    "                      ]).reshape(1, 3, 1).astype('float32')\n",
    "else:\n",
    "    data_X = np.array([[.2, .1],\n",
    "                       [.5, .3],\n",
    "                       [.4, 0.]\n",
    "                      ]).reshape(1, 3, 2).astype('float32')\n",
    "\n",
    "print(data_X.shape)\n",
    "pprint(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.109688Z",
     "start_time": "2018-06-23T08:21:06.974525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer_4/kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_4/recurrent_kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_4/bias:0' shape=(6,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (GRU)              [(None, 2), (None, 2)]    30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = GRU(units, return_sequences=False, return_state=True, name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.161460Z",
     "start_time": "2018-06-23T08:21:07.110744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7015311   0.08663237  0.01490903 -0.5300734   0.16394049 -0.7903858 ]\n",
      " [ 0.45310313 -0.06462902  0.7931908   0.18173534 -0.04084522 -0.55416363]]\n",
      "[[-0.5284298  -0.01888672  0.67646074 -0.2728485   0.05823601  0.43007952]\n",
      " [-0.22994931  0.15907124 -0.06359684 -0.27196684 -0.8899605  -0.22755088]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Kernel_shape: (2, 6)\n",
      "Recurrent_Kernel_shape: (2, 6)\n",
      "Bias_shape: (6,)\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "print('Kernel_shape:', kernel.shape)\n",
    "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
    "print('Bias_shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.185348Z",
     "start_time": "2018-06-23T08:21:07.162597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
      " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
      "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
      " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
      "[0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['z', 'r', 'h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.227954Z",
     "start_time": "2018-06-23T08:21:07.186456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
      " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
      "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
      " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "inputs\n",
      "(2,)\n",
      "array([0.2, 0.1], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0., 0.], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.2 0.1]\n",
      "prev h\t\t: [0. 0.]\n",
      "h\t\t: [0.11069148 0.12194498]\n",
      "output(0)\t: [0.11069148 0.12194498]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(2,)\n",
      "array([0.5, 0.3], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.5 0.3]\n",
      "prev h\t\t: [0.11069148 0.12194498]\n",
      "h\t\t: [0.3070247  0.32504663]\n",
      "output(1)\t: [0.3070247  0.32504663]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(2,)\n",
      "array([0.4, 0. ], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.2784692, 0.3089273], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.2784692, 0.3089273], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4 0. ]\n",
      "prev h\t\t: [0.3070247  0.32504663]\n",
      "h\t\t: [0.2784692 0.3089273]\n",
      "output(2)\t: [0.2784692 0.3089273]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[0.2784692, 0.3089273]], dtype=float32), array([[0.2784692, 0.3089273]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[0.27963528, 0.31039596]], dtype=float32), array([[0.27963528, 0.31039596]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = False\n",
    "return_state = True\n",
    "\n",
    "\"\"\"\n",
    "activation = np.tanh\n",
    "recurrent_activation = sigmoid\n",
    "\"\"\"\n",
    "\n",
    "kernel_z = kernel[:,          : units * 1]\n",
    "kernel_r = kernel[:, units * 1: units * 2]\n",
    "kernel_h = kernel[:, units * 2:]\n",
    "\n",
    "recurrent_kernel_z = recurrent_kernel[:,          : units * 1]\n",
    "recurrent_kernel_r = recurrent_kernel[:, units * 1: units * 2]\n",
    "recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "\n",
    "bias_z = bias[         : units * 1]\n",
    "bias_r = bias[units    : units * 2]\n",
    "bias_h = bias[units * 2:]\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('x -----------')\n",
    "    print('dropout(input) time')\n",
    "    x_z = np.dot(inputs, kernel_z) + bias_z\n",
    "    x_r = np.dot(inputs, kernel_r) + bias_r\n",
    "    x_h = np.dot(inputs, kernel_h) + bias_h\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h]\n",
    "    h_tm1 = prev_h = states[0]\n",
    "    print('prev --------')\n",
    "    print(prev_h.shape)\n",
    "    pprint(prev_h)\n",
    "    #print('\\nprev:', prev_output)\n",
    "    \n",
    "    print('gate --------')\n",
    "    print('recurrent dropout(h_tm1) time')\n",
    "    z = sigmoid(x_z + np.dot(h_tm1, recurrent_kernel_z))\n",
    "    r = sigmoid(x_r + np.dot(h_tm1, recurrent_kernel_r))\n",
    "    hh = np.tanh(x_h + np.dot(h_tm1, recurrent_kernel_h))\n",
    "    \n",
    "    h = z * h_tm1 + (1 - z) * hh\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h\\t\\t:', prev_h)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.324573Z",
     "start_time": "2018-06-23T08:21:07.229086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'RNN_layer_5/kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_5/recurrent_kernel:0' shape=(2, 6) dtype=float32_ref>,\n",
      " <tf.Variable 'RNN_layer_5/bias:0' shape=(6,) dtype=float32_ref>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "RNN_layer (GRU)              [(None, 3, 2), (None, 2)] 30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = units\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = GRU(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.404804Z",
     "start_time": "2018-06-23T08:21:07.325615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
      " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
      "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
      " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
      "[0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weight = ['z', 'r', 'h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.446178Z",
     "start_time": "2018-06-23T08:21:07.406026Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.4 0.5 0.6 0.7]\n",
      " [0.8 0.9 1.  1.1 1.2 1.3]]\n",
      "[[-0.05 -0.04 -0.03 -0.02 -0.01  0.  ]\n",
      " [ 0.01  0.02  0.03  0.04  0.05  0.06]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "inputs\n",
      "(2,)\n",
      "array([0.2, 0.1], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0., 0.], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "\n",
      "step (0)=====================================\n",
      "input\t\t: [0.2 0.1]\n",
      "prev h\t\t: [0. 0.]\n",
      "h\t\t: [0.11069148 0.12194498]\n",
      "output(0)\t: [0.11069148 0.12194498]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(2,)\n",
      "array([0.5, 0.3], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0.11069148, 0.12194498], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "\n",
      "step (1)=====================================\n",
      "input\t\t: [0.5 0.3]\n",
      "prev h\t\t: [0.11069148 0.12194498]\n",
      "h\t\t: [0.3070247  0.32504663]\n",
      "output(1)\t: [0.3070247  0.32504663]\n",
      "=============================================\n",
      "\n",
      "inputs\n",
      "(2,)\n",
      "array([0.4, 0. ], dtype=float32)\n",
      "x -----------\n",
      "dropout(input) time\n",
      "prev --------\n",
      "(2,)\n",
      "array([0.3070247 , 0.32504663], dtype=float32)\n",
      "gate --------\n",
      "recurrent dropout(h_tm1) time\n",
      "(2,)\n",
      "array([0.2784692, 0.3089273], dtype=float32)\n",
      "output ------\n",
      "(2,)\n",
      "array([0.2784692, 0.3089273], dtype=float32)\n",
      "\n",
      "step (2)=====================================\n",
      "input\t\t: [0.4 0. ]\n",
      "prev h\t\t: [0.3070247  0.32504663]\n",
      "h\t\t: [0.2784692 0.3089273]\n",
      "output(2)\t: [0.2784692 0.3089273]\n",
      "=============================================\n",
      "\n",
      "\n",
      "Result: [Output, State]\n",
      "\n",
      "=== Numpy ===\n",
      "[array([[[0.11069148, 0.12194498],\n",
      "        [0.3070247 , 0.32504663],\n",
      "        [0.2784692 , 0.3089273 ]]], dtype=float32), array([[0.2784692, 0.3089273]], dtype=float32)]\n",
      "\n",
      "=== Keras ===\n",
      "[array([[[0.11209598, 0.12390368],\n",
      "        [0.31483552, 0.33543658],\n",
      "        [0.27963528, 0.31039596]]], dtype=float32), array([[0.27963528, 0.31039596]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = True\n",
    "return_state = True\n",
    "\n",
    "\"\"\"\n",
    "activation = np.tanh\n",
    "recurrent_activation = sigmoid\n",
    "\"\"\"\n",
    "\n",
    "kernel_z = kernel[:,          : units * 1]\n",
    "kernel_r = kernel[:, units * 1: units * 2]\n",
    "kernel_h = kernel[:, units * 2:]\n",
    "\n",
    "recurrent_kernel_z = recurrent_kernel[:,          : units * 1]\n",
    "recurrent_kernel_r = recurrent_kernel[:, units * 1: units * 2]\n",
    "recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "\n",
    "bias_z = bias[         : units * 1]\n",
    "bias_r = bias[units    : units * 2]\n",
    "bias_h = bias[units * 2:]\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('x -----------')\n",
    "    print('dropout(input) time')\n",
    "    x_z = np.dot(inputs, kernel_z) + bias_z\n",
    "    x_r = np.dot(inputs, kernel_r) + bias_r\n",
    "    x_h = np.dot(inputs, kernel_h) + bias_h\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h]\n",
    "    h_tm1 = prev_h = states[0]\n",
    "    print('prev --------')\n",
    "    print(prev_h.shape)\n",
    "    pprint(prev_h)\n",
    "    #print('\\nprev:', prev_output)\n",
    "    \n",
    "    print('gate --------')\n",
    "    print('recurrent dropout(h_tm1) time')\n",
    "    z = sigmoid(x_z + np.dot(h_tm1, recurrent_kernel_z))\n",
    "    r = sigmoid(x_r + np.dot(h_tm1, recurrent_kernel_r))\n",
    "    hh = np.tanh(x_h + np.dot(h_tm1, recurrent_kernel_h))\n",
    "    \n",
    "    h = z * h_tm1 + (1 - z) * hh\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('input\\t\\t:', inputs)\n",
    "    print('prev h\\t\\t:', prev_h)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RNN with Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.451966Z",
     "start_time": "2018-06-23T08:21:07.447412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 17], [44, 3], [6, 10], [5, 3], [15], [40], [49, 10], [13, 44], [49, 3], [14, 48, 17, 46]]\n",
      "[[23 17  0  0]\n",
      " [44  3  0  0]\n",
      " [ 6 10  0  0]\n",
      " [ 5  3  0  0]\n",
      " [15  0  0  0]\n",
      " [40  0  0  0]\n",
      " [49 10  0  0]\n",
      " [13 44  0  0]\n",
      " [49  3  0  0]\n",
      " [14 48 17 46]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.463804Z",
     "start_time": "2018-06-23T08:21:07.453041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.527841Z",
     "start_time": "2018-06-23T08:21:07.464861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 4, 1)              10        \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(SimpleRNN(1, return_sequences=True, return_state=False))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.531163Z",
     "start_time": "2018-06-23T08:21:07.528904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.539599Z",
     "start_time": "2018-06-23T08:21:07.532139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.680257Z",
     "start_time": "2018-06-23T08:21:07.540647Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected simple_rnn_1 to have 3 dimensions, but got array with shape (10, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-06cfc31c8474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected simple_rnn_1 to have 3 dimensions, but got array with shape (10, 1)"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.680782Z",
     "start_time": "2018-06-23T08:21:05.910Z"
    }
   },
   "outputs": [],
   "source": [
    "units = 2\n",
    "input_dim = 2\n",
    "\n",
    "if input_dim == 1:\n",
    "    data_X = np.array([[.3],\n",
    "                       [.7],\n",
    "                       [.4]\n",
    "                      ]).reshape(1, 3, 1).astype('float32')\n",
    "else:\n",
    "    data_X = np.array([[.3, .8],\n",
    "                       [.7, .6],\n",
    "                       [.4, 0.]\n",
    "                      ]).reshape(1, 3, 2).astype('float32')\n",
    "\n",
    "print(data_X.shape)\n",
    "pprint(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.681397Z",
     "start_time": "2018-06-23T08:21:05.977Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units = units\n",
    "#init_state = np.zeros((1, units), dtype=np.float32)\n",
    "#init_state = [K.zeros(init_state.shape, dtype=np.float32, name=None)]\n",
    "\n",
    "if len(data_X.shape) == 3:\n",
    "    n_sample, seq_len, input_dim = data_X.shape\n",
    "else:\n",
    "    n_sample, seq_len, input_dim, _ = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = SimpleRNN(units, return_sequences=False,\n",
    "                       return_state=True,\n",
    "                       name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.682038Z",
     "start_time": "2018-06-23T08:21:05.991Z"
    }
   },
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.682695Z",
     "start_time": "2018-06-23T08:21:05.995Z"
    }
   },
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Session Error Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.683320Z",
     "start_time": "2018-06-23T08:21:06.072Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.get_weights()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.683965Z",
     "start_time": "2018-06-23T08:21:06.080Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel, recurrent_kernel, bias = _rnn_layer.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "print('Kernel_shape:', kernel.shape)\n",
    "print('Recurrent_Kernel_shape:', recurrent_kernel.shape)\n",
    "print('Bias_shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.684645Z",
     "start_time": "2018-06-23T08:21:06.085Z"
    }
   },
   "outputs": [],
   "source": [
    "_rnn_layer.get_initial_state(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.685264Z",
     "start_time": "2018-06-23T08:21:06.088Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = ['h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight))\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight))\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), )\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.685836Z",
     "start_time": "2018-06-23T08:21:06.091Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = False\n",
    "return_state = True\n",
    "\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('h -----------')\n",
    "    h = np.dot(inputs, kernel) + bias\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [h]\n",
    "    prev_output = states[0]\n",
    "    print('prev --------')\n",
    "    print(prev_output.shape)\n",
    "    pprint(prev_output)\n",
    "    #print('\\nprev:', prev_output)\n",
    "\n",
    "    print('a -----------')\n",
    "    a = np.dot(prev_output, recurrent_kernel)\n",
    "    a = a.astype(np.float32)\n",
    "    print(a.shape)\n",
    "    pprint(a)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h + a\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('prev\\t\\t:', prev_output)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.686508Z",
     "start_time": "2018-06-23T08:21:06.174Z"
    }
   },
   "outputs": [],
   "source": [
    "units = units\n",
    "n_sample, seq_len, input_dim = data_X.shape\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "_input_layer = Input(shape=(seq_len, input_dim), name='Input_layer')\n",
    "\n",
    "_rnn_layer = SimpleRNN(units, return_sequences=True, return_state=True, name='RNN_layer')\n",
    "outputs, states = _rnn_layer(_input_layer)\n",
    "\n",
    "#_output_layer = Dense(1, activation='softmax', name='Output_layer')\n",
    "#_output_layer = Activation('softmax', name='Output_layer')\n",
    "#_outputs = _output_layer(outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs=_input_layer, outputs=[outputs, states])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "pprint(model.weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.687177Z",
     "start_time": "2018-06-23T08:21:06.182Z"
    }
   },
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.687732Z",
     "start_time": "2018-06-23T08:21:06.186Z"
    }
   },
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.688376Z",
     "start_time": "2018-06-23T08:21:06.190Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = ['h']\n",
    "\n",
    "my_kernel = (np.arange(input_dim * units* len(weight)) * .1 + .2).reshape(input_dim, units* len(weight)).astype(np.float32)\n",
    "my_recurrent_kernel = (np.arange(units * units * len(weight)) * .01 - .05).reshape(units, units * len(weight)).astype(np.float32)\n",
    "my_bias = np.zeros(units * len(weight)).reshape(units * len(weight), ).astype(np.float32)\n",
    "\n",
    "print(my_kernel, my_recurrent_kernel, my_bias, sep='\\n')\n",
    "\n",
    "_rnn_layer.set_weights([my_kernel, my_recurrent_kernel, my_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T08:21:07.689006Z",
     "start_time": "2018-06-23T08:21:06.194Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kernel, recurrent_kernel, bias = model.get_weights()\n",
    "print(kernel, recurrent_kernel, bias, sep='\\n')\n",
    "\n",
    "return_sequence = True\n",
    "return_state = True\n",
    "\n",
    "\n",
    "sequence = []\n",
    "for _ in range(len(data_X[0])):\n",
    "    \n",
    "    inputs = data_X[0][_]\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    print('inputs')\n",
    "    print(inputs.shape)\n",
    "    pprint(inputs)\n",
    "\n",
    "    print('h -----------')\n",
    "    h = np.dot(inputs, kernel) + bias\n",
    "    h = h.astype(np.float32)\n",
    "    print(h.shape)\n",
    "    pprint(h)\n",
    "    #print('\\nh:', h)\n",
    "\n",
    "    if _ == 0:\n",
    "        initial_state = [np.zeros(units, dtype=np.float32)]\n",
    "        states = initial_state\n",
    "    else:\n",
    "        states = [output]\n",
    "    prev_output = states[0]\n",
    "    print('prev --------')\n",
    "    print(prev_output.shape)\n",
    "    pprint(prev_output)\n",
    "    #print('\\nprev:', prev_output)\n",
    "\n",
    "    print('a -----------')\n",
    "    a = np.dot(prev_output, recurrent_kernel)\n",
    "    a = a.astype(np.float32)\n",
    "    print(a.shape)\n",
    "    pprint(a)\n",
    "\n",
    "    print('output ------')\n",
    "    output = h + a\n",
    "    output = output.astype(np.float32)\n",
    "    print(output.shape)\n",
    "    pprint(output)\n",
    "    \n",
    "    \n",
    "    print('\\nstep (%s)' % _ + '='*37)\n",
    "    print('h\\t\\t:', h)\n",
    "    print('prev\\t\\t:', prev_output)\n",
    "    print('output(%s)\\t: %s' % (_, output))\n",
    "    print('='*45 + '\\n')\n",
    "    \n",
    "    sequence.append(output)\n",
    "    \n",
    "    if return_sequence:\n",
    "        result = sequence\n",
    "    else:\n",
    "        result = sequence[-1]\n",
    "    \n",
    "    if return_state:\n",
    "        state = output\n",
    "    else:\n",
    "        state = []\n",
    "        \n",
    "        \n",
    "result = np.expand_dims(np.stack(result), axis=0)\n",
    "state = np.expand_dims(np.array(state), axis=0)\n",
    "\n",
    "print('\\nResult: [Output, State]')\n",
    "print('\\n=== Numpy ===')\n",
    "print([result, state])\n",
    "print('\\n=== Keras ===')\n",
    "print(model.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow: Python3.6 (conda env)",
   "language": "python",
   "name": "tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "644px",
    "left": "0px",
    "right": "810.4px",
    "top": "159px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": 16,
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
