{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Network-Learning-Parameter\" data-toc-modified-id=\"Network-Learning-Parameter-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Network Learning Parameter</a></div><div class=\"lev1 toc-item\"><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Data-for-Machine-Translation\" data-toc-modified-id=\"Data-for-Machine-Translation-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data for Machine Translation</a></div><div class=\"lev1 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev4 toc-item\"><a href=\"#Run\" data-toc-modified-id=\"Run-3001\"><span class=\"toc-item-num\">3.0.0.1&nbsp;&nbsp;</span>Run</a></div><div class=\"lev3 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-301\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev4 toc-item\"><a href=\"#Run\" data-toc-modified-id=\"Run-3011\"><span class=\"toc-item-num\">3.0.1.1&nbsp;&nbsp;</span>Run</a></div><div class=\"lev1 toc-item\"><a href=\"#RNNCell-Wrapper\" data-toc-modified-id=\"RNNCell-Wrapper-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>RNNCell Wrapper</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-401\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#RNN-Wrapper\" data-toc-modified-id=\"RNN-Wrapper-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>RNN Wrapper</a></div><div class=\"lev2 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev2 toc-item\"><a href=\"#fullrnn\" data-toc-modified-id=\"fullrnn-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>fullrnn</a></div><div class=\"lev2 toc-item\"><a href=\"#ATTRNNCell\" data-toc-modified-id=\"ATTRNNCell-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>ATTRNNCell</a></div><div class=\"lev2 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev3 toc-item\"><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-631\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Modeling</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-632\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#ATTRNN-2-:-States\" data-toc-modified-id=\"ATTRNN-2-:-States-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>ATTRNN 2 : States</a></div><div class=\"lev2 toc-item\"><a href=\"#fullrnn\" data-toc-modified-id=\"fullrnn-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>fullrnn</a></div><div class=\"lev2 toc-item\"><a href=\"#RNNCell-Wrapper\" data-toc-modified-id=\"RNNCell-Wrapper-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>RNNCell Wrapper</a></div><div class=\"lev2 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev3 toc-item\"><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-731\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>Modeling</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-732\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#ATTRNN-Wrapper\" data-toc-modified-id=\"ATTRNN-Wrapper-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>ATTRNN Wrapper</a></div><div class=\"lev4 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-8001\"><span class=\"toc-item-num\">8.0.0.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#GRU-Decoder-with-Attention-(encoder:-return_sequence=True)\" data-toc-modified-id=\"GRU-Decoder-with-Attention-(encoder:-return_sequence=True)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>GRU Decoder with Attention (encoder: <code>return_sequence=True</code>)</a></div><div class=\"lev3 toc-item\"><a href=\"#MyGRUAttention-(Feed-Forward,-Not-Recurrent)\" data-toc-modified-id=\"MyGRUAttention-(Feed-Forward,-Not-Recurrent)-901\"><span class=\"toc-item-num\">9.0.1&nbsp;&nbsp;</span>MyGRUAttention (Feed-Forward, Not Recurrent)</a></div><div class=\"lev3 toc-item\"><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-902\"><span class=\"toc-item-num\">9.0.2&nbsp;&nbsp;</span>Modeling</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-903\"><span class=\"toc-item-num\">9.0.3&nbsp;&nbsp;</span>Training</a></div><div class=\"lev3 toc-item\"><a href=\"#Scoring\" data-toc-modified-id=\"Scoring-904\"><span class=\"toc-item-num\">9.0.4&nbsp;&nbsp;</span>Scoring</a></div><div class=\"lev3 toc-item\"><a href=\"#Testing\" data-toc-modified-id=\"Testing-905\"><span class=\"toc-item-num\">9.0.5&nbsp;&nbsp;</span>Testing</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import _object_list_uid\n",
    "from keras.utils.generic_utils import has_arg\n",
    "\n",
    "# Legacy support.\n",
    "from keras.legacy.layers import Recurrent\n",
    "from keras.legacy import interfaces\n",
    "from keras.layers import (SimpleRNNCell, SimpleRNN, RNN, LSTM, GRU,\n",
    "                          Input, Reshape, Dense, Flatten, Permute, Lambda,\n",
    "                          Embedding, RepeatVector, Activation,\n",
    "                          TimeDistributed, Bidirectional,\n",
    "                          dot, multiply, concatenate, merge)\n",
    "from keras.callbacks import Callback, LambdaCallback\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.weights = []\n",
    "        self.states = []\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.weights.append([{'begin_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.weights.append([{'end_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "        \n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[0].get_weights()))\n",
    "#print_outputs = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[2].output))\n",
    "#print_states = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[2].states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Learning Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = HIDDEN_SIZE = 64\n",
    "EPOCH_NUM = 100\n",
    "BATCH_SIZE = 256\n",
    "#GPU_NUM = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence to sequence example in Keras (character-level).\n",
    "This script demonstrates how to implement a basic character-level\n",
    "sequence-to-sequence model.  \n",
    "We apply it to translating\n",
    "short English sentences into short French sentences,\n",
    "character-by-character. Note that it is fairly unusual to\n",
    "do character-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "\n",
    "* Summary of the algorithm\n",
    "    - We start with input sequences from a domain (e.g. English sentences)\n",
    "        and correspding target sequences from another domain\n",
    "        (e.g. French sentences).\n",
    "    - An encoder LSTM turns input sequences to 2 state vectors\n",
    "        (we keep the last LSTM state and discard the outputs).\n",
    "    - A decoder LSTM is trained to turn the target sequences into\n",
    "        the same sequence but offset by one timestep in the future,\n",
    "        a training process called \"teacher forcing\" in this context.  \n",
    "        Is uses as initial state the state vectors from the encoder.\n",
    "        Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "        given `targets[...t]`, conditioned on the input sequence.\n",
    "    - In inference mode, when we want to decode unknown input sequences, we:\n",
    "        - Encode the input sequence into state vectors\n",
    "        - Start with a target sequence of size 1\n",
    "            (just the start-of-sequence character)\n",
    "        - Feed the state vectors and 1-char target sequence\n",
    "            to the decoder to produce predictions for the next character\n",
    "        - Sample the next character using these predictions\n",
    "            (we simply use argmax).\n",
    "        - Append the sampled character to the target sequence\n",
    "        - Repeat until we generate the end-of-sequence character or we\n",
    "            hit the character limit.\n",
    "* Data download\n",
    "    English to French sentence pairs.\n",
    "    http://www.manythings.org/anki/fra-eng.zip\n",
    "    Lots of neat sentence pairs datasets can be found at:\n",
    "    http://www.manythings.org/anki/\n",
    "\n",
    "* References\n",
    "    - Sequence to Sequence Learning with Neural Networks\n",
    "        https://arxiv.org/abs/1409.3215\n",
    "    - Learning Phrase Representations using\n",
    "        RNN Encoder-Decoder for Statistical Machine Translation\n",
    "        https://arxiv.org/abs/1406.1078\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_vocab</th>\n",
       "      <th>machine_vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KAKAUKA 14 1992</td>\n",
       "      <td>1992-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 JUN. 1999</td>\n",
       "      <td>1999-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.03.00</td>\n",
       "      <td>2000-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 Juni 1979</td>\n",
       "      <td>1979-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>फेब्रुवारी 1, 1988</td>\n",
       "      <td>1988-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          human_vocab machine_vocab\n",
       "0     KAKAUKA 14 1992    1992-12-14\n",
       "1         8 JUN. 1999    1999-06-08\n",
       "2            11.03.00    2000-03-11\n",
       "3        16 Juni 1979    1979-06-16\n",
       "4  फेब्रुवारी 1, 1988    1988-02-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NUM = 1000\n",
    "\n",
    "data = pd.read_csv('training.csv')\n",
    "data.columns = ['human_vocab', 'machine_vocab']\n",
    "\n",
    "data = data.iloc[:DATA_NUM, :]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_input_length\t: 43\n",
      "max_target_length\t: 10\n",
      "input_dict_length\t: 500\n",
      "target_dict_length\t: 11\n",
      "Input Array Shape\t: (1000, 43, 500)\n",
      "Target Array Shape\t: (1000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "input_ = data['human_vocab']\n",
    "target_ = data['machine_vocab']\n",
    "\n",
    "input_characters = set()\n",
    "[input_characters.add(char) for sentence in input_ for char in sentence]\n",
    "input_idx = {char:i for i, char in enumerate(input_characters)}\n",
    "input_dict = {i:char for i, char in enumerate(input_characters)}\n",
    "\n",
    "target_characters = set()\n",
    "[target_characters.add(char) for sentence in target_ for char in sentence]\n",
    "target_idx = {char:i for i, char in enumerate(target_characters)}\n",
    "target_dict = {i:char for i, char in enumerate(target_characters)}\n",
    "\n",
    "max_input_length = max(input_.apply(len))\n",
    "max_target_length = max(target_.apply(len))\n",
    "\n",
    "print(\"max_input_length\\t: %s\" % max_input_length)\n",
    "print(\"max_target_length\\t: %s\" % max_target_length)\n",
    "\n",
    "input_dict_length = len(input_dict)\n",
    "target_dict_length = len(target_dict)\n",
    "\n",
    "print(\"input_dict_length\\t: %s\" % input_dict_length)\n",
    "print(\"target_dict_length\\t: %s\" % target_dict_length)\n",
    "\n",
    "input_array = np.zeros((len(input_), max_input_length, input_dict_length), dtype='float32')\n",
    "target_array = np.zeros((len(target_), max_target_length, target_dict_length), dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_, target_)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        input_array[i, t, input_idx[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        target_array[i, t, target_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            target_array[i, t - 1, target_idx[char]] = 1.\n",
    "\n",
    "print(\"Input Array Shape\\t:\", input_array.shape)\n",
    "print(\"Target Array Shape\\t:\", target_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X (1000, 43, 500)\n",
      "data_Y (1000, 43, 11)\n"
     ]
    }
   ],
   "source": [
    "data_X = input_array\n",
    "data_Y = pad_sequences(target_array, max_input_length, padding='post')\n",
    "\n",
    "print('data_X', data_X.shape)\n",
    "print('data_Y', data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_many_to_many_1'](lstm_many_to_many_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_attention'](rnn_with_att.jpg)\n",
    "!['Overview of the Attention mechanism in an Encoder-Decoder setup'](lstm_attention_3.png)\n",
    "!['detail_lstm_attention'](detail_attentionmodel1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Attention Structure 1](https://blog.heuritech.com/2016/01/20/attention-mechanism/)  \n",
    "[Attention Structure 2](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)  \n",
    "[Attention Structure 3](https://medium.com/datalogue/attention-in-keras-1892773a4f22)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Embedding`:  \n",
    "> `(nb_words, vocab_size) x (vocab_size, embedding_dim) = (nb_words, embedding_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import _object_list_uid\n",
    "from keras.utils.generic_utils import has_arg\n",
    "\n",
    "# Legacy support.\n",
    "from keras.legacy.layers import Recurrent\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import (RNN,\n",
    "                          SimpleRNNCell,\n",
    "                          LSTMCell, LSTM,\n",
    "                          GRUCell, GRU,\n",
    "                          Layer, Input,\n",
    "                          Wrapper)\n",
    "\n",
    "from keras.layers.recurrent import *\n",
    "from keras import Model\n",
    "#from keras.layers.recurrent import (_generate_dropout_ones,\n",
    "#                                    _generate_dropout_mask)\n",
    "\n",
    "# %% ATTRNNCell ---------------------------------------------------------------\n",
    "\n",
    "class ATTRNNCell(Layer):\n",
    "\n",
    "    def __init__(self, units, attn_size, attn_length,\n",
    "                 activation='tanh',\n",
    "                 **kwargs):\n",
    "        super(ATTRNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self._attn_size = attn_size\n",
    "        self._attn_length = attn_length\n",
    "        self._state_size = self.units\n",
    "        #self.state_size = (self.units,\n",
    "        #                   self._attn_size,\n",
    "        #                   self._attn_size * self._attn_length)\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        #state_size = self.units\n",
    "\n",
    "        state_size_a = []\n",
    "        for state_size in (self.units, self.units):\n",
    "            state_size_a.append(state_size)\n",
    "\n",
    "        return state_size_a\n",
    "\n",
    "    #@state_size.setter\n",
    "    #def state_size(self, state_size):\n",
    "    #    self.state_size = state_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "        self.attn_kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                           initializer='uniform',\n",
    "                                           name='attn_kernel')\n",
    "\n",
    "    def call(self, inputs, states, constants=None):\n",
    "        prev_output = states[0]\n",
    "        attn_state = states[1:]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        output = self.activation(output)\n",
    "        return output, [output] + list(attn_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  [(None, 3, 2), (None, 2), 8         \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "bb = ATTRNNCell(2, 3, 3)\n",
    "cc = RNN(bb, return_sequences=True, return_state=True)(aa)\n",
    "#cc = LSTM(2, return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% ATTRNN Layer -------------------------------------------------------------\n",
    "\n",
    "class ATTRNN(RNN):\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        super(ATTRNN, self).__init__(cell, **kwargs)\n",
    "        #self.cell = cell\n",
    "        #self.return_sequences = return_sequences\n",
    "        #self.return_state = return_state\n",
    "        #self.go_backwards = go_backwards\n",
    "        #self.stateful = stateful\n",
    "        #self.unroll = unroll\n",
    "\n",
    "        #self.supports_masking = True\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        #self.state_spec = None\n",
    "        #self._states = None\n",
    "        #self.constants_spec = None\n",
    "        #self._num_constants = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        return super(ATTRNN, self).get_initial_state(inputs)\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(RNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(RNN, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(RNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        last_output, outputs, states = fullrnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "    \n",
    "    def get_attention(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "attrnn_2 (ATTRNN)            (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %% RUN ----------------------------------------------------------------------\n",
    "\n",
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "cc = ATTRNN(ATTRNNCell(2, 3, 3), return_sequences=True, return_state=True)(aa)\n",
    "#cc = LSTM(2, return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "attrnn_3 (ATTRNN)            (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %% RUN ----------------------------------------------------------------------\n",
    "\n",
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "bb = Input(tensor=aa)\n",
    "#cc = RNN(ATTRNNCell(2, 3, 3), return_sequences=True, return_state=True)(aa, constants=bb)\n",
    "cc = ATTRNN(LSTMCell(2), return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RNNCell Wrapper"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CellWrapper(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    A Cell Wrapper for Attention Mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        super(CellWrapper, self).__init__(*args, **kwargs)\n",
    "        self._cell = cell\n",
    "        self._cell.__init__(self.units, **kwargs)\n",
    "\n",
    "        self.trainable = self._cell.trainable\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._cell.output_size\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "#    @property\n",
    "#    def weights(self):\n",
    "#        return self._cell.weights + super(CellWrapper, self).weights\n",
    "\n",
    "#    @property\n",
    "#    def get_weights(self):\n",
    "#        #return self._cell.weights + self.weights\n",
    "#        #return self.weights\n",
    "#\n",
    "#        params = self.weights\n",
    "#        return K.batch_get_value(params)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self._cell.build(input_shape)\n",
    "        if self._cell.trainable:\n",
    "            self._trainable_weights.extend(self._cell.weights)\n",
    "        else:\n",
    "            self._non_trainable_weights.extend(self._cell.weights)\n",
    "\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kk = self.add_weight(shape=(input_dim, self.units,),\n",
    "                                  name='wrapper_kernel',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bb = self.add_weight(shape=(self.units,),\n",
    "                                  name='wrapper_bias',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        \"\"\"\n",
    "        self.kernel\n",
    "        self.recurrent_kernel\n",
    "\n",
    "        \"\"\"\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        new_inputs, new_states = self._cell.call(inputs, states,\n",
    "                                                 training=training)\n",
    "\n",
    "        new_inputs = K.dot(new_inputs, self.kk)\n",
    "        new_inputs = K.bias_add(new_inputs, self.bb)\n",
    "\n",
    "        return new_inputs, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellWrapper(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    A Cell Wrapper for Attention Mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        super(CellWrapper, self).__init__(*args, **kwargs)\n",
    "        self.cell = cell\n",
    "        self.cell.__init__(self.units, **kwargs)\n",
    "\n",
    "        self.trainable = self.cell.trainable\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self.cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self.cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self.cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self.cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self.cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self.cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self.cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self.cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self.cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self.cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self.cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self.cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self.cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self.cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def wrapper_state_size(self):\n",
    "        wrapper_state_size = self.cell.units\n",
    "        wrapper_state_size = 6\n",
    "        return wrapper_state_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        state_size_s = []\n",
    "        for state_size in [self.cell.state_size, self.wrapper_state_size]:\n",
    "            if hasattr(state_size, '__len__'):\n",
    "                state_size_s += list(state_size)\n",
    "            else:\n",
    "                state_size_s.append(state_size)\n",
    "        return tuple(state_size_s)\n",
    "        #return (self.cell.state_size, 3 * 2, )\n",
    "        #return (self.cell.units, self.cell.units)\n",
    "\n",
    "    @property\n",
    "    def state_length(self):\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            cell_state_length = len(self.cell.state_size)\n",
    "        else:\n",
    "            cell_state_length = 1\n",
    "        \n",
    "        wrapper_state_length = len(self.state_size) - cell_state_length\n",
    "        state_length = (cell_state_length, wrapper_state_length)\n",
    "        return state_length\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.cell.output_size\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "\n",
    "#    @property\n",
    "#    def weights(self):\n",
    "#        return self.cell.weights + super(CellWrapper, self).weights\n",
    "\n",
    "#    @property\n",
    "#    def get_weights(self):\n",
    "#        #return self.cell.weights + self.weights\n",
    "#        #return self.weights\n",
    "#\n",
    "#        params = self.weights\n",
    "#        return K.batch_get_value(params)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.cell.build(input_shape)\n",
    "        if self.cell.trainable:\n",
    "            self._trainable_weights.extend(self.cell.weights)\n",
    "        else:\n",
    "            self._non_trainable_weights.extend(self.cell.weights)\n",
    "\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kk = self.add_weight(shape=(input_dim, self.units,),\n",
    "                                  name='wrapper_kernel',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bb = self.add_weight(shape=(self.units,),\n",
    "                                  name='wrapper_bias',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        \"\"\"\n",
    "        self.kernel\n",
    "        self.recurrent_kernel\n",
    "\n",
    "        \"\"\"\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        inner_states = states[:self.state_length[0]]\n",
    "        wrapper_states = states[self.state_length[0]:]\n",
    "\n",
    "        new_outputs, new_inner_states = self.cell.call(inputs, inner_states,\n",
    "                                                 training=training)\n",
    "\n",
    "        i = K.dot(new_outputs, self.kk)\n",
    "        h = K.bias_add(i, self.bb)\n",
    "        \n",
    "        new_wrapper_states = h\n",
    "        \n",
    "        new_states = list(new_inner_states) + list(wrapper_states)\n",
    "\n",
    "        return new_outputs, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellWrapper(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    A Cell Wrapper for Attention Mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        super(CellWrapper, self).__init__(*args, **kwargs)\n",
    "        self.cell = cell\n",
    "        self.cell.__init__(self.units, **kwargs)\n",
    "\n",
    "        self.trainable = self.cell.trainable\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self.cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self.cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self.cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self.cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self.cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self.cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self.cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self.cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self.cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self.cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self.cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self.cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self.cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self.cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def wrapper_state_size(self):\n",
    "        wrapper_state_size = self.cell.units\n",
    "        wrapper_state_size = 6\n",
    "        return wrapper_state_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        state_size_s = []\n",
    "        for state_size in [self.cell.state_size, self.wrapper_state_size]:\n",
    "            if hasattr(state_size, '__len__'):\n",
    "                state_size_s += list(state_size)\n",
    "            else:\n",
    "                state_size_s.append(state_size)\n",
    "        return tuple(state_size_s)\n",
    "        #return (self.cell.state_size, 3 * 2, )\n",
    "        #return (self.cell.units, self.cell.units)\n",
    "\n",
    "    @property\n",
    "    def state_length(self):\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            cell_state_length = len(self.cell.state_size)\n",
    "        else:\n",
    "            cell_state_length = 1\n",
    "        \n",
    "        wrapper_state_length = len(self.state_size) - cell_state_length\n",
    "        state_length = (cell_state_length, wrapper_state_length)\n",
    "        return state_length\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.cell.output_size\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "\n",
    "#    @property\n",
    "#    def weights(self):\n",
    "#        return self.cell.weights + super(CellWrapper, self).weights\n",
    "\n",
    "#    @property\n",
    "#    def get_weights(self):\n",
    "#        #return self.cell.weights + self.weights\n",
    "#        #return self.weights\n",
    "#\n",
    "#        params = self.weights\n",
    "#        return K.batch_get_value(params)\n",
    "\n",
    "#    def add_loss(self, losses, inputs=None):\n",
    "#        self.cell.add_loss(losses, inputs=inputs)\n",
    "#        if losses is None or losses == []:\n",
    "#            return\n",
    "#        self._losses = self.cell._losses\n",
    "#        self._per_input_losses = self.cell._per_input_losses\n",
    "#    \n",
    "#    def add_update(self, updates, inputs=None):\n",
    "#        self.cell.add_update(updates, inputs=inputs)\n",
    "#        if updates is None or updates == []:\n",
    "#            return\n",
    "#        self._updates = self.cell.updates\n",
    "#        self._per_input_updates = self.cell._per_input_updates\n",
    "#\n",
    "#    def get_updates_for(self, inputs):\n",
    "#        return self.cell.get_updates_for(inputs)\n",
    "#    \n",
    "#    def get_losses_for(self, inputs):\n",
    "#        return self.cell.get_losses_for(inputs)\n",
    "    \n",
    "#    @property\n",
    "#    def losses(self):\n",
    "#        return self.cell.losses\n",
    "#\n",
    "#    def get_losses_for(self, inputs=None):\n",
    "#        return self.cell.get_losses_for(inputs)\n",
    "#\n",
    "#    @property\n",
    "#    def losses(self):\n",
    "#        losses = []\n",
    "#        if isinstance(self.cell, Layer):\n",
    "#            losses += self.cell.losses\n",
    "#        losses += super(CellWrapper, self).losses\n",
    "#        return losses\n",
    "#\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        losses = []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            losses += self.cell.get_losses_for(inputs)\n",
    "        losses += super(CellWrapper, self).get_losses_for(inputs)\n",
    "        return losses\n",
    "\n",
    "    @property\n",
    "    def updates(self):\n",
    "        return self.cell.updates + self._updates\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        return self.cell.losses + self._losses\n",
    "\n",
    "#    @property\n",
    "#    def constraints(self):\n",
    "#        constraints = {}\n",
    "#        if hasattr(self.forward_layer, 'constraints'):\n",
    "#            constraints.update(self.forward_layer.constraints)\n",
    "#            constraints.update(self.backward_layer.constraints)\n",
    "#        return constraints\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.cell.build(input_shape)\n",
    "        if self.cell.trainable:\n",
    "            self._trainable_weights.extend(self.cell.weights)\n",
    "        else:\n",
    "            self._non_trainable_weights.extend(self.cell.weights)\n",
    "\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kk = self.add_weight(shape=(input_dim, self.units,),\n",
    "                                  name='wrapper_kernel',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bb = self.add_weight(shape=(self.units,),\n",
    "                                  name='wrapper_bias',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        \"\"\"\n",
    "        self.kernel\n",
    "        self.recurrent_kernel\n",
    "\n",
    "        \"\"\"\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        inner_states = states[:self.state_length[0]]\n",
    "        wrapper_states = states[self.state_length[0]:]\n",
    "\n",
    "        new_outputs, new_inner_states = self.cell.call(inputs, inner_states,\n",
    "                                                 training=training)\n",
    "\n",
    "        i = K.dot(new_outputs, self.kk)\n",
    "        h = K.bias_add(i, self.bb)\n",
    "        \n",
    "        new_wrapper_states = h\n",
    "        \n",
    "        new_states = list(new_inner_states) + list(wrapper_states)\n",
    "\n",
    "        return new_outputs, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_7 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = RNN(cc, return_sequences=True, return_state=False)(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_7/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.35444921, -0.87534273],\n",
       "        [ 0.02369773, -0.20659781]], dtype=float32),\n",
       " array([[-0.69787079, -0.71622372],\n",
       "        [-0.71622372,  0.69787079]], dtype=float32),\n",
       " array([ 0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_7/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/wrapper_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_7/wrapper_bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.35444921, -0.87534273],\n",
       "        [ 0.02369773, -0.20659781]], dtype=float32),\n",
       " array([[-0.69787079, -0.71622372],\n",
       "        [-0.71622372,  0.69787079]], dtype=float32),\n",
       " array([ 0.,  0.], dtype=float32),\n",
       " array([[-1.20725369,  1.10173929],\n",
       "        [ 0.25902939, -0.28722858]], dtype=float32),\n",
       " array([-0.01721525,  1.05787301], dtype=float32)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-088f7cf5f8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0;31m#validation_data=(testX, testY),  # Validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                   )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_186': []},\n",
      "  {'begin_rnn_9': [array([[ 0.60905588,  1.1969775 ],\n",
      "       [-0.48984379,  1.05192268]], dtype=float32),\n",
      "                   array([[-0.63039839, -0.77627176],\n",
      "       [-0.77627176,  0.63039839]], dtype=float32),\n",
      "                   array([ 0.,  0.], dtype=float32),\n",
      "                   array([[-0.7190221 ,  0.39371204],\n",
      "       [ 0.85585606, -0.20114851]], dtype=float32),\n",
      "                   array([ 0.57564878, -0.24027562], dtype=float32)]}],\n",
      " [{'end_input_186': []},\n",
      "  {'end_rnn_9': [array([[ 0.60980004,  1.19623339],\n",
      "       [-0.48909965,  1.05117857]], dtype=float32),\n",
      "                 array([[-0.63114256, -0.77552766],\n",
      "       [-0.7755276 ,  0.62965423]], dtype=float32),\n",
      "                 array([ 0.00074414, -0.00074414], dtype=float32),\n",
      "                 array([[-0.71827793,  0.39296791],\n",
      "       [ 0.8551119 , -0.20040436]], dtype=float32),\n",
      "                 array([ 0.57490462, -0.23953147], dtype=float32)]}],\n",
      " [{'begin_input_186': []},\n",
      "  {'begin_rnn_9': [array([[ 0.60980004,  1.19623339],\n",
      "       [-0.48909965,  1.05117857]], dtype=float32),\n",
      "                   array([[-0.63114256, -0.77552766],\n",
      "       [-0.7755276 ,  0.62965423]], dtype=float32),\n",
      "                   array([ 0.00074414, -0.00074414], dtype=float32),\n",
      "                   array([[-0.71827793,  0.39296791],\n",
      "       [ 0.8551119 , -0.20040436]], dtype=float32),\n",
      "                   array([ 0.57490462, -0.23953147], dtype=float32)]}],\n",
      " [{'end_input_186': []},\n",
      "  {'end_rnn_9': [array([[ 0.61064863,  1.1954248 ],\n",
      "       [-0.48824754,  1.0503509 ]], dtype=float32),\n",
      "                 array([[-0.63200217, -0.77599603],\n",
      "       [-0.77468073,  0.62884998]], dtype=float32),\n",
      "                 array([ 0.00160321, -0.00149927], dtype=float32),\n",
      "                 array([[-0.71742254,  0.39211255],\n",
      "       [ 0.85425895, -0.19955145]], dtype=float32),\n",
      "                 array([ 0.57404613, -0.238673  ], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from functools import wraps\n",
    "\n",
    "__all__ = ['time_profiler']\n",
    "\n",
    "\n",
    "def time_profiler(func):\n",
    "\n",
    "    @wraps(func)\n",
    "    def profiler(*args, **kwargs):\n",
    "\n",
    "        start_tm = dt.now()\n",
    "        print(\"JobStart :\", start_tm)\n",
    "\n",
    "        res = func(*args, **kwargs)\n",
    "\n",
    "        end_tm = dt.now()\n",
    "        print(\"JobEnd   :\", end_tm)\n",
    "\n",
    "        elapsed_tm = end_tm - start_tm\n",
    "        print(\"Elapsed  :\", elapsed_tm)\n",
    "\n",
    "        return res\n",
    "\n",
    "    return profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wrapper__call__(__call__):\n",
    "    \n",
    "    @wraps(__call__)\n",
    "    def wrapped(*args, **kwargs):\n",
    "        result = __call__(*args, **kwargs)\n",
    "        return result\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "def _wrapper__call__(__call__):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        result = __call__(*args, **kwargs)\n",
    "        return result\n",
    "    return wrapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWrapper(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, RNNLayer,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 attention_ok=False,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(RNNWrapper, self).__init__(**kwargs)\n",
    "        self.layer = RNNLayer\n",
    "        self.cell = self.layer.cell\n",
    "\n",
    "        self.return_sequences = self.layer.return_sequences\n",
    "        self.return_state = self.layer.return_state\n",
    "        self.go_backwards = self.layer.go_backwards\n",
    "        self.stateful = self.layer.stateful\n",
    "        self.unroll = self.layer.unroll\n",
    "\n",
    "        #self.layer.__init__(self.layer.cell,\n",
    "        #                    return_sequences=self.return_sequences,\n",
    "        #                    return_state=self.return_state,\n",
    "        #                    go_backwards=self.go_backwards,\n",
    "        #                    stateful=self.stateful,\n",
    "        #                    unroll=self.unroll,\n",
    "        #                    **kwargs)\n",
    "\n",
    "        self.supports_masking = self.layer.supports_masking\n",
    "        self.input_spec = self.layer.input_spec\n",
    "        self.state_spec = self.layer.state_spec\n",
    "        self._states = self.layer._states\n",
    "        self.constants_spec = self.layer.constants_spec\n",
    "        self._num_constants = self.layer._num_constants\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.layer.states\n",
    "    \n",
    "    @property\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.layer.compute_output_shape\n",
    "    \n",
    "    @property\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return self.layer.compute_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer.build(self, input_shape)\n",
    "\n",
    "        self.input_spec = self.layer.input_spec\n",
    "        self.cell.build = self.layer.cell.build\n",
    "        self.state_spec = self.layer.state_spec\n",
    "\n",
    "    @property\n",
    "    def get_initial_state(self, inputs):\n",
    "        return self.layer.get_initial_state(inputs)\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        #inputs, initial_state, constants = self._standardize_args(\n",
    "        #    inputs, initial_state, constants)\n",
    "        self.layer.called = self.layer.__call__(inputs,\n",
    "                                                initial_state=initial_state,\n",
    "                                                constants=constants,\n",
    "                                                **kwargs)\n",
    "        \n",
    "        self.state_spec = self.layer.state_spec\n",
    "        self.constants_spec = self.layer.constants_spec\n",
    "        self._num_constants = self.layer._num_constants\n",
    "        self.input_spec = self.layer.input_spec\n",
    "        \n",
    "        return self.layer.called\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        inner_output = self.layer.call(inputs,\n",
    "                                       mask=mask,\n",
    "                                       training=training,\n",
    "                                       initial_state=initial_state,\n",
    "                                       constants=constants)\n",
    "        \n",
    "        return inner_output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        (inputs,\n",
    "         initial_state,\n",
    "         constants) = self.layer._standardize_args(inputs,\n",
    "                                                   initial_state,\n",
    "                                                   constants)\n",
    "        \n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        self.layer.reset_states(states=states)\n",
    "\n",
    "    def get_config(self):\n",
    "        return self.layer.get_config()\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        return self.layer.trainable_weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        return self.layer.non_trainable_weights\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        return self.layer.losses\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        return self.layer.get_losses_for(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(Layer):\n",
    "    \"\"\"Abstract wrapper base class.\n",
    "\n",
    "    Wrappers take another layer and augment it in various ways.\n",
    "    Do not use this class as a layer, it is only an abstract base class.\n",
    "    Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n",
    "\n",
    "    # Arguments\n",
    "        layer: The layer to be wrapped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, **kwargs):\n",
    "        self.layer = layer\n",
    "        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n",
    "        # the inner layer has update ops that depend on its inputs (as opposed\n",
    "        # to the inputs to the Wrapper layer).\n",
    "        self._input_map = {}\n",
    "        super(Wrapper, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape=None):\n",
    "        self.built = True\n",
    "\n",
    "    @property\n",
    "    def activity_regularizer(self):\n",
    "        if hasattr(self.layer, 'activity_regularizer'):\n",
    "            return self.layer.activity_regularizer\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        return self.layer.trainable_weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        return self.layer.non_trainable_weights\n",
    "\n",
    "    @property\n",
    "    def updates(self):\n",
    "        if hasattr(self.layer, 'updates'):\n",
    "            return self.layer.updates\n",
    "        return []\n",
    "\n",
    "    def get_updates_for(self, inputs=None):\n",
    "        # If the wrapper modifies the inputs, use the modified inputs to\n",
    "        # get the updates from the inner layer.\n",
    "        inner_inputs = inputs\n",
    "        if inputs is not None:\n",
    "            uid = _object_list_uid(inputs)\n",
    "            if uid in self._input_map:\n",
    "                inner_inputs = self._input_map[uid]\n",
    "\n",
    "        updates = self.layer.get_updates_for(inner_inputs)\n",
    "        updates += super(Wrapper, self).get_updates_for(inputs)\n",
    "        return updates\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if hasattr(self.layer, 'losses'):\n",
    "            return self.layer.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if inputs is None:\n",
    "            losses = self.layer.get_losses_for(None)\n",
    "            return losses + super(Wrapper, self).get_losses_for(None)\n",
    "        return super(Wrapper, self).get_losses_for(inputs)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.layer.get_weights()\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.layer.set_weights(weights)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'layer': {'class_name': self.layer.__class__.__name__,\n",
    "                            'config': self.layer.get_config()}}\n",
    "        base_config = super(Wrapper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        layer = deserialize_layer(config.pop('layer'),\n",
    "                                  custom_objects=custom_objects)\n",
    "        return cls(layer, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWrapper(Wrapper):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_226 (InputLayer)       (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_51 (RNN)                 (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "DD = RNN(cc, return_sequences=True, return_state=False)\n",
    "dd = DD(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "DD = RNN(cc, return_sequences=True, return_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD.return_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_215 (InputLayer)       (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_40 (RNN)                 (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DDD = RNNWrapper(DD)\n",
    "dd = DDD(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_227 (InputLayer)       (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_52 (RNN)                 (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "DDD = RNN(cc, return_sequences=True, return_state=False)\n",
    "dd = RNNWrapper(DDD)(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDD.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 10, BATCH_SIZE 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-936-088f7cf5f8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0;31m#validation_data=(testX, testY),  # Validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                   )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fullrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import *\n",
    "\n",
    "\n",
    "def fullrnn(step_function, inputs, initial_states,\n",
    "        go_backwards=False, mask=None, constants=None,\n",
    "        unroll=False, input_length=None):\n",
    "    \"\"\"Iterates over the time dimension of a tensor.\n",
    "\n",
    "    # Arguments\n",
    "        step_function: RNN step function.\n",
    "            Parameters:\n",
    "                inputs: tensor with shape `(samples, ...)` (no time dimension),\n",
    "                    representing input for the batch of samples at a certain\n",
    "                    time step.\n",
    "                states: list of tensors.\n",
    "            Returns:\n",
    "                outputs: tensor with shape `(samples, output_dim)`\n",
    "                    (no time dimension).\n",
    "                new_states: list of tensors, same length and shapes\n",
    "                    as 'states'. The first state in the list must be the\n",
    "                    output tensor at the previous timestep.\n",
    "        inputs: tensor of temporal data of shape `(samples, time, ...)`\n",
    "            (at least 3D).\n",
    "        initial_states: tensor with shape (samples, output_dim)\n",
    "            (no time dimension),\n",
    "            containing the initial values for the states used in\n",
    "            the step function.\n",
    "        go_backwards: boolean. If True, do the iteration over the time\n",
    "            dimension in reverse order and return the reversed sequence.\n",
    "        mask: binary tensor with shape `(samples, time, 1)`,\n",
    "            with a zero for every element that is masked.\n",
    "        constants: a list of constant values passed at each step.\n",
    "        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n",
    "        input_length: not relevant in the TensorFlow implementation.\n",
    "            Must be specified if using unrolling with Theano.\n",
    "\n",
    "    # Returns\n",
    "        A tuple, `(last_output, outputs, new_states)`.\n",
    "\n",
    "            last_output: the latest output of the rnn, of shape `(samples, ...)`\n",
    "            outputs: tensor with shape `(samples, time, ...)` where each\n",
    "                entry `outputs[s, t]` is the output of the step function\n",
    "                at time `t` for sample `s`.\n",
    "            new_states: list of tensors, latest states returned by\n",
    "                the step function, of shape `(samples, ...)`.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: if input dimension is less than 3.\n",
    "        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n",
    "        ValueError: if `mask` is provided (not `None`) but states is not provided\n",
    "            (`len(states)` == 0).\n",
    "    \"\"\"\n",
    "    ndim = len(inputs.get_shape())\n",
    "    if ndim < 3:\n",
    "        raise ValueError('Input should be at least 3D.')\n",
    "\n",
    "    # Transpose to time-major, i.e.\n",
    "    # from (batch, time, ...) to (time, batch, ...)\n",
    "    axes = [1, 0] + list(range(2, ndim))\n",
    "    inputs = tf.transpose(inputs, (axes))\n",
    "\n",
    "    if mask is not None:\n",
    "        if mask.dtype != tf.bool:\n",
    "            mask = tf.cast(mask, tf.bool)\n",
    "        if len(mask.get_shape()) == ndim - 1:\n",
    "            mask = expand_dims(mask)\n",
    "        mask = tf.transpose(mask, axes)\n",
    "\n",
    "    if constants is None:\n",
    "        constants = []\n",
    "\n",
    "    global uses_learning_phase\n",
    "    uses_learning_phase = False\n",
    "\n",
    "    if unroll:\n",
    "        if not inputs.get_shape()[0]:\n",
    "            raise ValueError('Unrolling requires a '\n",
    "                             'fixed number of timesteps.')\n",
    "        states = initial_states\n",
    "        successive_states = []\n",
    "        successive_outputs = []\n",
    "\n",
    "        input_list = tf.unstack(inputs)\n",
    "        if go_backwards:\n",
    "            input_list.reverse()\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_list = tf.unstack(mask)\n",
    "            if go_backwards:\n",
    "                mask_list.reverse()\n",
    "\n",
    "            for inp, mask_t in zip(input_list, mask_list):\n",
    "                output, full_inputs, new_states = step_function(inp, input_list, states + constants) ###########\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "\n",
    "                # tf.where needs its condition tensor\n",
    "                # to be the same shape as its two\n",
    "                # result tensors, but in our case\n",
    "                # the condition (mask) tensor is\n",
    "                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n",
    "                # So we need to\n",
    "                # broadcast the mask to match the shape of A and B.\n",
    "                # That's what the tile call does,\n",
    "                # it just repeats the mask along its second dimension\n",
    "                # n times.\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "\n",
    "                if not successive_outputs:\n",
    "                    prev_output = zeros_like(output)\n",
    "                else:\n",
    "                    prev_output = successive_outputs[-1]\n",
    "\n",
    "                output = tf.where(tiled_mask_t, output, prev_output)\n",
    "\n",
    "                return_states = []\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    # (see earlier comment for tile explanation)\n",
    "                    tiled_mask_t = tf.tile(mask_t,\n",
    "                                           tf.stack([1, tf.shape(new_state)[1]]))\n",
    "                    return_states.append(tf.where(tiled_mask_t,\n",
    "                                                  new_state,\n",
    "                                                  state))\n",
    "                states = return_states\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "        else:\n",
    "            for inp in input_list:\n",
    "                output, full_inputs, states = step_function(inp, input_list, states + constants)############\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "\n",
    "    else:\n",
    "        if go_backwards:\n",
    "            inputs = reverse(inputs, 0)\n",
    "\n",
    "        states = tuple(initial_states)\n",
    "\n",
    "        time_steps = tf.shape(inputs)[0]\n",
    "        outputs, full_inputs, _ = step_function(inputs[0], inputs, initial_states + constants) ###########\n",
    "        output_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=outputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='output_ta')\n",
    "        input_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=inputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='input_ta')\n",
    "        input_ta = input_ta.unstack(inputs)\n",
    "        time = tf.constant(0, dtype='int32', name='time')\n",
    "\n",
    "        if mask is not None:\n",
    "            if not states:\n",
    "                raise ValueError('No initial states provided! '\n",
    "                                 'When using masking in an RNN, you should '\n",
    "                                 'provide initial states '\n",
    "                                 '(and your step function should return '\n",
    "                                 'as its first state at time `t` '\n",
    "                                 'the output at time `t-1`).')\n",
    "            if go_backwards:\n",
    "                mask = reverse(mask, 0)\n",
    "\n",
    "            mask_ta = tensor_array_ops.TensorArray(\n",
    "                dtype=tf.bool,\n",
    "                size=time_steps,\n",
    "                tensor_array_name='mask_ta')\n",
    "            mask_ta = mask_ta.unstack(mask)\n",
    "\n",
    "            def _step(time, output_ta_t, input_ta, *states):##########\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "                #current_input = K.stack(current_input)\n",
    "                #current_input = K.concatenate([current_input.stack(), input_ta.stack()])\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]#############\n",
    "                #whole_inputs = [current_input, full_inputs]\n",
    "                \n",
    "\n",
    "                mask_t = mask_ta.read(time)\n",
    "                output, full_inputs, new_states = step_function(current_input,\n",
    "                                                   full_inputs,#############\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "                output = tf.where(tiled_mask_t, output, states[0])\n",
    "                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t, input_ta) + tuple(new_states)############\n",
    "        else:\n",
    "            def _step(time, output_ta_t, input_ta, *states):############\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "                #current_input = K.expand_dims(current_input, axis=0)\n",
    "                #current_input = K.concatenate([current_input, input_ta.stack()], axis=0)\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]##########\n",
    "                #whole_inputs = [current_input, full_inputs]\n",
    "                #states = states_ta_t.stack()[:time]\n",
    "\n",
    "\n",
    "                output, full_inputs, new_states = step_function(current_input,\n",
    "                                                   full_inputs,#############\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t, input_ta) + tuple(new_states)##############\n",
    "\n",
    "        final_outputs = control_flow_ops.while_loop(\n",
    "            cond=lambda time, *_: time < time_steps,\n",
    "            body=_step,\n",
    "            loop_vars=(time, output_ta, input_ta) + states,################\n",
    "            parallel_iterations=32,\n",
    "            swap_memory=True)\n",
    "        last_time = final_outputs[0]\n",
    "        output_ta = final_outputs[1]\n",
    "        new_states = final_outputs[2:]\n",
    "\n",
    "        outputs = output_ta.stack()\n",
    "        last_output = output_ta.read(last_time - 1)\n",
    "\n",
    "    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n",
    "    outputs = tf.transpose(outputs, axes)\n",
    "    last_output._uses_learning_phase = uses_learning_phase\n",
    "    return last_output, outputs, new_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ATTRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTRNNCell(Layer):\n",
    "    \"\"\"Cell class for SimpleRNN.\n",
    "\n",
    "    # Arguments\n",
    "        units: Positive integer, dimensionality of the output space.\n",
    "        activation: Activation function to use\n",
    "            (see [activations](../activations.md)).\n",
    "            If you pass None, no activation is applied\n",
    "            (ie. \"linear\" activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
    "            used for the linear transformation of the inputs.\n",
    "            (see [initializers](../initializers.md)).\n",
    "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
    "            weights matrix,\n",
    "            used for the linear transformation of the recurrent state.\n",
    "            (see [initializers](../initializers.md)).\n",
    "        bias_initializer: Initializer for the bias vector\n",
    "            (see [initializers](../initializers.md)).\n",
    "        kernel_regularizer: Regularizer function applied to\n",
    "            the `kernel` weights matrix\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        recurrent_regularizer: Regularizer function applied to\n",
    "            the `recurrent_kernel` weights matrix\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        bias_regularizer: Regularizer function applied to the bias vector\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        kernel_constraint: Constraint function applied to\n",
    "            the `kernel` weights matrix\n",
    "            (see [constraints](../constraints.md)).\n",
    "        recurrent_constraint: Constraint function applied to\n",
    "            the `recurrent_kernel` weights matrix\n",
    "            (see [constraints](../constraints.md)).\n",
    "        bias_constraint: Constraint function applied to the bias vector\n",
    "            (see [constraints](../constraints.md)).\n",
    "        dropout: Float between 0 and 1.\n",
    "            Fraction of the units to drop for\n",
    "            the linear transformation of the inputs.\n",
    "        recurrent_dropout: Float between 0 and 1.\n",
    "            Fraction of the units to drop for\n",
    "            the linear transformation of the recurrent state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units,\n",
    "                 activation='tanh',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 recurrent_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 recurrent_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 dropout=0.,\n",
    "                 recurrent_dropout=0.,\n",
    "                 **kwargs):\n",
    "        super(ATTRNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = min(1., max(0., dropout))\n",
    "        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
    "        self.state_size = self.units\n",
    "        self._dropout_mask = None\n",
    "        self._recurrent_dropout_mask = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        timestep, input_dim = input_shape\n",
    "        #self.state_size = (self.units, input_shape[1])\n",
    "        \n",
    "        #self.attn_vec_kernel = self.add_weight(shape=(input_dim, timestep),\n",
    "        #                                       name='attn_vec_kernel',\n",
    "        #                                       initializer=self.kernel_initializer,\n",
    "        #                                       regularizer=self.kernel_regularizer,\n",
    "        #                                       constraint=self.kernel_constraint)\n",
    "        \n",
    "        #self.attn_input_kernel = self.add_weight(shape=(input_dim,),\n",
    "        #                                         name='attn_input_kernel',\n",
    "        #                                         initializer=self.kernel_initializer,\n",
    "        #                                         regularizer=self.kernel_regularizer,\n",
    "        #                                         constraint=self.kernel_constraint)\n",
    "        \n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      name='kernel',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            name='recurrent_kernel',\n",
    "            initializer=self.recurrent_initializer,\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        name='bias',\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        prev_output = states[0]\n",
    "        full_input = states[-1]\n",
    "        \n",
    "        #_, timestep, input_dim = K.int_shape(full_input)\n",
    "        \n",
    "        repeated_input = K.repeat(inputs, 43)\n",
    "        #attn_vec = K.softmax(K.tanh(full_input + repeated_input))\n",
    "        added = full_input + repeated_input\n",
    "        attn_vec = K.softmax(K.tanh(added))\n",
    "        weighted = attn_vec * full_input\n",
    "        attended = K.sum(weighted, axis=1, keepdims=False)\n",
    "        inputs = attended\n",
    "\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
    "                self.dropout,\n",
    "                training=training)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, self.units),\n",
    "                self.recurrent_dropout,\n",
    "                training=training)\n",
    "\n",
    "        dp_mask = self._dropout_mask\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        if dp_mask is not None:\n",
    "            h = K.dot(inputs * dp_mask, self.kernel)\n",
    "        else:\n",
    "            h = K.dot(inputs, self.kernel)\n",
    "        if self.bias is not None:\n",
    "            h = K.bias_add(h, self.bias)\n",
    "\n",
    "        if rec_dp_mask is not None:\n",
    "            prev_output *= rec_dp_mask\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        \n",
    "        #full_output = K.dot(h, self.attn_kernel)\n",
    "\n",
    "        # Properly set learning phase on output tensor.\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                output._uses_learning_phase = True\n",
    "        return output, [output, full_input]\n",
    "        #return output, [output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATTRNN(Layer):\n",
    "    \"\"\"Base class for recurrent layers.\n",
    "\n",
    "    # Arguments\n",
    "        cell: A RNN cell instance. A RNN cell is a class that has:\n",
    "            - a `call(input_at_t, states_at_t)` method, returning\n",
    "                `(output_at_t, states_at_t_plus_1)`. The call method of the\n",
    "                cell can also take the optional argument `constants`, see\n",
    "                section \"Note on passing external constants\" below.\n",
    "            - a `state_size` attribute. This can be a single integer\n",
    "                (single state) in which case it is\n",
    "                the size of the recurrent state\n",
    "                (which should be the same as the size of the cell output).\n",
    "                This can also be a list/tuple of integers\n",
    "                (one size per state). In this case, the first entry\n",
    "                (`state_size[0]`) should be the same as\n",
    "                the size of the cell output.\n",
    "            It is also possible for `cell` to be a list of RNN cell instances,\n",
    "            in which cases the cells get stacked on after the other in the RNN,\n",
    "            implementing an efficient stacked RNN.\n",
    "        return_sequences: Boolean. Whether to return the last output.\n",
    "            in the output sequence, or the full sequence.\n",
    "        return_state: Boolean. Whether to return the last state\n",
    "            in addition to the output.\n",
    "        go_backwards: Boolean (default False).\n",
    "            If True, process the input sequence backwards and return the\n",
    "            reversed sequence.\n",
    "        stateful: Boolean (default False). If True, the last state\n",
    "            for each sample at index i in a batch will be used as initial\n",
    "            state for the sample of index i in the following batch.\n",
    "        unroll: Boolean (default False).\n",
    "            If True, the network will be unrolled,\n",
    "            else a symbolic loop will be used.\n",
    "            Unrolling can speed-up a RNN,\n",
    "            although it tends to be more memory-intensive.\n",
    "            Unrolling is only suitable for short sequences.\n",
    "        input_dim: dimensionality of the input (integer).\n",
    "            This argument (or alternatively,\n",
    "            the keyword argument `input_shape`)\n",
    "            is required when using this layer as the first layer in a model.\n",
    "        input_length: Length of input sequences, to be specified\n",
    "            when it is constant.\n",
    "            This argument is required if you are going to connect\n",
    "            `Flatten` then `Dense` layers upstream\n",
    "            (without it, the shape of the dense outputs cannot be computed).\n",
    "            Note that if the recurrent layer is not the first layer\n",
    "            in your model, you would need to specify the input length\n",
    "            at the level of the first layer\n",
    "            (e.g. via the `input_shape` argument)\n",
    "\n",
    "    # Input shape\n",
    "        3D tensor with shape `(batch_size, timesteps, input_dim)`.\n",
    "\n",
    "    # Output shape\n",
    "        - if `return_state`: a list of tensors. The first tensor is\n",
    "            the output. The remaining tensors are the last states,\n",
    "            each with shape `(batch_size, units)`.\n",
    "        - if `return_sequences`: 3D tensor with shape\n",
    "            `(batch_size, timesteps, units)`.\n",
    "        - else, 2D tensor with shape `(batch_size, units)`.\n",
    "\n",
    "    # Masking\n",
    "        This layer supports masking for input data with a variable number\n",
    "        of timesteps. To introduce masks to your data,\n",
    "        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n",
    "        set to `True`.\n",
    "\n",
    "    # Note on using statefulness in RNNs\n",
    "        You can set RNN layers to be 'stateful', which means that the states\n",
    "        computed for the samples in one batch will be reused as initial states\n",
    "        for the samples in the next batch. This assumes a one-to-one mapping\n",
    "        between samples in different successive batches.\n",
    "\n",
    "        To enable statefulness:\n",
    "            - specify `stateful=True` in the layer constructor.\n",
    "            - specify a fixed batch size for your model, by passing\n",
    "                if sequential model:\n",
    "                  `batch_input_shape=(...)` to the first layer in your model.\n",
    "                else for functional model with 1 or more Input layers:\n",
    "                  `batch_shape=(...)` to all the first layers in your model.\n",
    "                This is the expected shape of your inputs\n",
    "                *including the batch size*.\n",
    "                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n",
    "            - specify `shuffle=False` when calling fit().\n",
    "\n",
    "        To reset the states of your model, call `.reset_states()` on either\n",
    "        a specific layer, or on your entire model.\n",
    "\n",
    "    # Note on specifying the initial state of RNNs\n",
    "        You can specify the initial state of RNN layers symbolically by\n",
    "        calling them with the keyword argument `initial_state`. The value of\n",
    "        `initial_state` should be a tensor or list of tensors representing\n",
    "        the initial state of the RNN layer.\n",
    "\n",
    "        You can specify the initial state of RNN layers numerically by\n",
    "        calling `reset_states` with the keyword argument `states`. The value of\n",
    "        `states` should be a numpy array or list of numpy arrays representing\n",
    "        the initial state of the RNN layer.\n",
    "\n",
    "    # Note on passing external constants to RNNs\n",
    "        You can pass \"external\" constants to the cell using the `constants`\n",
    "        keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n",
    "        requires that the `cell.call` method accepts the same keyword argument\n",
    "        `constants`. Such constants can be used to condition the cell\n",
    "        transformation on additional static inputs (not changing over time),\n",
    "        a.k.a. an attention mechanism.\n",
    "\n",
    "    # Examples\n",
    "\n",
    "    ```python\n",
    "        # First, let's define a RNN Cell, as a layer subclass.\n",
    "\n",
    "        class MinimalRNNCell(keras.layers.Layer):\n",
    "\n",
    "            def __init__(self, units, **kwargs):\n",
    "                self.units = units\n",
    "                self.state_size = units\n",
    "                super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "            def build(self, input_shape):\n",
    "                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                              initializer='uniform',\n",
    "                                              name='kernel')\n",
    "                self.recurrent_kernel = self.add_weight(\n",
    "                    shape=(self.units, self.units),\n",
    "                    initializer='uniform',\n",
    "                    name='recurrent_kernel')\n",
    "                self.built = True\n",
    "\n",
    "            def call(self, inputs, states):\n",
    "                prev_output = states[0]\n",
    "                h = K.dot(inputs, self.kernel)\n",
    "                output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "                return output, [output]\n",
    "\n",
    "        # Let's use this cell in a RNN layer:\n",
    "\n",
    "        cell = MinimalRNNCell(32)\n",
    "        x = keras.Input((None, 5))\n",
    "        layer = RNN(cell)\n",
    "        y = layer(x)\n",
    "\n",
    "        # Here's how to use the cell to build a stacked RNN:\n",
    "\n",
    "        cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
    "        x = keras.Input((None, 5))\n",
    "        layer = RNN(cells)\n",
    "        y = layer(x)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(ATTRNN, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            initial_state =  [K.tile(initial_state, [1, dim])\n",
    "                              for dim in self.cell.state_size]\n",
    "        else:\n",
    "            initial_state = [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "        return initial_state + [inputs]\n",
    "        #return initial_state\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ATTRNN, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states) + 1:\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(ATTRNN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(ATTRNN, self).get_losses_for(inputs)\n",
    "        return super(ATTRNN, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_2 (RNN)                  (None, 3, 2)              10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "#cc = CellWrapper(bb)\n",
    "DD = RNN(bb, return_sequences=True, return_state=False)\n",
    "dd = DD(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 43, 500)           0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 43, 500)           1501500   \n",
      "_________________________________________________________________\n",
      "attrnn_13 (ATTRNN)           (None, 43, 11)            5632      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43, 11)            132       \n",
      "=================================================================\n",
      "Total params: 1,507,264\n",
      "Trainable params: 1,507,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = data_X.shape\n",
    "_, timestepY, ndimY = data_Y.shape\n",
    "xlen, ylen = ndimX, ndimY\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "\n",
    "input_layer = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "encoded = GRU(ndimX, return_sequences=True)(input_layer)\n",
    "#cc = CellWrapper(bb)\n",
    "decoded = ATTRNN(ATTRNNCell(ndimY), return_sequences=True, return_state=False)(encoded)\n",
    "softmaxed = Dense(target_dict_length, activation='softmax')(decoded)\n",
    "model = Model(inputs=input_layer, outputs=softmaxed)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 10, BATCH_SIZE 3\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/callbacks.py:93: UserWarning: Method on_batch_begin() is slow compared to the batch update (0.226871). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 3.4138 - mean_absolute_error: 0.6680 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 2/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 3/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 4/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 5/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 6/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 7/10\n",
      " - 11s - loss: 3.5774 - mean_absolute_error: 0.7955 - val_loss: 3.5366 - val_mean_absolute_error: 0.7958\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-50bf30b0e942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0;31m#validation_data=(testX, testY),  # Validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                   )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 10\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "fitted = model.fit(data_X, data_Y,\n",
    "                   epochs=EPOCH_NUM,     # How many times to run back_propagation\n",
    "                   batch_size=BATCH_SIZE,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.62077272,  0.54501438],\n",
       "           [ 1.20184696,  0.21438408]], dtype=float32),\n",
       "    array([[ 0.33353525, -0.94273764],\n",
       "           [-0.94273764, -0.33353525]], dtype=float32),\n",
       "    array([ 0.,  0.], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.62002856,  0.54575855],\n",
       "           [ 1.20110285,  0.21512823]], dtype=float32),\n",
       "    array([[ 0.33279112, -0.94199347],\n",
       "           [-0.9434818 , -0.33427939]], dtype=float32),\n",
       "    array([-0.00074414,  0.00074414], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.62002856,  0.54575855],\n",
       "           [ 1.20110285,  0.21512823]], dtype=float32),\n",
       "    array([[ 0.33279112, -0.94199347],\n",
       "           [-0.9434818 , -0.33427939]], dtype=float32),\n",
       "    array([-0.00074414,  0.00074414], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61919141,  0.54660857],\n",
       "           [ 1.20032609,  0.21595261]], dtype=float32),\n",
       "    array([[ 0.33217111, -0.94113505],\n",
       "           [-0.94391912, -0.33513734]], dtype=float32),\n",
       "    array([-0.00155155,  0.00156192], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61919141,  0.54660857],\n",
       "           [ 1.20032609,  0.21595261]], dtype=float32),\n",
       "    array([[ 0.33217111, -0.94113505],\n",
       "           [-0.94391912, -0.33513734]], dtype=float32),\n",
       "    array([-0.00155155,  0.00156192], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61830211,  0.54750335],\n",
       "           [ 1.19957519,  0.21683189]], dtype=float32),\n",
       "    array([[ 0.33140501, -0.94023949],\n",
       "           [-0.94460136, -0.33600834]], dtype=float32),\n",
       "    array([-0.00238585,  0.00244832], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61830211,  0.54750335],\n",
       "           [ 1.19957519,  0.21683189]], dtype=float32),\n",
       "    array([[ 0.33140501, -0.94023949],\n",
       "           [-0.94460136, -0.33600834]], dtype=float32),\n",
       "    array([-0.00238585,  0.00244832], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61741292,  0.54842532],\n",
       "           [ 1.19874227,  0.2177532 ]], dtype=float32),\n",
       "    array([[ 0.33060718, -0.93932486],\n",
       "           [-0.94524431, -0.33591306]], dtype=float32),\n",
       "    array([-0.00326786,  0.00336349], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61741292,  0.54842532],\n",
       "           [ 1.19874227,  0.2177532 ]], dtype=float32),\n",
       "    array([[ 0.33060718, -0.93932486],\n",
       "           [-0.94524431, -0.33591306]], dtype=float32),\n",
       "    array([-0.00326786,  0.00336349], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61652309,  0.54932982],\n",
       "           [ 1.19791377,  0.21862319]], dtype=float32),\n",
       "    array([[ 0.32985839, -0.93838733],\n",
       "           [-0.94560593, -0.33617225]], dtype=float32),\n",
       "    array([-0.00415747,  0.0042887 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61652309,  0.54932982],\n",
       "           [ 1.19791377,  0.21862319]], dtype=float32),\n",
       "    array([[ 0.32985839, -0.93838733],\n",
       "           [-0.94560593, -0.33617225]], dtype=float32),\n",
       "    array([-0.00415747,  0.0042887 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61560905,  0.55018848],\n",
       "           [ 1.19703901,  0.21953516]], dtype=float32),\n",
       "    array([[ 0.32907704, -0.93742514],\n",
       "           [-0.94609714, -0.33635363]], dtype=float32),\n",
       "    array([-0.00504686,  0.0052421 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61560905,  0.55018848],\n",
       "           [ 1.19703901,  0.21953516]], dtype=float32),\n",
       "    array([[ 0.32907704, -0.93742514],\n",
       "           [-0.94609714, -0.33635363]], dtype=float32),\n",
       "    array([-0.00504686,  0.0052421 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61486614,  0.55100179],\n",
       "           [ 1.19615364,  0.22006655]], dtype=float32),\n",
       "    array([[ 0.32865274, -0.93649721],\n",
       "           [-0.9464649 , -0.33604956]], dtype=float32),\n",
       "    array([-0.00580603,  0.00595561], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61486614,  0.55100179],\n",
       "           [ 1.19615364,  0.22006655]], dtype=float32),\n",
       "    array([[ 0.32865274, -0.93649721],\n",
       "           [-0.9464649 , -0.33604956]], dtype=float32),\n",
       "    array([-0.00580603,  0.00595561], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61413372,  0.55177379],\n",
       "           [ 1.19523561,  0.22069649]], dtype=float32),\n",
       "    array([[ 0.32816431, -0.93556166],\n",
       "           [-0.94689351, -0.33599022]], dtype=float32),\n",
       "    array([-0.00658387,  0.00671429], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61413372,  0.55177379],\n",
       "           [ 1.19523561,  0.22069649]], dtype=float32),\n",
       "    array([[ 0.32816431, -0.93556166],\n",
       "           [-0.94689351, -0.33599022]], dtype=float32),\n",
       "    array([-0.00658387,  0.00671429], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61332011,  0.55261445],\n",
       "           [ 1.1942842 ,  0.22139342]], dtype=float32),\n",
       "    array([[ 0.32752723, -0.93459773],\n",
       "           [-0.94735545, -0.33578226]], dtype=float32),\n",
       "    array([-0.00743037,  0.00751969], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61332011,  0.55261445],\n",
       "           [ 1.1942842 ,  0.22139342]], dtype=float32),\n",
       "    array([[ 0.32752723, -0.93459773],\n",
       "           [-0.94735545, -0.33578226]], dtype=float32),\n",
       "    array([-0.00743037,  0.00751969], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61258894,  0.55336994],\n",
       "           [ 1.19332135,  0.22200744]], dtype=float32),\n",
       "    array([[ 0.32705697, -0.93362463],\n",
       "           [-0.94755977, -0.33547434]], dtype=float32),\n",
       "    array([-0.00819269,  0.0082647 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61258894,  0.55336994],\n",
       "           [ 1.19332135,  0.22200744]], dtype=float32),\n",
       "    array([[ 0.32705697, -0.93362463],\n",
       "           [-0.94755977, -0.33547434]], dtype=float32),\n",
       "    array([-0.00819269,  0.0082647 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61180383,  0.55419409],\n",
       "           [ 1.19233096,  0.22270113]], dtype=float32),\n",
       "    array([[ 0.32647038, -0.93264425],\n",
       "           [-0.94788009, -0.33525825]], dtype=float32),\n",
       "    array([-0.00903024,  0.00906473], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61180383,  0.55419409],\n",
       "           [ 1.19233096,  0.22270113]], dtype=float32),\n",
       "    array([[ 0.32647038, -0.93264425],\n",
       "           [-0.94788009, -0.33525825]], dtype=float32),\n",
       "    array([-0.00903024,  0.00906473], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61096865,  0.55501086],\n",
       "           [ 1.19136071,  0.22338019]], dtype=float32),\n",
       "    array([[ 0.32602906, -0.93166387],\n",
       "           [-0.94799727, -0.33488309]], dtype=float32),\n",
       "    array([-0.00985532,  0.00987362], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61096865,  0.55501086],\n",
       "           [ 1.19136071,  0.22338019]], dtype=float32),\n",
       "    array([[ 0.32602906, -0.93166387],\n",
       "           [-0.94799727, -0.33488309]], dtype=float32),\n",
       "    array([-0.00985532,  0.00987362], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.61029768,  0.55570614],\n",
       "           [ 1.19051385,  0.22389723]], dtype=float32),\n",
       "    array([[ 0.32586819, -0.93070358],\n",
       "           [-0.94787616, -0.33435404]], dtype=float32),\n",
       "    array([-0.01048109,  0.01063426], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.61029768,  0.55570614],\n",
       "           [ 1.19051385,  0.22389723]], dtype=float32),\n",
       "    array([[ 0.32586819, -0.93070358],\n",
       "           [-0.94787616, -0.33435404]], dtype=float32),\n",
       "    array([-0.01048109,  0.01063426], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60957557,  0.55647808],\n",
       "           [ 1.18969834,  0.22442621]], dtype=float32),\n",
       "    array([[ 0.325645  , -0.92973888],\n",
       "           [-0.94783044, -0.33385313]], dtype=float32),\n",
       "    array([-0.01112146,  0.01143388], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60957557,  0.55647808],\n",
       "           [ 1.18969834,  0.22442621]], dtype=float32),\n",
       "    array([[ 0.325645  , -0.92973888],\n",
       "           [-0.94783044, -0.33385313]], dtype=float32),\n",
       "    array([-0.01112146,  0.01143388], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60876167,  0.55732608],\n",
       "           [ 1.18881679,  0.22506256]], dtype=float32),\n",
       "    array([[ 0.3252131 , -0.92874908],\n",
       "           [-0.94798666, -0.33335942]], dtype=float32),\n",
       "    array([-0.01187238,  0.01230085], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60876167,  0.55732608],\n",
       "           [ 1.18881679,  0.22506256]], dtype=float32),\n",
       "    array([[ 0.3252131 , -0.92874908],\n",
       "           [-0.94798666, -0.33335942]], dtype=float32),\n",
       "    array([-0.01187238,  0.01230085], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60789096,  0.55823708],\n",
       "           [ 1.18791664,  0.22574177]], dtype=float32),\n",
       "    array([[ 0.32467332, -0.92775446],\n",
       "           [-0.94828445, -0.33282462]], dtype=float32),\n",
       "    array([-0.0126703 ,  0.01321505], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60789096,  0.55823708],\n",
       "           [ 1.18791664,  0.22574177]], dtype=float32),\n",
       "    array([[ 0.32467332, -0.92775446],\n",
       "           [-0.94828445, -0.33282462]], dtype=float32),\n",
       "    array([-0.0126703 ,  0.01321505], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60707372,  0.55907726],\n",
       "           [ 1.18706119,  0.22642189]], dtype=float32),\n",
       "    array([[ 0.32419997, -0.92678648],\n",
       "           [-0.94851059, -0.3323437 ]], dtype=float32),\n",
       "    array([-0.01339941,  0.01406081], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60707372,  0.55907726],\n",
       "           [ 1.18706119,  0.22642189]], dtype=float32),\n",
       "    array([[ 0.32419997, -0.92678648],\n",
       "           [-0.94851059, -0.3323437 ]], dtype=float32),\n",
       "    array([-0.01339941,  0.01406081], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60618705,  0.5599584 ],\n",
       "           [ 1.18615317,  0.22717793]], dtype=float32),\n",
       "    array([[ 0.32359743, -0.92580652],\n",
       "           [-0.94893128, -0.33193997]], dtype=float32),\n",
       "    array([-0.01420707,  0.01494464], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60618705,  0.5599584 ],\n",
       "           [ 1.18615317,  0.22717793]], dtype=float32),\n",
       "    array([[ 0.32359743, -0.92580652],\n",
       "           [-0.94893128, -0.33193997]], dtype=float32),\n",
       "    array([-0.01420707,  0.01494464], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60528797,  0.56085366],\n",
       "           [ 1.18523073,  0.22798006]], dtype=float32),\n",
       "    array([[ 0.32300577, -0.92480773],\n",
       "           [-0.94941026, -0.33154514]], dtype=float32),\n",
       "    array([-0.0150066 ,  0.01582868], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60528797,  0.56085366],\n",
       "           [ 1.18523073,  0.22798006]], dtype=float32),\n",
       "    array([[ 0.32300577, -0.92480773],\n",
       "           [-0.94941026, -0.33154514]], dtype=float32),\n",
       "    array([-0.0150066 ,  0.01582868], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60434371,  0.56178021],\n",
       "           [ 1.18428898,  0.22881444]], dtype=float32),\n",
       "    array([[ 0.32237744, -0.92379588],\n",
       "           [-0.94987416, -0.33113363]], dtype=float32),\n",
       "    array([-0.01587355,  0.0167556 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60434371,  0.56178021],\n",
       "           [ 1.18428898,  0.22881444]], dtype=float32),\n",
       "    array([[ 0.32237744, -0.92379588],\n",
       "           [-0.94987416, -0.33113363]], dtype=float32),\n",
       "    array([-0.01587355,  0.0167556 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60350281,  0.56267411],\n",
       "           [ 1.18333137,  0.22959112]], dtype=float32),\n",
       "    array([[ 0.32185477, -0.92279923],\n",
       "           [-0.95030177, -0.33070952]], dtype=float32),\n",
       "    array([-0.01668338,  0.01760269], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60350281,  0.56267411],\n",
       "           [ 1.18333137,  0.22959112]], dtype=float32),\n",
       "    array([[ 0.32185477, -0.92279923],\n",
       "           [-0.95030177, -0.33070952]], dtype=float32),\n",
       "    array([-0.01668338,  0.01760269], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60260236,  0.56361401],\n",
       "           [ 1.18234897,  0.23042767]], dtype=float32),\n",
       "    array([[ 0.3212131 , -0.92178845],\n",
       "           [-0.95083177, -0.33029038]], dtype=float32),\n",
       "    array([-0.01755612,  0.01851303], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60260236,  0.56361401],\n",
       "           [ 1.18234897,  0.23042767]], dtype=float32),\n",
       "    array([[ 0.3212131 , -0.92178845],\n",
       "           [-0.95083177, -0.33029038]], dtype=float32),\n",
       "    array([-0.01755612,  0.01851303], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60165387,  0.56458163],\n",
       "           [ 1.18133259,  0.23128898]], dtype=float32),\n",
       "    array([[ 0.32051933, -0.92075986],\n",
       "           [-0.95140028, -0.32982194]], dtype=float32),\n",
       "    array([-0.01849202,  0.01944531], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60165387,  0.56458163],\n",
       "           [ 1.18133259,  0.23128898]], dtype=float32),\n",
       "    array([[ 0.32051933, -0.92075986],\n",
       "           [-0.95140028, -0.32982194]], dtype=float32),\n",
       "    array([-0.01849202,  0.01944531], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.60072201,  0.56552279],\n",
       "           [ 1.18036401,  0.23208903]], dtype=float32),\n",
       "    array([[ 0.31996715, -0.91975093],\n",
       "           [-0.95187181, -0.32928604]], dtype=float32),\n",
       "    array([-0.01934388,  0.02034498], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.60072201,  0.56552279],\n",
       "           [ 1.18036401,  0.23208903]], dtype=float32),\n",
       "    array([[ 0.31996715, -0.91975093],\n",
       "           [-0.95187181, -0.32928604]], dtype=float32),\n",
       "    array([-0.01934388,  0.02034498], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59978014,  0.56643492],\n",
       "           [ 1.17939281,  0.23287064]], dtype=float32),\n",
       "    array([[ 0.31937549, -0.91875184],\n",
       "           [-0.95233893, -0.32870862]], dtype=float32),\n",
       "    array([-0.02021402,  0.02121247], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59978014,  0.56643492],\n",
       "           [ 1.17939281,  0.23287064]], dtype=float32),\n",
       "    array([[ 0.31937549, -0.91875184],\n",
       "           [-0.95233893, -0.32870862]], dtype=float32),\n",
       "    array([-0.02021402,  0.02121247], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59882599,  0.56730479],\n",
       "           [ 1.17844212,  0.23363939]], dtype=float32),\n",
       "    array([[ 0.31869382, -0.91778481],\n",
       "           [-0.95290893, -0.32805133]], dtype=float32),\n",
       "    array([-0.02110882,  0.02207005], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59882599,  0.56730479],\n",
       "           [ 1.17844212,  0.23363939]], dtype=float32),\n",
       "    array([[ 0.31869382, -0.91778481],\n",
       "           [-0.95290893, -0.32805133]], dtype=float32),\n",
       "    array([-0.02110882,  0.02207005], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59789795,  0.56816435],\n",
       "           [ 1.17750597,  0.23441921]], dtype=float32),\n",
       "    array([[ 0.31803185, -0.91681004],\n",
       "           [-0.95346111, -0.3274242 ]], dtype=float32),\n",
       "    array([-0.02196322,  0.02292321], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59789795,  0.56816435],\n",
       "           [ 1.17750597,  0.23441921]], dtype=float32),\n",
       "    array([[ 0.31803185, -0.91681004],\n",
       "           [-0.95346111, -0.3274242 ]], dtype=float32),\n",
       "    array([-0.02196322,  0.02292321], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59702617,  0.56899858],\n",
       "           [ 1.17660689,  0.23509464]], dtype=float32),\n",
       "    array([[ 0.31743699, -0.91584575],\n",
       "           [-0.95394546, -0.32667649]], dtype=float32),\n",
       "    array([-0.02275227,  0.02374599], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59702617,  0.56899858],\n",
       "           [ 1.17660689,  0.23509464]], dtype=float32),\n",
       "    array([[ 0.31743699, -0.91584575],\n",
       "           [-0.95394546, -0.32667649]], dtype=float32),\n",
       "    array([-0.02275227,  0.02374599], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59611732,  0.56989521],\n",
       "           [ 1.17571545,  0.23581196]], dtype=float32),\n",
       "    array([[ 0.31683102, -0.91487163],\n",
       "           [-0.95443887, -0.32594061]], dtype=float32),\n",
       "    array([-0.02355984,  0.02462225], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59611732,  0.56989521],\n",
       "           [ 1.17571545,  0.23581196]], dtype=float32),\n",
       "    array([[ 0.31683102, -0.91487163],\n",
       "           [-0.95443887, -0.32594061]], dtype=float32),\n",
       "    array([-0.02355984,  0.02462225], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59524411,  0.57073623],\n",
       "           [ 1.17483389,  0.23650064]], dtype=float32),\n",
       "    array([[ 0.31625661, -0.91390151],\n",
       "           [-0.95478809, -0.32533836]], dtype=float32),\n",
       "    array([-0.02436924,  0.02550218], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59524411,  0.57073623],\n",
       "           [ 1.17483389,  0.23650064]], dtype=float32),\n",
       "    array([[ 0.31625661, -0.91390151],\n",
       "           [-0.95478809, -0.32533836]], dtype=float32),\n",
       "    array([-0.02436924,  0.02550218], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59435093,  0.57157087],\n",
       "           [ 1.17398489,  0.23705103]], dtype=float32),\n",
       "    array([[ 0.3157565 , -0.91293448],\n",
       "           [-0.95508772, -0.3246215 ]], dtype=float32),\n",
       "    array([-0.02517261,  0.02632555], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59435093,  0.57157087],\n",
       "           [ 1.17398489,  0.23705103]], dtype=float32),\n",
       "    array([[ 0.3157565 , -0.91293448],\n",
       "           [-0.95508772, -0.3246215 ]], dtype=float32),\n",
       "    array([-0.02517261,  0.02632555], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59342521,  0.57239133],\n",
       "           [ 1.1731199 ,  0.2376432 ]], dtype=float32),\n",
       "    array([[ 0.31520256, -0.9119609 ],\n",
       "           [-0.95547587, -0.32396811]], dtype=float32),\n",
       "    array([-0.02599278,  0.02713246], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59342521,  0.57239133],\n",
       "           [ 1.1731199 ,  0.2376432 ]], dtype=float32),\n",
       "    array([[ 0.31520256, -0.9119609 ],\n",
       "           [-0.95547587, -0.32396811]], dtype=float32),\n",
       "    array([-0.02599278,  0.02713246], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59255636,  0.57310957],\n",
       "           [ 1.17231774,  0.23812422]], dtype=float32),\n",
       "    array([[ 0.31482407, -0.91099238],\n",
       "           [-0.95565677, -0.32324025]], dtype=float32),\n",
       "    array([-0.02671932,  0.02781669], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59255636,  0.57310957],\n",
       "           [ 1.17231774,  0.23812422]], dtype=float32),\n",
       "    array([[ 0.31482407, -0.91099238],\n",
       "           [-0.95565677, -0.32324025]], dtype=float32),\n",
       "    array([-0.02671932,  0.02781669], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59168571,  0.57381266],\n",
       "           [ 1.17146444,  0.23865277]], dtype=float32),\n",
       "    array([[ 0.3144182 , -0.91002959],\n",
       "           [-0.9558726 , -0.32243738]], dtype=float32),\n",
       "    array([-0.02746675,  0.02849434], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59168571,  0.57381266],\n",
       "           [ 1.17146444,  0.23865277]], dtype=float32),\n",
       "    array([[ 0.3144182 , -0.91002959],\n",
       "           [-0.9558726 , -0.32243738]], dtype=float32),\n",
       "    array([-0.02746675,  0.02849434], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.59079021,  0.57457697],\n",
       "           [ 1.17052388,  0.23931445]], dtype=float32),\n",
       "    array([[ 0.31389785, -0.90905076],\n",
       "           [-0.95621765, -0.32174811]], dtype=float32),\n",
       "    array([-0.02829577,  0.02926161], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.59079021,  0.57457697],\n",
       "           [ 1.17052388,  0.23931445]], dtype=float32),\n",
       "    array([[ 0.31389785, -0.90905076],\n",
       "           [-0.95621765, -0.32174811]], dtype=float32),\n",
       "    array([-0.02829577,  0.02926161], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58984321,  0.57538897],\n",
       "           [ 1.16953766,  0.23997948]], dtype=float32),\n",
       "    array([[ 0.31330973, -0.90807128],\n",
       "           [-0.95671505, -0.32113478]], dtype=float32),\n",
       "    array([-0.02917449,  0.03006236], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58984321,  0.57538897],\n",
       "           [ 1.16953766,  0.23997948]], dtype=float32),\n",
       "    array([[ 0.31330973, -0.90807128],\n",
       "           [-0.95671505, -0.32113478]], dtype=float32),\n",
       "    array([-0.02917449,  0.03006236], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58892304,  0.57624465],\n",
       "           [ 1.16856432,  0.24072257]], dtype=float32),\n",
       "    array([[ 0.31274468, -0.90708047],\n",
       "           [-0.95724678, -0.32052276]], dtype=float32),\n",
       "    array([-0.03000875,  0.03090747], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58892304,  0.57624465],\n",
       "           [ 1.16856432,  0.24072257]], dtype=float32),\n",
       "    array([[ 0.31274468, -0.90708047],\n",
       "           [-0.95724678, -0.32052276]], dtype=float32),\n",
       "    array([-0.03000875,  0.03090747], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58806229,  0.57704496],\n",
       "           [ 1.1676476 ,  0.24145852]], dtype=float32),\n",
       "    array([[ 0.31221592, -0.90611678],\n",
       "           [-0.95781839, -0.31991166]], dtype=float32),\n",
       "    array([-0.0307104 ,  0.03177122], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58806229,  0.57704496],\n",
       "           [ 1.1676476 ,  0.24145852]], dtype=float32),\n",
       "    array([[ 0.31221592, -0.90611678],\n",
       "           [-0.95781839, -0.31991166]], dtype=float32),\n",
       "    array([-0.0307104 ,  0.03177122], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58729166,  0.57774729],\n",
       "           [ 1.16674078,  0.24207884]], dtype=float32),\n",
       "    array([[ 0.31174889, -0.9051668 ],\n",
       "           [-0.95824194, -0.31924808]], dtype=float32),\n",
       "    array([-0.03138508,  0.03255969], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58729166,  0.57774729],\n",
       "           [ 1.16674078,  0.24207884]], dtype=float32),\n",
       "    array([[ 0.31174889, -0.9051668 ],\n",
       "           [-0.95824194, -0.31924808]], dtype=float32),\n",
       "    array([-0.03138508,  0.03255969], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58651131,  0.57845926],\n",
       "           [ 1.16583514,  0.24274467]], dtype=float32),\n",
       "    array([[ 0.31128678, -0.90418279],\n",
       "           [-0.95861095, -0.31858689]], dtype=float32),\n",
       "    array([-0.03209129,  0.03336154], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58651131,  0.57845926],\n",
       "           [ 1.16583514,  0.24274467]], dtype=float32),\n",
       "    array([[ 0.31128678, -0.90418279],\n",
       "           [-0.95861095, -0.31858689]], dtype=float32),\n",
       "    array([-0.03209129,  0.03336154], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58568859,  0.57922149],\n",
       "           [ 1.16488683,  0.24345721]], dtype=float32),\n",
       "    array([[ 0.31069627, -0.90319353],\n",
       "           [-0.95906109, -0.31796601]], dtype=float32),\n",
       "    array([-0.03288776,  0.0342223 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58568859,  0.57922149],\n",
       "           [ 1.16488683,  0.24345721]], dtype=float32),\n",
       "    array([[ 0.31069627, -0.90319353],\n",
       "           [-0.95906109, -0.31796601]], dtype=float32),\n",
       "    array([-0.03288776,  0.0342223 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58491576,  0.57993746],\n",
       "           [ 1.1639924 ,  0.24416588]], dtype=float32),\n",
       "    array([[ 0.31014451, -0.90223199],\n",
       "           [-0.95956147, -0.31734401]], dtype=float32),\n",
       "    array([-0.0335566 ,  0.03510048], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58491576,  0.57993746],\n",
       "           [ 1.1639924 ,  0.24416588]], dtype=float32),\n",
       "    array([[ 0.31014451, -0.90223199],\n",
       "           [-0.95956147, -0.31734401]], dtype=float32),\n",
       "    array([-0.0335566 ,  0.03510048], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5841046 ,  0.58063811],\n",
       "           [ 1.16310632,  0.24477902]], dtype=float32),\n",
       "    array([[ 0.30966857, -0.90125841],\n",
       "           [-0.95994633, -0.31658259]], dtype=float32),\n",
       "    array([-0.03424701,  0.03593442], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5841046 ,  0.58063811],\n",
       "           [ 1.16310632,  0.24477902]], dtype=float32),\n",
       "    array([[ 0.30966857, -0.90125841],\n",
       "           [-0.95994633, -0.31658259]], dtype=float32),\n",
       "    array([-0.03424701,  0.03593442], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58336836,  0.581186  ],\n",
       "           [ 1.16228068,  0.24528468]], dtype=float32),\n",
       "    array([[ 0.30934176, -0.90028191],\n",
       "           [-0.96011525, -0.31575581]], dtype=float32),\n",
       "    array([-0.03486874,  0.0366781 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58336836,  0.581186  ],\n",
       "           [ 1.16228068,  0.24528468]], dtype=float32),\n",
       "    array([[ 0.30934176, -0.90028191],\n",
       "           [-0.96011525, -0.31575581]], dtype=float32),\n",
       "    array([-0.03486874,  0.0366781 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5825718 ,  0.58179444],\n",
       "           [ 1.16140473,  0.24584183]], dtype=float32),\n",
       "    array([[ 0.3089453 , -0.89927804],\n",
       "           [-0.96038848, -0.31493393]], dtype=float32),\n",
       "    array([-0.03554544,  0.03744871], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5825718 ,  0.58179444],\n",
       "           [ 1.16140473,  0.24584183]], dtype=float32),\n",
       "    array([[ 0.3089453 , -0.89927804],\n",
       "           [-0.96038848, -0.31493393]], dtype=float32),\n",
       "    array([-0.03554544,  0.03744871], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58191991,  0.58237845],\n",
       "           [ 1.16067648,  0.24623661]], dtype=float32),\n",
       "    array([[ 0.30873927, -0.89829862],\n",
       "           [-0.96050835, -0.31404653]], dtype=float32),\n",
       "    array([-0.03602575,  0.0381325 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58191991,  0.58237845],\n",
       "           [ 1.16067648,  0.24623661]], dtype=float32),\n",
       "    array([[ 0.30873927, -0.89829862],\n",
       "           [-0.96050835, -0.31404653]], dtype=float32),\n",
       "    array([-0.03602575,  0.0381325 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58125931,  0.58297271],\n",
       "           [ 1.15985858,  0.24672446]], dtype=float32),\n",
       "    array([[ 0.30847725, -0.89732206],\n",
       "           [-0.96076077, -0.31329569]], dtype=float32),\n",
       "    array([-0.03656713,  0.03885421], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58125931,  0.58297271],\n",
       "           [ 1.15985858,  0.24672446]], dtype=float32),\n",
       "    array([[ 0.30847725, -0.89732206],\n",
       "           [-0.96076077, -0.31329569]], dtype=float32),\n",
       "    array([-0.03656713,  0.03885421], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.58061343,  0.58361053],\n",
       "           [ 1.15899217,  0.2473076 ]], dtype=float32),\n",
       "    array([[ 0.30817831, -0.8963353 ],\n",
       "           [-0.96103233, -0.31266508]], dtype=float32),\n",
       "    array([-0.03715382,  0.03964119], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.58061343,  0.58361053],\n",
       "           [ 1.15899217,  0.2473076 ]], dtype=float32),\n",
       "    array([[ 0.30817831, -0.8963353 ],\n",
       "           [-0.96103233, -0.31266508]], dtype=float32),\n",
       "    array([-0.03715382,  0.03964119], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57987857,  0.58433026],\n",
       "           [ 1.15809333,  0.24795777]], dtype=float32),\n",
       "    array([[ 0.30776998, -0.89532441],\n",
       "           [-0.96141267, -0.31201303]], dtype=float32),\n",
       "    array([-0.03781747,  0.04046492], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57987857,  0.58433026],\n",
       "           [ 1.15809333,  0.24795777]], dtype=float32),\n",
       "    array([[ 0.30776998, -0.89532441],\n",
       "           [-0.96141267, -0.31201303]], dtype=float32),\n",
       "    array([-0.03781747,  0.04046492], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57900113,  0.58511966],\n",
       "           [ 1.15711987,  0.2486061 ]], dtype=float32),\n",
       "    array([[ 0.30719623, -0.89428228],\n",
       "           [-0.96192908, -0.31130245]], dtype=float32),\n",
       "    array([-0.03862222,  0.04131657], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57900113,  0.58511966],\n",
       "           [ 1.15711987,  0.2486061 ]], dtype=float32),\n",
       "    array([[ 0.30719623, -0.89428228],\n",
       "           [-0.96192908, -0.31130245]], dtype=float32),\n",
       "    array([-0.03862222,  0.04131657], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57805878,  0.58599222],\n",
       "           [ 1.15607834,  0.24936627]], dtype=float32),\n",
       "    array([[ 0.30649808, -0.8932364 ],\n",
       "           [-0.9625988 , -0.31064141]], dtype=float32),\n",
       "    array([-0.03950703,  0.04223736], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57805878,  0.58599222],\n",
       "           [ 1.15607834,  0.24936627]], dtype=float32),\n",
       "    array([[ 0.30649808, -0.8932364 ],\n",
       "           [-0.9625988 , -0.31064141]], dtype=float32),\n",
       "    array([-0.03950703,  0.04223736], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57707262,  0.58691406],\n",
       "           [ 1.15504038,  0.25018388]], dtype=float32),\n",
       "    array([[ 0.30567831, -0.8921656 ],\n",
       "           [-0.96336579, -0.30993369]], dtype=float32),\n",
       "    array([-0.04043621,  0.04318941], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57707262,  0.58691406],\n",
       "           [ 1.15504038,  0.25018388]], dtype=float32),\n",
       "    array([[ 0.30567831, -0.8921656 ],\n",
       "           [-0.96336579, -0.30993369]], dtype=float32),\n",
       "    array([-0.04043621,  0.04318941], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57608128,  0.58776647],\n",
       "           [ 1.15398467,  0.25096065]], dtype=float32),\n",
       "    array([[ 0.30486795, -0.89110768],\n",
       "           [-0.96412176, -0.30911952]], dtype=float32),\n",
       "    array([-0.04136794,  0.0440705 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57608128,  0.58776647],\n",
       "           [ 1.15398467,  0.25096065]], dtype=float32),\n",
       "    array([[ 0.30486795, -0.89110768],\n",
       "           [-0.96412176, -0.30911952]], dtype=float32),\n",
       "    array([-0.04136794,  0.0440705 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57511634,  0.58862162],\n",
       "           [ 1.15295053,  0.25176874]], dtype=float32),\n",
       "    array([[ 0.30411416, -0.89008975],\n",
       "           [-0.96483099, -0.3083066 ]], dtype=float32),\n",
       "    array([-0.04228898,  0.04494817], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57511634,  0.58862162],\n",
       "           [ 1.15295053,  0.25176874]], dtype=float32),\n",
       "    array([[ 0.30411416, -0.89008975],\n",
       "           [-0.96483099, -0.3083066 ]], dtype=float32),\n",
       "    array([-0.04228898,  0.04494817], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57415831,  0.58955723],\n",
       "           [ 1.15191126,  0.25262192]], dtype=float32),\n",
       "    array([[ 0.30336484, -0.88906866],\n",
       "           [-0.96559191, -0.30750978]], dtype=float32),\n",
       "    array([-0.04318742,  0.04587327], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57415831,  0.58955723],\n",
       "           [ 1.15191126,  0.25262192]], dtype=float32),\n",
       "    array([[ 0.30336484, -0.88906866],\n",
       "           [-0.96559191, -0.30750978]], dtype=float32),\n",
       "    array([-0.04318742,  0.04587327], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57323068,  0.59041822],\n",
       "           [ 1.15089822,  0.25346798]], dtype=float32),\n",
       "    array([[ 0.30267808, -0.88808376],\n",
       "           [-0.966263  , -0.30664971]], dtype=float32),\n",
       "    array([-0.04406949,  0.04674689], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57323068,  0.59041822],\n",
       "           [ 1.15089822,  0.25346798]], dtype=float32),\n",
       "    array([[ 0.30267808, -0.88808376],\n",
       "           [-0.966263  , -0.30664971]], dtype=float32),\n",
       "    array([-0.04406949,  0.04674689], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57232803,  0.59121567],\n",
       "           [ 1.14990509,  0.25419885]], dtype=float32),\n",
       "    array([[ 0.30204186, -0.88710564],\n",
       "           [-0.96685737, -0.30572677]], dtype=float32),\n",
       "    array([-0.04492997,  0.04754188], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57232803,  0.59121567],\n",
       "           [ 1.14990509,  0.25419885]], dtype=float32),\n",
       "    array([[ 0.30204186, -0.88710564],\n",
       "           [-0.96685737, -0.30572677]], dtype=float32),\n",
       "    array([-0.04492997,  0.04754188], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57141393,  0.5920316 ],\n",
       "           [ 1.14894831,  0.25490305]], dtype=float32),\n",
       "    array([[ 0.30143237, -0.88616258],\n",
       "           [-0.96748042, -0.30483329]], dtype=float32),\n",
       "    array([-0.0457627 ,  0.04836015], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57141393,  0.5920316 ],\n",
       "           [ 1.14894831,  0.25490305]], dtype=float32),\n",
       "    array([[ 0.30143237, -0.88616258],\n",
       "           [-0.96748042, -0.30483329]], dtype=float32),\n",
       "    array([-0.0457627 ,  0.04836015], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.57057458,  0.59270817],\n",
       "           [ 1.14812756,  0.25554514]], dtype=float32),\n",
       "    array([[ 0.30095816, -0.88525248],\n",
       "           [-0.96782857, -0.30388182]], dtype=float32),\n",
       "    array([-0.04650903,  0.04912403], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.57057458,  0.59270817],\n",
       "           [ 1.14812756,  0.25554514]], dtype=float32),\n",
       "    array([[ 0.30095816, -0.88525248],\n",
       "           [-0.96782857, -0.30388182]], dtype=float32),\n",
       "    array([-0.04650903,  0.04912403], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56983912,  0.59327817],\n",
       "           [ 1.14737427,  0.25599471]], dtype=float32),\n",
       "    array([[ 0.3007133 , -0.88438123],\n",
       "           [-0.96797627, -0.30287826]], dtype=float32),\n",
       "    array([-0.04711226,  0.04973429], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56983912,  0.59327817],\n",
       "           [ 1.14737427,  0.25599471]], dtype=float32),\n",
       "    array([[ 0.3007133 , -0.88438123],\n",
       "           [-0.96797627, -0.30287826]], dtype=float32),\n",
       "    array([-0.04711226,  0.04973429], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56911999,  0.59385324],\n",
       "           [ 1.14656138,  0.25643936]], dtype=float32),\n",
       "    array([[ 0.30042267, -0.88349551],\n",
       "           [-0.96818632, -0.30186692]], dtype=float32),\n",
       "    array([-0.04775091,  0.050355  ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56911999,  0.59385324],\n",
       "           [ 1.14656138,  0.25643936]], dtype=float32),\n",
       "    array([[ 0.30042267, -0.88349551],\n",
       "           [-0.96818632, -0.30186692]], dtype=float32),\n",
       "    array([-0.04775091,  0.050355  ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56845063,  0.59435117],\n",
       "           [ 1.14587164,  0.25688195]], dtype=float32),\n",
       "    array([[ 0.30019304, -0.88263994],\n",
       "           [-0.96830291, -0.30076262]], dtype=float32),\n",
       "    array([-0.04826543,  0.0509592 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56845063,  0.59435117],\n",
       "           [ 1.14587164,  0.25688195]], dtype=float32),\n",
       "    array([[ 0.30019304, -0.88263994],\n",
       "           [-0.96830291, -0.30076262]], dtype=float32),\n",
       "    array([-0.04826543,  0.0509592 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5677374 ,  0.59490252],\n",
       "           [ 1.14508486,  0.25740016]], dtype=float32),\n",
       "    array([[ 0.29984123, -0.88175344],\n",
       "           [-0.96852815, -0.29972038]], dtype=float32),\n",
       "    array([-0.04886453,  0.0515845 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5677374 ,  0.59490252],\n",
       "           [ 1.14508486,  0.25740016]], dtype=float32),\n",
       "    array([[ 0.29984123, -0.88175344],\n",
       "           [-0.96852815, -0.29972038]], dtype=float32),\n",
       "    array([-0.04886453,  0.0515845 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56706446,  0.59540725],\n",
       "           [ 1.14433503,  0.257918  ]], dtype=float32),\n",
       "    array([[ 0.29954571, -0.88089663],\n",
       "           [-0.96868062, -0.29872   ]], dtype=float32),\n",
       "    array([-0.04941227,  0.05216384], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56706446,  0.59540725],\n",
       "           [ 1.14433503,  0.257918  ]], dtype=float32),\n",
       "    array([[ 0.29954571, -0.88089663],\n",
       "           [-0.96868062, -0.29872   ]], dtype=float32),\n",
       "    array([-0.04941227,  0.05216384], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56627136,  0.59601748],\n",
       "           [ 1.14349294,  0.2585085 ]], dtype=float32),\n",
       "    array([[ 0.29914406, -0.88000548],\n",
       "           [-0.96895647, -0.29769328]], dtype=float32),\n",
       "    array([-0.05012431,  0.05283077], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56627136,  0.59601748],\n",
       "           [ 1.14349294,  0.2585085 ]], dtype=float32),\n",
       "    array([[ 0.29914406, -0.88000548],\n",
       "           [-0.96895647, -0.29769328]], dtype=float32),\n",
       "    array([-0.05012431,  0.05283077], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56544328,  0.59664911],\n",
       "           [ 1.14262438,  0.2591241 ]], dtype=float32),\n",
       "    array([[ 0.29870084, -0.87908936],\n",
       "           [-0.96930712, -0.29668683]], dtype=float32),\n",
       "    array([-0.05085161,  0.05354911], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56544328,  0.59664911],\n",
       "           [ 1.14262438,  0.2591241 ]], dtype=float32),\n",
       "    array([[ 0.29870084, -0.87908936],\n",
       "           [-0.96930712, -0.29668683]], dtype=float32),\n",
       "    array([-0.05085161,  0.05354911], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56466967,  0.59726048],\n",
       "           [ 1.14175463,  0.25972202]], dtype=float32),\n",
       "    array([[ 0.29831296, -0.87820661],\n",
       "           [-0.9697265 , -0.29585037]], dtype=float32),\n",
       "    array([-0.05154708,  0.0542712 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56466967,  0.59726048],\n",
       "           [ 1.14175463,  0.25972202]], dtype=float32),\n",
       "    array([[ 0.29831296, -0.87820661],\n",
       "           [-0.9697265 , -0.29585037]], dtype=float32),\n",
       "    array([-0.05154708,  0.0542712 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5639264 ,  0.59789342],\n",
       "           [ 1.14090633,  0.26036364]], dtype=float32),\n",
       "    array([[ 0.29792279, -0.87732273],\n",
       "           [-0.97016895, -0.2950182 ]], dtype=float32),\n",
       "    array([-0.05222075,  0.05502187], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5639264 ,  0.59789342],\n",
       "           [ 1.14090633,  0.26036364]], dtype=float32),\n",
       "    array([[ 0.29792279, -0.87732273],\n",
       "           [-0.97016895, -0.2950182 ]], dtype=float32),\n",
       "    array([-0.05222075,  0.05502187], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56314963,  0.59861344],\n",
       "           [ 1.14002192,  0.26110235]], dtype=float32),\n",
       "    array([[ 0.2974875 , -0.87638682],\n",
       "           [-0.97066844, -0.29415473]], dtype=float32),\n",
       "    array([-0.05290467,  0.05582415], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56314963,  0.59861344],\n",
       "           [ 1.14002192,  0.26110235]], dtype=float32),\n",
       "    array([[ 0.2974875 , -0.87638682],\n",
       "           [-0.97066844, -0.29415473]], dtype=float32),\n",
       "    array([-0.05290467,  0.05582415], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56236517,  0.59940428],\n",
       "           [ 1.13907731,  0.26196897]], dtype=float32),\n",
       "    array([[ 0.29699227, -0.87542313],\n",
       "           [-0.97120494, -0.29329994]], dtype=float32),\n",
       "    array([-0.05362311,  0.05670608], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56236517,  0.59940428],\n",
       "           [ 1.13907731,  0.26196897]], dtype=float32),\n",
       "    array([[ 0.29699227, -0.87542313],\n",
       "           [-0.97120494, -0.29329994]], dtype=float32),\n",
       "    array([-0.05362311,  0.05670608], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56150818,  0.60028267],\n",
       "           [ 1.13812375,  0.26287669]], dtype=float32),\n",
       "    array([[ 0.29643092, -0.87443399],\n",
       "           [-0.97177094, -0.29239631]], dtype=float32),\n",
       "    array([-0.05443185,  0.05767332], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56150818,  0.60028267],\n",
       "           [ 1.13812375,  0.26287669]], dtype=float32),\n",
       "    array([[ 0.29643092, -0.87443399],\n",
       "           [-0.97177094, -0.29239631]], dtype=float32),\n",
       "    array([-0.05443185,  0.05767332], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.56055808,  0.60117197],\n",
       "           [ 1.13716424,  0.26377439]], dtype=float32),\n",
       "    array([[ 0.29581869, -0.8734349 ],\n",
       "           [-0.97237265, -0.29147488]], dtype=float32),\n",
       "    array([-0.05529974,  0.05861686], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.56055808,  0.60117197],\n",
       "           [ 1.13716424,  0.26377439]], dtype=float32),\n",
       "    array([[ 0.29581869, -0.8734349 ],\n",
       "           [-0.97237265, -0.29147488]], dtype=float32),\n",
       "    array([-0.05529974,  0.05861686], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55958045,  0.60203683],\n",
       "           [ 1.13621354,  0.26457039]], dtype=float32),\n",
       "    array([[ 0.295275  , -0.87242424],\n",
       "           [-0.97288328, -0.29044378]], dtype=float32),\n",
       "    array([-0.05618165,  0.05952126], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55958045,  0.60203683],\n",
       "           [ 1.13621354,  0.26457039]], dtype=float32),\n",
       "    array([[ 0.295275  , -0.87242424],\n",
       "           [-0.97288328, -0.29044378]], dtype=float32),\n",
       "    array([-0.05618165,  0.05952126], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55862606,  0.60285288],\n",
       "           [ 1.13527548,  0.26522118]], dtype=float32),\n",
       "    array([[ 0.29475102, -0.87141532],\n",
       "           [-0.97339475, -0.28939697]], dtype=float32),\n",
       "    array([-0.0570089 ,  0.06033455], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55862606,  0.60285288],\n",
       "           [ 1.13527548,  0.26522118]], dtype=float32),\n",
       "    array([[ 0.29475102, -0.87141532],\n",
       "           [-0.97339475, -0.28939697]], dtype=float32),\n",
       "    array([-0.0570089 ,  0.06033455], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55772841,  0.60355693],\n",
       "           [ 1.13438463,  0.26585007]], dtype=float32),\n",
       "    array([[ 0.29429165, -0.87043118],\n",
       "           [-0.97383469, -0.28845373]], dtype=float32),\n",
       "    array([-0.0577723 ,  0.06109935], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55772841,  0.60355693],\n",
       "           [ 1.13438463,  0.26585007]], dtype=float32),\n",
       "    array([[ 0.29429165, -0.87043118],\n",
       "           [-0.97383469, -0.28845373]], dtype=float32),\n",
       "    array([-0.0577723 ,  0.06109935], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55686694,  0.60418183],\n",
       "           [ 1.13349199,  0.2664189 ]], dtype=float32),\n",
       "    array([[ 0.29385716, -0.86945945],\n",
       "           [-0.97422713, -0.28744814]], dtype=float32),\n",
       "    array([-0.05852288,  0.06180162], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55686694,  0.60418183],\n",
       "           [ 1.13349199,  0.2664189 ]], dtype=float32),\n",
       "    array([[ 0.29385716, -0.86945945],\n",
       "           [-0.97422713, -0.28744814]], dtype=float32),\n",
       "    array([-0.05852288,  0.06180162], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55613393,  0.6047622 ],\n",
       "           [ 1.13269484,  0.26687247]], dtype=float32),\n",
       "    array([[ 0.29361603, -0.8685059 ],\n",
       "           [-0.97442216, -0.28642526]], dtype=float32),\n",
       "    array([-0.05915461,  0.06245048], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55613393,  0.6047622 ],\n",
       "           [ 1.13269484,  0.26687247]], dtype=float32),\n",
       "    array([[ 0.29361603, -0.8685059 ],\n",
       "           [-0.97442216, -0.28642526]], dtype=float32),\n",
       "    array([-0.05915461,  0.06245048], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55554974,  0.60526472],\n",
       "           [ 1.131984  ,  0.26716205]], dtype=float32),\n",
       "    array([[ 0.29351223, -0.86760777],\n",
       "           [-0.97454578, -0.28547353]], dtype=float32),\n",
       "    array([-0.05964713,  0.06297159], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55554974,  0.60526472],\n",
       "           [ 1.131984  ,  0.26716205]], dtype=float32),\n",
       "    array([[ 0.29351223, -0.86760777],\n",
       "           [-0.97454578, -0.28547353]], dtype=float32),\n",
       "    array([-0.05964713,  0.06297159], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55497134,  0.6056655 ],\n",
       "           [ 1.13131678,  0.26739436]], dtype=float32),\n",
       "    array([[ 0.2935141 , -0.8667264 ],\n",
       "           [-0.97446513, -0.28451157]], dtype=float32),\n",
       "    array([-0.06010582,  0.06347271], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55497134,  0.6056655 ],\n",
       "           [ 1.13131678,  0.26739436]], dtype=float32),\n",
       "    array([[ 0.2935141 , -0.8667264 ],\n",
       "           [-0.97446513, -0.28451157]], dtype=float32),\n",
       "    array([-0.06010582,  0.06347271], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55439919,  0.60613203],\n",
       "           [ 1.13062465,  0.2676841 ]], dtype=float32),\n",
       "    array([[ 0.29346314, -0.86585891],\n",
       "           [-0.97443682, -0.28345981]], dtype=float32),\n",
       "    array([-0.06058496,  0.0640255 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55439919,  0.60613203],\n",
       "           [ 1.13062465,  0.2676841 ]], dtype=float32),\n",
       "    array([[ 0.29346314, -0.86585891],\n",
       "           [-0.97443682, -0.28345981]], dtype=float32),\n",
       "    array([-0.06058496,  0.0640255 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55390483,  0.60649085],\n",
       "           [ 1.12999225,  0.26783878]], dtype=float32),\n",
       "    array([[ 0.29354134, -0.86501867],\n",
       "           [-0.97427529, -0.28242773]], dtype=float32),\n",
       "    array([-0.06094936,  0.06448085], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55390483,  0.60649085],\n",
       "           [ 1.12999225,  0.26783878]], dtype=float32),\n",
       "    array([[ 0.29354134, -0.86501867],\n",
       "           [-0.97427529, -0.28242773]], dtype=float32),\n",
       "    array([-0.06094936,  0.06448085], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55337006,  0.60684645],\n",
       "           [ 1.12934434,  0.26800963]], dtype=float32),\n",
       "    array([[ 0.29355744, -0.86419791],\n",
       "           [-0.97426623, -0.28142565]], dtype=float32),\n",
       "    array([-0.06129653,  0.06496507], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55337006,  0.60684645],\n",
       "           [ 1.12934434,  0.26800963]], dtype=float32),\n",
       "    array([[ 0.29355744, -0.86419791],\n",
       "           [-0.97426623, -0.28142565]], dtype=float32),\n",
       "    array([-0.06129653,  0.06496507], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55289245,  0.60727668],\n",
       "           [ 1.12868738,  0.26832554]], dtype=float32),\n",
       "    array([[ 0.2935549 , -0.86335266],\n",
       "           [-0.97425663, -0.28044602]], dtype=float32),\n",
       "    array([-0.06161996,  0.06553572], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55289245,  0.60727668],\n",
       "           [ 1.12868738,  0.26832554]], dtype=float32),\n",
       "    array([[ 0.2935549 , -0.86335266],\n",
       "           [-0.97425663, -0.28044602]], dtype=float32),\n",
       "    array([-0.06161996,  0.06553572], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5523904 ,  0.60779083],\n",
       "           [ 1.12799978,  0.26873314]], dtype=float32),\n",
       "    array([[ 0.29355261, -0.86251801],\n",
       "           [-0.97431272, -0.27953401]], dtype=float32),\n",
       "    array([-0.06201317,  0.06618166], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5523904 ,  0.60779083],\n",
       "           [ 1.12799978,  0.26873314]], dtype=float32),\n",
       "    array([[ 0.29355261, -0.86251801],\n",
       "           [-0.97431272, -0.27953401]], dtype=float32),\n",
       "    array([-0.06201317,  0.06618166], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55181473,  0.60829359],\n",
       "           [ 1.12729418,  0.26905584]], dtype=float32),\n",
       "    array([[ 0.29353538, -0.86165386],\n",
       "           [-0.97433883, -0.27852941]], dtype=float32),\n",
       "    array([-0.06245292,  0.06680204], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55181473,  0.60829359],\n",
       "           [ 1.12729418,  0.26905584]], dtype=float32),\n",
       "    array([[ 0.29353538, -0.86165386],\n",
       "           [-0.97433883, -0.27852941]], dtype=float32),\n",
       "    array([-0.06245292,  0.06680204], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55123955,  0.60875642],\n",
       "           [ 1.12663126,  0.26941842]], dtype=float32),\n",
       "    array([[ 0.29354182, -0.86082125],\n",
       "           [-0.97430837, -0.27753177]], dtype=float32),\n",
       "    array([-0.06287266,  0.06737578], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55123955,  0.60875642],\n",
       "           [ 1.12663126,  0.26941842]], dtype=float32),\n",
       "    array([[ 0.29354182, -0.86082125],\n",
       "           [-0.97430837, -0.27753177]], dtype=float32),\n",
       "    array([-0.06287266,  0.06737578], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.55065799,  0.60919404],\n",
       "           [ 1.12595439,  0.2698276 ]], dtype=float32),\n",
       "    array([[ 0.29353857, -0.8599447 ],\n",
       "           [-0.97424507, -0.27654809]], dtype=float32),\n",
       "    array([-0.06331144,  0.06794884], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.55065799,  0.60919404],\n",
       "           [ 1.12595439,  0.2698276 ]], dtype=float32),\n",
       "    array([[ 0.29353857, -0.8599447 ],\n",
       "           [-0.97424507, -0.27654809]], dtype=float32),\n",
       "    array([-0.06331144,  0.06794884], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5500949 ,  0.609707  ],\n",
       "           [ 1.12530673,  0.27028739]], dtype=float32),\n",
       "    array([[ 0.29352558, -0.85907525],\n",
       "           [-0.97426122, -0.27556321]], dtype=float32),\n",
       "    array([-0.06370477,  0.0686032 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5500949 ,  0.609707  ],\n",
       "           [ 1.12530673,  0.27028739]], dtype=float32),\n",
       "    array([[ 0.29352558, -0.85907525],\n",
       "           [-0.97426122, -0.27556321]], dtype=float32),\n",
       "    array([-0.06370477,  0.0686032 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54942292,  0.61027431],\n",
       "           [ 1.12456608,  0.27081096]], dtype=float32),\n",
       "    array([[ 0.29340544, -0.85820293],\n",
       "           [-0.9743852 , -0.27448183]], dtype=float32),\n",
       "    array([-0.06425076,  0.06932083], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54942292,  0.61027431],\n",
       "           [ 1.12456608,  0.27081096]], dtype=float32),\n",
       "    array([[ 0.29340544, -0.85820293],\n",
       "           [-0.9743852 , -0.27448183]], dtype=float32),\n",
       "    array([-0.06425076,  0.06932083], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54873431,  0.61089772],\n",
       "           [ 1.1237886 ,  0.27137744]], dtype=float32),\n",
       "    array([[ 0.29324988, -0.85732913],\n",
       "           [-0.97460824, -0.273469  ]], dtype=float32),\n",
       "    array([-0.06484489,  0.07006489], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54873431,  0.61089772],\n",
       "           [ 1.1237886 ,  0.27137744]], dtype=float32),\n",
       "    array([[ 0.29324988, -0.85732913],\n",
       "           [-0.97460824, -0.273469  ]], dtype=float32),\n",
       "    array([-0.06484489,  0.07006489], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54811317,  0.61145276],\n",
       "           [ 1.12308538,  0.27189615]], dtype=float32),\n",
       "    array([[ 0.29315764, -0.85648501],\n",
       "           [-0.97476757, -0.27254042]], dtype=float32),\n",
       "    array([-0.06536528,  0.07075907], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54811317,  0.61145276],\n",
       "           [ 1.12308538,  0.27189615]], dtype=float32),\n",
       "    array([[ 0.29315764, -0.85648501],\n",
       "           [-0.97476757, -0.27254042]], dtype=float32),\n",
       "    array([-0.06536528,  0.07075907], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54757595,  0.61191416],\n",
       "           [ 1.12243831,  0.27224448]], dtype=float32),\n",
       "    array([[ 0.2932511 , -0.85567033],\n",
       "           [-0.97473341, -0.27157277]], dtype=float32),\n",
       "    array([-0.06576473,  0.07131032], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54757595,  0.61191416],\n",
       "           [ 1.12243831,  0.27224448]], dtype=float32),\n",
       "    array([[ 0.2932511 , -0.85567033],\n",
       "           [-0.97473341, -0.27157277]], dtype=float32),\n",
       "    array([-0.06576473,  0.07131032], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54689687,  0.61244082],\n",
       "           [ 1.12168097,  0.27262762]], dtype=float32),\n",
       "    array([[ 0.29311642, -0.8548438 ],\n",
       "           [-0.97488111, -0.27063277]], dtype=float32),\n",
       "    array([-0.06632917,  0.07191729], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54689687,  0.61244082],\n",
       "           [ 1.12168097,  0.27262762]], dtype=float32),\n",
       "    array([[ 0.29311642, -0.8548438 ],\n",
       "           [-0.97488111, -0.27063277]], dtype=float32),\n",
       "    array([-0.06632917,  0.07191729], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54614323,  0.61305416],\n",
       "           [ 1.1208986 ,  0.27310264]], dtype=float32),\n",
       "    array([[ 0.29290941, -0.85400039],\n",
       "           [-0.97515965, -0.2697061 ]], dtype=float32),\n",
       "    array([-0.06695756,  0.07263311], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54614323,  0.61305416],\n",
       "           [ 1.1208986 ,  0.27310264]], dtype=float32),\n",
       "    array([[ 0.29290941, -0.85400039],\n",
       "           [-0.97515965, -0.2697061 ]], dtype=float32),\n",
       "    array([-0.06695756,  0.07263311], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54531413,  0.61377031],\n",
       "           [ 1.12004411,  0.27367288]], dtype=float32),\n",
       "    array([[ 0.29262304, -0.85310006],\n",
       "           [-0.97550189, -0.26872164]], dtype=float32),\n",
       "    array([-0.06766386,  0.07339578], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54531413,  0.61377031],\n",
       "           [ 1.12004411,  0.27367288]], dtype=float32),\n",
       "    array([[ 0.29262304, -0.85310006],\n",
       "           [-0.97550189, -0.26872164]], dtype=float32),\n",
       "    array([-0.06766386,  0.07339578], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54457498,  0.6144017 ],\n",
       "           [ 1.1191529 ,  0.2740759 ]], dtype=float32),\n",
       "    array([[ 0.29245991, -0.85220701],\n",
       "           [-0.97576213, -0.26773602]], dtype=float32),\n",
       "    array([-0.06832018,  0.07407354], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54457498,  0.6144017 ],\n",
       "           [ 1.1191529 ,  0.2740759 ]], dtype=float32),\n",
       "    array([[ 0.29245991, -0.85220701],\n",
       "           [-0.97576213, -0.26773602]], dtype=float32),\n",
       "    array([-0.06832018,  0.07407354], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54389262,  0.61492264],\n",
       "           [ 1.11830258,  0.2742919 ]], dtype=float32),\n",
       "    array([[ 0.29237542, -0.85133088],\n",
       "           [-0.97592723, -0.2666629 ]], dtype=float32),\n",
       "    array([-0.06890621,  0.07461578], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54389262,  0.61492264],\n",
       "           [ 1.11830258,  0.2742919 ]], dtype=float32),\n",
       "    array([[ 0.29237542, -0.85133088],\n",
       "           [-0.97592723, -0.2666629 ]], dtype=float32),\n",
       "    array([-0.06890621,  0.07461578], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54326785,  0.61541837],\n",
       "           [ 1.11745918,  0.27450415]], dtype=float32),\n",
       "    array([[ 0.29233572, -0.85049361],\n",
       "           [-0.97606748, -0.2656121 ]], dtype=float32),\n",
       "    array([-0.06947006,  0.07512316], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54326785,  0.61541837],\n",
       "           [ 1.11745918,  0.27450415]], dtype=float32),\n",
       "    array([[ 0.29233572, -0.85049361],\n",
       "           [-0.97606748, -0.2656121 ]], dtype=float32),\n",
       "    array([-0.06947006,  0.07512316], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54268515,  0.61580628],\n",
       "           [ 1.11673927,  0.27470866]], dtype=float32),\n",
       "    array([[ 0.29238799, -0.849666  ],\n",
       "           [-0.97597677, -0.26450664]], dtype=float32),\n",
       "    array([-0.06997623,  0.07561401], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54268515,  0.61580628],\n",
       "           [ 1.11673927,  0.27470866]], dtype=float32),\n",
       "    array([[ 0.29238799, -0.849666  ],\n",
       "           [-0.97597677, -0.26450664]], dtype=float32),\n",
       "    array([-0.06997623,  0.07561401], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54201078,  0.61629641],\n",
       "           [ 1.11591971,  0.27505058]], dtype=float32),\n",
       "    array([[ 0.29225963, -0.84879476],\n",
       "           [-0.9760828 , -0.26339057]], dtype=float32),\n",
       "    array([-0.07056808,  0.07620385], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54201078,  0.61629641],\n",
       "           [ 1.11591971,  0.27505058]], dtype=float32),\n",
       "    array([[ 0.29225963, -0.84879476],\n",
       "           [-0.9760828 , -0.26339057]], dtype=float32),\n",
       "    array([-0.07056808,  0.07620385], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54134166,  0.61680555],\n",
       "           [ 1.11500573,  0.27552107]], dtype=float32),\n",
       "    array([[ 0.29205307, -0.84791988],\n",
       "           [-0.97624063, -0.26227349]], dtype=float32),\n",
       "    array([-0.07121851,  0.07684948], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54134166,  0.61680555],\n",
       "           [ 1.11500573,  0.27552107]], dtype=float32),\n",
       "    array([[ 0.29205307, -0.84791988],\n",
       "           [-0.97624063, -0.26227349]], dtype=float32),\n",
       "    array([-0.07121851,  0.07684948], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54072618,  0.61729264],\n",
       "           [ 1.11410213,  0.27596506]], dtype=float32),\n",
       "    array([[ 0.29190266, -0.84707999],\n",
       "           [-0.97637451, -0.26117885]], dtype=float32),\n",
       "    array([-0.07184328,  0.07745304], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54072618,  0.61729264],\n",
       "           [ 1.11410213,  0.27596506]], dtype=float32),\n",
       "    array([[ 0.29190266, -0.84707999],\n",
       "           [-0.97637451, -0.26117885]], dtype=float32),\n",
       "    array([-0.07184328,  0.07745304], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.54004049,  0.6177364 ],\n",
       "           [ 1.11312437,  0.27641782]], dtype=float32),\n",
       "    array([[ 0.29165083, -0.84624362],\n",
       "           [-0.97663361, -0.26004827]], dtype=float32),\n",
       "    array([-0.07256623,  0.07804377], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.54004049,  0.6177364 ],\n",
       "           [ 1.11312437,  0.27641782]], dtype=float32),\n",
       "    array([[ 0.29165083, -0.84624362],\n",
       "           [-0.97663361, -0.26004827]], dtype=float32),\n",
       "    array([-0.07256623,  0.07804377], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53917563,  0.61833197],\n",
       "           [ 1.11210167,  0.27697328]], dtype=float32),\n",
       "    array([[ 0.29125014, -0.84537512],\n",
       "           [-0.97706962, -0.25885445]], dtype=float32),\n",
       "    array([-0.07346464,  0.07879517], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53917563,  0.61833197],\n",
       "           [ 1.11210167,  0.27697328]], dtype=float32),\n",
       "    array([[ 0.29125014, -0.84537512],\n",
       "           [-0.97706962, -0.25885445]], dtype=float32),\n",
       "    array([-0.07346464,  0.07879517], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53834718,  0.61885709],\n",
       "           [ 1.11112046,  0.27755424]], dtype=float32),\n",
       "    array([[ 0.29088452, -0.84450829],\n",
       "           [-0.97742003, -0.25768507]], dtype=float32),\n",
       "    array([-0.0743057 ,  0.07950597], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53834718,  0.61885709],\n",
       "           [ 1.11112046,  0.27755424]], dtype=float32),\n",
       "    array([[ 0.29088452, -0.84450829],\n",
       "           [-0.97742003, -0.25768507]], dtype=float32),\n",
       "    array([-0.0743057 ,  0.07950597], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53748167,  0.61944324],\n",
       "           [ 1.11012936,  0.27815592]], dtype=float32),\n",
       "    array([[ 0.2905049 , -0.8436287 ],\n",
       "           [-0.97781622, -0.25654158]], dtype=float32),\n",
       "    array([-0.07516628,  0.08024678], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53748167,  0.61944324],\n",
       "           [ 1.11012936,  0.27815592]], dtype=float32),\n",
       "    array([[ 0.2905049 , -0.8436287 ],\n",
       "           [-0.97781622, -0.25654158]], dtype=float32),\n",
       "    array([-0.07516628,  0.08024678], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5366869 ,  0.62001002],\n",
       "           [ 1.10912573,  0.27859625]], dtype=float32),\n",
       "    array([[ 0.29021445, -0.84274936],\n",
       "           [-0.97815377, -0.25539207]], dtype=float32),\n",
       "    array([-0.07597101,  0.08091242], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5366869 ,  0.62001002],\n",
       "           [ 1.10912573,  0.27859625]], dtype=float32),\n",
       "    array([[ 0.29021445, -0.84274936],\n",
       "           [-0.97815377, -0.25539207]], dtype=float32),\n",
       "    array([-0.07597101,  0.08091242], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53596509,  0.62047577],\n",
       "           [ 1.10814726,  0.2789242 ]], dtype=float32),\n",
       "    array([[ 0.29003873, -0.841887  ],\n",
       "           [-0.97841215, -0.25426763]], dtype=float32),\n",
       "    array([-0.07670821,  0.0815196 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53596509,  0.62047577],\n",
       "           [ 1.10814726,  0.2789242 ]], dtype=float32),\n",
       "    array([[ 0.29003873, -0.841887  ],\n",
       "           [-0.97841215, -0.25426763]], dtype=float32),\n",
       "    array([-0.07670821,  0.0815196 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53538799,  0.62087655],\n",
       "           [ 1.10727036,  0.27899936]], dtype=float32),\n",
       "    array([[ 0.29005009, -0.84105086],\n",
       "           [-0.97850668, -0.25314111]], dtype=float32),\n",
       "    array([-0.07726976,  0.08193404], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53538799,  0.62087655],\n",
       "           [ 1.10727036,  0.27899936]], dtype=float32),\n",
       "    array([[ 0.29005009, -0.84105086],\n",
       "           [-0.97850668, -0.25314111]], dtype=float32),\n",
       "    array([-0.07726976,  0.08193404], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53491116,  0.62119287],\n",
       "           [ 1.10651231,  0.27903724]], dtype=float32),\n",
       "    array([[ 0.29012057, -0.84028715],\n",
       "           [-0.97855669, -0.25216484]], dtype=float32),\n",
       "    array([-0.07770243,  0.08231472], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53491116,  0.62119287],\n",
       "           [ 1.10651231,  0.27903724]], dtype=float32),\n",
       "    array([[ 0.29012057, -0.84028715],\n",
       "           [-0.97855669, -0.25216484]], dtype=float32),\n",
       "    array([-0.07770243,  0.08231472], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53430587,  0.62161094],\n",
       "           [ 1.10567486,  0.27917045]], dtype=float32),\n",
       "    array([[ 0.29007125, -0.83948308],\n",
       "           [-0.97878373, -0.25117552]], dtype=float32),\n",
       "    array([-0.07825266,  0.08278143], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53430587,  0.62161094],\n",
       "           [ 1.10567486,  0.27917045]], dtype=float32),\n",
       "    array([[ 0.29007125, -0.83948308],\n",
       "           [-0.97878373, -0.25117552]], dtype=float32),\n",
       "    array([-0.07825266,  0.08278143], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53376466,  0.62198502],\n",
       "           [ 1.10489535,  0.27927893]], dtype=float32),\n",
       "    array([[ 0.29008192, -0.83878666],\n",
       "           [-0.9790231 , -0.25045219]], dtype=float32),\n",
       "    array([-0.07872126,  0.083249  ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53376466,  0.62198502],\n",
       "           [ 1.10489535,  0.27927893]], dtype=float32),\n",
       "    array([[ 0.29008192, -0.83878666],\n",
       "           [-0.9790231 , -0.25045219]], dtype=float32),\n",
       "    array([-0.07872126,  0.083249  ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53326386,  0.62241679],\n",
       "           [ 1.10416114,  0.2794193 ]], dtype=float32),\n",
       "    array([[ 0.29009977, -0.83809036],\n",
       "           [-0.97929525, -0.24972199]], dtype=float32),\n",
       "    array([-0.07912163,  0.08376212], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53326386,  0.62241679],\n",
       "           [ 1.10416114,  0.2794193 ]], dtype=float32),\n",
       "    array([[ 0.29009977, -0.83809036],\n",
       "           [-0.97929525, -0.24972199]], dtype=float32),\n",
       "    array([-0.07912163,  0.08376212], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53278381,  0.62273884],\n",
       "           [ 1.1035676 ,  0.27956095]], dtype=float32),\n",
       "    array([[ 0.29027286, -0.83738911],\n",
       "           [-0.97927153, -0.24884923]], dtype=float32),\n",
       "    array([-0.0794228 ,  0.08423152], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53278381,  0.62273884],\n",
       "           [ 1.1035676 ,  0.27956095]], dtype=float32),\n",
       "    array([[ 0.29027286, -0.83738911],\n",
       "           [-0.97927153, -0.24884923]], dtype=float32),\n",
       "    array([-0.0794228 ,  0.08423152], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53221518,  0.62309605],\n",
       "           [ 1.10288441,  0.27977577]], dtype=float32),\n",
       "    array([[ 0.2903161 , -0.83664292],\n",
       "           [-0.97935832, -0.24795814]], dtype=float32),\n",
       "    array([-0.07981674,  0.08473247], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53221518,  0.62309605],\n",
       "           [ 1.10288441,  0.27977577]], dtype=float32),\n",
       "    array([[ 0.2903161 , -0.83664292],\n",
       "           [-0.97935832, -0.24795814]], dtype=float32),\n",
       "    array([-0.07981674,  0.08473247], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53166598,  0.62349224],\n",
       "           [ 1.1021682 ,  0.27997744]], dtype=float32),\n",
       "    array([[ 0.29042342, -0.83587897],\n",
       "           [-0.979361  , -0.24698597]], dtype=float32),\n",
       "    array([-0.08025952,  0.08524764], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53166598,  0.62349224],\n",
       "           [ 1.1021682 ,  0.27997744]], dtype=float32),\n",
       "    array([[ 0.29042342, -0.83587897],\n",
       "           [-0.979361  , -0.24698597]], dtype=float32),\n",
       "    array([-0.08025952,  0.08524764], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53124094,  0.62386012],\n",
       "           [ 1.10155928,  0.28010103]], dtype=float32),\n",
       "    array([[ 0.29066476, -0.8350898 ],\n",
       "           [-0.97917753, -0.24595051]], dtype=float32),\n",
       "    array([-0.08055301,  0.08572307], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53124094,  0.62386012],\n",
       "           [ 1.10155928,  0.28010103]], dtype=float32),\n",
       "    array([[ 0.29066476, -0.8350898 ],\n",
       "           [-0.97917753, -0.24595051]], dtype=float32),\n",
       "    array([-0.08055301,  0.08572307], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53077865,  0.6242649 ],\n",
       "           [ 1.10091186,  0.28030118]], dtype=float32),\n",
       "    array([[ 0.29084912, -0.83427972],\n",
       "           [-0.97900009, -0.24491462]], dtype=float32),\n",
       "    array([-0.08090205,  0.08627769], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53077865,  0.6242649 ],\n",
       "           [ 1.10091186,  0.28030118]], dtype=float32),\n",
       "    array([[ 0.29084912, -0.83427972],\n",
       "           [-0.97900009, -0.24491462]], dtype=float32),\n",
       "    array([-0.08090205,  0.08627769], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.53021711,  0.62481505],\n",
       "           [ 1.10019875,  0.28061122]], dtype=float32),\n",
       "    array([[ 0.29090583, -0.83342904],\n",
       "           [-0.97897774, -0.24380754]], dtype=float32),\n",
       "    array([-0.08132325,  0.08690294], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.53021711,  0.62481505],\n",
       "           [ 1.10019875,  0.28061122]], dtype=float32),\n",
       "    array([[ 0.29090583, -0.83342904],\n",
       "           [-0.97897774, -0.24380754]], dtype=float32),\n",
       "    array([-0.08132325,  0.08690294], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5296526 ,  0.62532669],\n",
       "           [ 1.09952617,  0.28093731]], dtype=float32),\n",
       "    array([[ 0.29099426, -0.83259177],\n",
       "           [-0.97894943, -0.24274825]], dtype=float32),\n",
       "    array([-0.08171241,  0.08749682], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5296526 ,  0.62532669],\n",
       "           [ 1.09952617,  0.28093731]], dtype=float32),\n",
       "    array([[ 0.29099426, -0.83259177],\n",
       "           [-0.97894943, -0.24274825]], dtype=float32),\n",
       "    array([-0.08171241,  0.08749682], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52908933,  0.62586761],\n",
       "           [ 1.09885716,  0.28128973]], dtype=float32),\n",
       "    array([[ 0.29106763, -0.83176708],\n",
       "           [-0.97892243, -0.24172686]], dtype=float32),\n",
       "    array([-0.0821095 ,  0.08811167], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52908933,  0.62586761],\n",
       "           [ 1.09885716,  0.28128973]], dtype=float32),\n",
       "    array([[ 0.29106763, -0.83176708],\n",
       "           [-0.97892243, -0.24172686]], dtype=float32),\n",
       "    array([-0.0821095 ,  0.08811167], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52852207,  0.62634075],\n",
       "           [ 1.09814155,  0.28160143]], dtype=float32),\n",
       "    array([[ 0.29113066, -0.83095759],\n",
       "           [-0.97892714, -0.24079123]], dtype=float32),\n",
       "    array([-0.08255243,  0.08873112], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52852207,  0.62634075],\n",
       "           [ 1.09814155,  0.28160143]], dtype=float32),\n",
       "    array([[ 0.29113066, -0.83095759],\n",
       "           [-0.97892714, -0.24079123]], dtype=float32),\n",
       "    array([-0.08255243,  0.08873112], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52784187,  0.62687445],\n",
       "           [ 1.09742367,  0.28200513]], dtype=float32),\n",
       "    array([[ 0.29111028, -0.83013695],\n",
       "           [-0.97900414, -0.23981602]], dtype=float32),\n",
       "    array([-0.08310623,  0.08943141], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52784187,  0.62687445],\n",
       "           [ 1.09742367,  0.28200513]], dtype=float32),\n",
       "    array([[ 0.29111028, -0.83013695],\n",
       "           [-0.97900414, -0.23981602]], dtype=float32),\n",
       "    array([-0.08310623,  0.08943141], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52725881,  0.62737876],\n",
       "           [ 1.09668589,  0.28223625]], dtype=float32),\n",
       "    array([[ 0.29122412, -0.82928556],\n",
       "           [-0.9789055 , -0.23880878]], dtype=float32),\n",
       "    array([-0.08360209,  0.09003334], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52725881,  0.62737876],\n",
       "           [ 1.09668589,  0.28223625]], dtype=float32),\n",
       "    array([[ 0.29122412, -0.82928556],\n",
       "           [-0.9789055 , -0.23880878]], dtype=float32),\n",
       "    array([-0.08360209,  0.09003334], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52659231,  0.62786579],\n",
       "           [ 1.09589791,  0.28250167]], dtype=float32),\n",
       "    array([[ 0.29127467, -0.82840741],\n",
       "           [-0.97884512, -0.2377557 ]], dtype=float32),\n",
       "    array([-0.08413506,  0.09064659], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52659231,  0.62786579],\n",
       "           [ 1.09589791,  0.28250167]], dtype=float32),\n",
       "    array([[ 0.29127467, -0.82840741],\n",
       "           [-0.97884512, -0.2377557 ]], dtype=float32),\n",
       "    array([-0.08413506,  0.09064659], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52603126,  0.62824774],\n",
       "           [ 1.09529626,  0.28275236]], dtype=float32),\n",
       "    array([[ 0.29142669, -0.82757002],\n",
       "           [-0.97862732, -0.236687  ]], dtype=float32),\n",
       "    array([-0.08452738,  0.09120904], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52603126,  0.62824774],\n",
       "           [ 1.09529626,  0.28275236]], dtype=float32),\n",
       "    array([[ 0.29142669, -0.82757002],\n",
       "           [-0.97862732, -0.236687  ]], dtype=float32),\n",
       "    array([-0.08452738,  0.09120904], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52549922,  0.6285224 ],\n",
       "           [ 1.09467316,  0.28287524]], dtype=float32),\n",
       "    array([[ 0.29162389, -0.82671684],\n",
       "           [-0.97833246, -0.23552868]], dtype=float32),\n",
       "    array([-0.08490493,  0.09167361], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52549922,  0.6285224 ],\n",
       "           [ 1.09467316,  0.28287524]], dtype=float32),\n",
       "    array([[ 0.29162389, -0.82671684],\n",
       "           [-0.97833246, -0.23552868]], dtype=float32),\n",
       "    array([-0.08490493,  0.09167361], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52487046,  0.62884957],\n",
       "           [ 1.09395993,  0.28307205]], dtype=float32),\n",
       "    array([[ 0.29169926, -0.82587379],\n",
       "           [-0.97821754, -0.23432592]], dtype=float32),\n",
       "    array([-0.08542379,  0.09218644], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52487046,  0.62884957],\n",
       "           [ 1.09395993,  0.28307205]], dtype=float32),\n",
       "    array([[ 0.29169926, -0.82587379],\n",
       "           [-0.97821754, -0.23432592]], dtype=float32),\n",
       "    array([-0.08542379,  0.09218644], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52421576,  0.629224  ],\n",
       "           [ 1.09319925,  0.28335515]], dtype=float32),\n",
       "    array([[ 0.29171553, -0.82504702],\n",
       "           [-0.97823149, -0.23320541]], dtype=float32),\n",
       "    array([-0.08599463,  0.09275004], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52421576,  0.629224  ],\n",
       "           [ 1.09319925,  0.28335515]], dtype=float32),\n",
       "    array([[ 0.29171553, -0.82504702],\n",
       "           [-0.97823149, -0.23320541]], dtype=float32),\n",
       "    array([-0.08599463,  0.09275004], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52345204,  0.62964702],\n",
       "           [ 1.09239626,  0.28365609]], dtype=float32),\n",
       "    array([[ 0.29164556, -0.82429272],\n",
       "           [-0.97842598, -0.23221874]], dtype=float32),\n",
       "    array([-0.08666066,  0.09337111], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52345204,  0.62964702],\n",
       "           [ 1.09239626,  0.28365609]], dtype=float32),\n",
       "    array([[ 0.29164556, -0.82429272],\n",
       "           [-0.97842598, -0.23221874]], dtype=float32),\n",
       "    array([-0.08666066,  0.09337111], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52281308,  0.63005334],\n",
       "           [ 1.091676  ,  0.28387657]], dtype=float32),\n",
       "    array([[ 0.29173934, -0.82352555],\n",
       "           [-0.97843325, -0.2312123 ]], dtype=float32),\n",
       "    array([-0.08721326,  0.09395351], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52281308,  0.63005334],\n",
       "           [ 1.091676  ,  0.28387657]], dtype=float32),\n",
       "    array([[ 0.29173934, -0.82352555],\n",
       "           [-0.97843325, -0.2312123 ]], dtype=float32),\n",
       "    array([-0.08721326,  0.09395351], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52219695,  0.63042539],\n",
       "           [ 1.09097457,  0.28411856]], dtype=float32),\n",
       "    array([[ 0.2918596 , -0.82277983],\n",
       "           [-0.97837627, -0.23020218]], dtype=float32),\n",
       "    array([-0.0877253 ,  0.09449849], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52219695,  0.63042539],\n",
       "           [ 1.09097457,  0.28411856]], dtype=float32),\n",
       "    array([[ 0.2918596 , -0.82277983],\n",
       "           [-0.97837627, -0.23020218]], dtype=float32),\n",
       "    array([-0.0877253 ,  0.09449849], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52164525,  0.63082469],\n",
       "           [ 1.0902096 ,  0.28438082]], dtype=float32),\n",
       "    array([[ 0.29197004, -0.8220225 ],\n",
       "           [-0.97833556, -0.22922651]], dtype=float32),\n",
       "    array([-0.08822279,  0.09501003], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52164525,  0.63082469],\n",
       "           [ 1.0902096 ,  0.28438082]], dtype=float32),\n",
       "    array([[ 0.29197004, -0.8220225 ],\n",
       "           [-0.97833556, -0.22922651]], dtype=float32),\n",
       "    array([-0.08822279,  0.09501003], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52105051,  0.63122344],\n",
       "           [ 1.08943737,  0.28465241]], dtype=float32),\n",
       "    array([[ 0.29201117, -0.8212837 ],\n",
       "           [-0.97843468, -0.22826959]], dtype=float32),\n",
       "    array([-0.08869756,  0.09555074], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52105051,  0.63122344],\n",
       "           [ 1.08943737,  0.28465241]], dtype=float32),\n",
       "    array([[ 0.29201117, -0.8212837 ],\n",
       "           [-0.97843468, -0.22826959]], dtype=float32),\n",
       "    array([-0.08869756,  0.09555074], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.52050942,  0.63166291],\n",
       "           [ 1.08873761,  0.28487089]], dtype=float32),\n",
       "    array([[ 0.29210454, -0.82051593],\n",
       "           [-0.97846621, -0.22726215]], dtype=float32),\n",
       "    array([-0.08908226,  0.0960618 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.52050942,  0.63166291],\n",
       "           [ 1.08873761,  0.28487089]], dtype=float32),\n",
       "    array([[ 0.29210454, -0.82051593],\n",
       "           [-0.97846621, -0.22726215]], dtype=float32),\n",
       "    array([-0.08908226,  0.0960618 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51992488,  0.63211375],\n",
       "           [ 1.08799553,  0.28511623]], dtype=float32),\n",
       "    array([[ 0.29217568, -0.8198334 ],\n",
       "           [-0.97859496, -0.22641951]], dtype=float32),\n",
       "    array([-0.08953024,  0.09661915], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51992488,  0.63211375],\n",
       "           [ 1.08799553,  0.28511623]], dtype=float32),\n",
       "    array([[ 0.29217568, -0.8198334 ],\n",
       "           [-0.97859496, -0.22641951]], dtype=float32),\n",
       "    array([-0.08953024,  0.09661915], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51924235,  0.63265228],\n",
       "           [ 1.08715534,  0.28542823]], dtype=float32),\n",
       "    array([[ 0.29210493, -0.81912273],\n",
       "           [-0.97891009, -0.22557138]], dtype=float32),\n",
       "    array([-0.09006202,  0.0972032 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51924235,  0.63265228],\n",
       "           [ 1.08715534,  0.28542823]], dtype=float32),\n",
       "    array([[ 0.29210493, -0.81912273],\n",
       "           [-0.97891009, -0.22557138]], dtype=float32),\n",
       "    array([-0.09006202,  0.0972032 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51855725,  0.63313675],\n",
       "           [ 1.08626568,  0.28582123]], dtype=float32),\n",
       "    array([[ 0.29199505, -0.81837064],\n",
       "           [-0.97919077, -0.22466299]], dtype=float32),\n",
       "    array([-0.09064133,  0.09780284], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51855725,  0.63313675],\n",
       "           [ 1.08626568,  0.28582123]], dtype=float32),\n",
       "    array([[ 0.29199505, -0.81837064],\n",
       "           [-0.97919077, -0.22466299]], dtype=float32),\n",
       "    array([-0.09064133,  0.09780284], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51794428,  0.63367414],\n",
       "           [ 1.08542132,  0.28614557]], dtype=float32),\n",
       "    array([[ 0.29195982, -0.81759781],\n",
       "           [-0.97936559, -0.22364511]], dtype=float32),\n",
       "    array([-0.09117061,  0.0983981 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51794428,  0.63367414],\n",
       "           [ 1.08542132,  0.28614557]], dtype=float32),\n",
       "    array([[ 0.29195982, -0.81759781],\n",
       "           [-0.97936559, -0.22364511]], dtype=float32),\n",
       "    array([-0.09117061,  0.0983981 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51745081,  0.63420814],\n",
       "           [ 1.08469129,  0.28646538]], dtype=float32),\n",
       "    array([[ 0.29201242, -0.81682885],\n",
       "           [-0.97946697, -0.22265965]], dtype=float32),\n",
       "    array([-0.09154183,  0.09900184], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51745081,  0.63420814],\n",
       "           [ 1.08469129,  0.28646538]], dtype=float32),\n",
       "    array([[ 0.29201242, -0.81682885],\n",
       "           [-0.97946697, -0.22265965]], dtype=float32),\n",
       "    array([-0.09154183,  0.09900184], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51688433,  0.6347968 ],\n",
       "           [ 1.08390284,  0.28687131]], dtype=float32),\n",
       "    array([[ 0.29204783, -0.81605065],\n",
       "           [-0.97959268, -0.22165529]], dtype=float32),\n",
       "    array([-0.09201982,  0.09965812], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51688433,  0.6347968 ],\n",
       "           [ 1.08390284,  0.28687131]], dtype=float32),\n",
       "    array([[ 0.29204783, -0.81605065],\n",
       "           [-0.97959268, -0.22165529]], dtype=float32),\n",
       "    array([-0.09201982,  0.09965812], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51633948,  0.63531476],\n",
       "           [ 1.08315146,  0.28719103]], dtype=float32),\n",
       "    array([[ 0.29214504, -0.81522679],\n",
       "           [-0.97961152, -0.22061802]], dtype=float32),\n",
       "    array([-0.09245112,  0.1002373 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51633948,  0.63531476],\n",
       "           [ 1.08315146,  0.28719103]], dtype=float32),\n",
       "    array([[ 0.29214504, -0.81522679],\n",
       "           [-0.97961152, -0.22061802]], dtype=float32),\n",
       "    array([-0.09245112,  0.1002373 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51574397,  0.63579094],\n",
       "           [ 1.08242345,  0.28758967]], dtype=float32),\n",
       "    array([[ 0.29221758, -0.8143971 ],\n",
       "           [-0.97961026, -0.21950717]], dtype=float32),\n",
       "    array([-0.09292414,  0.10082705], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51574397,  0.63579094],\n",
       "           [ 1.08242345,  0.28758967]], dtype=float32),\n",
       "    array([[ 0.29221758, -0.8143971 ],\n",
       "           [-0.97961026, -0.21950717]], dtype=float32),\n",
       "    array([-0.09292414,  0.10082705], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51499557,  0.63641214],\n",
       "           [ 1.08154583,  0.2881704 ]], dtype=float32),\n",
       "    array([[ 0.2921119 , -0.81352204],\n",
       "           [-0.97981554, -0.21835469]], dtype=float32),\n",
       "    array([-0.09359529,  0.10156445], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51499557,  0.63641214],\n",
       "           [ 1.08154583,  0.2881704 ]], dtype=float32),\n",
       "    array([[ 0.2921119 , -0.81352204],\n",
       "           [-0.97981554, -0.21835469]], dtype=float32),\n",
       "    array([-0.09359529,  0.10156445], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51419032,  0.63695669],\n",
       "           [ 1.0806886 ,  0.28874201]], dtype=float32),\n",
       "    array([[ 0.29191107, -0.8126927 ],\n",
       "           [-0.98014778, -0.21720943]], dtype=float32),\n",
       "    array([-0.09430948,  0.10231173], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51419032,  0.63695669],\n",
       "           [ 1.0806886 ,  0.28874201]], dtype=float32),\n",
       "    array([[ 0.29191107, -0.8126927 ],\n",
       "           [-0.98014778, -0.21720943]], dtype=float32),\n",
       "    array([-0.09430948,  0.10231173], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51342815,  0.6375283 ],\n",
       "           [ 1.07984805,  0.28925291]], dtype=float32),\n",
       "    array([[ 0.29176104, -0.81189299],\n",
       "           [-0.98043197, -0.21610022]], dtype=float32),\n",
       "    array([-0.09498826,  0.10301664], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51342815,  0.6375283 ],\n",
       "           [ 1.07984805,  0.28925291]], dtype=float32),\n",
       "    array([[ 0.29176104, -0.81189299],\n",
       "           [-0.98043197, -0.21610022]], dtype=float32),\n",
       "    array([-0.09498826,  0.10301664], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5127278 ,  0.638062  ],\n",
       "           [ 1.07905018,  0.28973618]], dtype=float32),\n",
       "    array([[ 0.29168609, -0.81110454],\n",
       "           [-0.98061281, -0.21505764]], dtype=float32),\n",
       "    array([-0.0956274 ,  0.10373478], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5127278 ,  0.638062  ],\n",
       "           [ 1.07905018,  0.28973618]], dtype=float32),\n",
       "    array([[ 0.29168609, -0.81110454],\n",
       "           [-0.98061281, -0.21505764]], dtype=float32),\n",
       "    array([-0.0956274 ,  0.10373478], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51218957,  0.63858199],\n",
       "           [ 1.07832253,  0.29009652]], dtype=float32),\n",
       "    array([[ 0.29178429, -0.81028235],\n",
       "           [-0.98056638, -0.21394971]], dtype=float32),\n",
       "    array([-0.09611575,  0.10440382], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51218957,  0.63858199],\n",
       "           [ 1.07832253,  0.29009652]], dtype=float32),\n",
       "    array([[ 0.29178429, -0.81028235],\n",
       "           [-0.98056638, -0.21394971]], dtype=float32),\n",
       "    array([-0.09611575,  0.10440382], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51170129,  0.63905042],\n",
       "           [ 1.07764602,  0.29037222]], dtype=float32),\n",
       "    array([[ 0.2919625 , -0.80948681],\n",
       "           [-0.98043543, -0.21286196]], dtype=float32),\n",
       "    array([-0.09654404,  0.10494336], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51170129,  0.63905042],\n",
       "           [ 1.07764602,  0.29037222]], dtype=float32),\n",
       "    array([[ 0.2919625 , -0.80948681],\n",
       "           [-0.98043543, -0.21286196]], dtype=float32),\n",
       "    array([-0.09654404,  0.10494336], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51115125,  0.63969517],\n",
       "           [ 1.07694495,  0.29074603]], dtype=float32),\n",
       "    array([[ 0.29204753, -0.80865997],\n",
       "           [-0.98040968, -0.21169978]], dtype=float32),\n",
       "    array([-0.09704073,  0.1055893 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51115125,  0.63969517],\n",
       "           [ 1.07694495,  0.29074603]], dtype=float32),\n",
       "    array([[ 0.29204753, -0.80865997],\n",
       "           [-0.98040968, -0.21169978]], dtype=float32),\n",
       "    array([-0.09704073,  0.1055893 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51075065,  0.64020628],\n",
       "           [ 1.07634449,  0.29100507]], dtype=float32),\n",
       "    array([[ 0.29225379, -0.80786353],\n",
       "           [-0.98021823, -0.21056391]], dtype=float32),\n",
       "    array([-0.09738769,  0.10615546], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51075065,  0.64020628],\n",
       "           [ 1.07634449,  0.29100507]], dtype=float32),\n",
       "    array([[ 0.29225379, -0.80786353],\n",
       "           [-0.98021823, -0.21056391]], dtype=float32),\n",
       "    array([-0.09738769,  0.10615546], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51042891,  0.64065099],\n",
       "           [ 1.07582664,  0.29121864]], dtype=float32),\n",
       "    array([[ 0.29249862, -0.80710995],\n",
       "           [-0.98003477, -0.20953892]], dtype=float32),\n",
       "    array([-0.09761873,  0.10668974], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51042891,  0.64065099],\n",
       "           [ 1.07582664,  0.29121864]], dtype=float32),\n",
       "    array([[ 0.29249862, -0.80710995],\n",
       "           [-0.98003477, -0.20953892]], dtype=float32),\n",
       "    array([-0.09761873,  0.10668974], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.51010358,  0.64109915],\n",
       "           [ 1.07531977,  0.29145733]], dtype=float32),\n",
       "    array([[ 0.29270783, -0.80642378],\n",
       "           [-0.9799248 , -0.20865554]], dtype=float32),\n",
       "    array([-0.09782103,  0.1072502 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.51010358,  0.64109915],\n",
       "           [ 1.07531977,  0.29145733]], dtype=float32),\n",
       "    array([[ 0.29270783, -0.80642378],\n",
       "           [-0.9799248 , -0.20865554]], dtype=float32),\n",
       "    array([-0.09782103,  0.1072502 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50983846,  0.64137638],\n",
       "           [ 1.07488513,  0.29149529]], dtype=float32),\n",
       "    array([[ 0.29298303, -0.80583298],\n",
       "           [-0.9797985 , -0.2079452 ]], dtype=float32),\n",
       "    array([-0.09789641,  0.10766339], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50983846,  0.64137638],\n",
       "           [ 1.07488513,  0.29149529]], dtype=float32),\n",
       "    array([[ 0.29298303, -0.80583298],\n",
       "           [-0.9797985 , -0.2079452 ]], dtype=float32),\n",
       "    array([-0.09789641,  0.10766339], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5095216 ,  0.6417045 ],\n",
       "           [ 1.07439423,  0.29156083]], dtype=float32),\n",
       "    array([[ 0.29313484, -0.80525512],\n",
       "           [-0.97987461, -0.20723489]], dtype=float32),\n",
       "    array([-0.09800383,  0.10811889], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5095216 ,  0.6417045 ],\n",
       "           [ 1.07439423,  0.29156083]], dtype=float32),\n",
       "    array([[ 0.29313484, -0.80525512],\n",
       "           [-0.97987461, -0.20723489]], dtype=float32),\n",
       "    array([-0.09800383,  0.10811889], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50911021,  0.642102  ],\n",
       "           [ 1.07377887,  0.29166853]], dtype=float32),\n",
       "    array([[ 0.29315865, -0.80460703],\n",
       "           [-0.98006368, -0.20648864]], dtype=float32),\n",
       "    array([-0.09822717,  0.10860462], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50911021,  0.642102  ],\n",
       "           [ 1.07377887,  0.29166853]], dtype=float32),\n",
       "    array([[ 0.29315865, -0.80460703],\n",
       "           [-0.98006368, -0.20648864]], dtype=float32),\n",
       "    array([-0.09822717,  0.10860462], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50871694,  0.64245433],\n",
       "           [ 1.07310009,  0.29185089]], dtype=float32),\n",
       "    array([[ 0.2931686 , -0.80398625],\n",
       "           [-0.9802596 , -0.20568238]], dtype=float32),\n",
       "    array([-0.0985001 ,  0.10909535], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50871694,  0.64245433],\n",
       "           [ 1.07310009,  0.29185089]], dtype=float32),\n",
       "    array([[ 0.2931686 , -0.80398625],\n",
       "           [-0.9802596 , -0.20568238]], dtype=float32),\n",
       "    array([-0.0985001 ,  0.10909535], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5082562 ,  0.64275849],\n",
       "           [ 1.07242429,  0.29201958]], dtype=float32),\n",
       "    array([[ 0.29323709, -0.80335826],\n",
       "           [-0.98037642, -0.20485692]], dtype=float32),\n",
       "    array([-0.09876781,  0.10957677], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5082562 ,  0.64275849],\n",
       "           [ 1.07242429,  0.29201958]], dtype=float32),\n",
       "    array([[ 0.29323709, -0.80335826],\n",
       "           [-0.98037642, -0.20485692]], dtype=float32),\n",
       "    array([-0.09876781,  0.10957677], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50785041,  0.64302593],\n",
       "           [ 1.07171142,  0.29209638]], dtype=float32),\n",
       "    array([[ 0.29337698, -0.80271721],\n",
       "           [-0.98043543, -0.204023  ]], dtype=float32),\n",
       "    array([-0.09903404,  0.11001906], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50785041,  0.64302593],\n",
       "           [ 1.07171142,  0.29209638]], dtype=float32),\n",
       "    array([[ 0.29337698, -0.80271721],\n",
       "           [-0.98043543, -0.204023  ]], dtype=float32),\n",
       "    array([-0.09903404,  0.11001906], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50738215,  0.64326346],\n",
       "           [ 1.07101524,  0.29220518]], dtype=float32),\n",
       "    array([[ 0.29349032, -0.80211407],\n",
       "           [-0.98050898, -0.2031927 ]], dtype=float32),\n",
       "    array([-0.09930789,  0.11045417], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50738215,  0.64326346],\n",
       "           [ 1.07101524,  0.29220518]], dtype=float32),\n",
       "    array([[ 0.29349032, -0.80211407],\n",
       "           [-0.98050898, -0.2031927 ]], dtype=float32),\n",
       "    array([-0.09930789,  0.11045417], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50702024,  0.64345872],\n",
       "           [ 1.07037866,  0.29210991]], dtype=float32),\n",
       "    array([[ 0.29377449, -0.80146563],\n",
       "           [-0.98035866, -0.20227395]], dtype=float32),\n",
       "    array([-0.09948441,  0.11077335], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50702024,  0.64345872],\n",
       "           [ 1.07037866,  0.29210991]], dtype=float32),\n",
       "    array([[ 0.29377449, -0.80146563],\n",
       "           [-0.98035866, -0.20227395]], dtype=float32),\n",
       "    array([-0.09948441,  0.11077335], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50668371,  0.64368868],\n",
       "           [ 1.06979549,  0.29201922]], dtype=float32),\n",
       "    array([[ 0.29409781, -0.80082643],\n",
       "           [-0.98015839, -0.2013572 ]], dtype=float32),\n",
       "    array([-0.09965093,  0.11104915], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50668371,  0.64368868],\n",
       "           [ 1.06979549,  0.29201922]], dtype=float32),\n",
       "    array([[ 0.29409781, -0.80082643],\n",
       "           [-0.98015839, -0.2013572 ]], dtype=float32),\n",
       "    array([-0.09965093,  0.11104915], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50643468,  0.6439361 ],\n",
       "           [ 1.06930292,  0.29198596]], dtype=float32),\n",
       "    array([[ 0.29446569, -0.80020082],\n",
       "           [-0.97987199, -0.20041272]], dtype=float32),\n",
       "    array([-0.09971233,  0.11135196], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50643468,  0.6439361 ],\n",
       "           [ 1.06930292,  0.29198596]], dtype=float32),\n",
       "    array([[ 0.29446569, -0.80020082],\n",
       "           [-0.97987199, -0.20041272]], dtype=float32),\n",
       "    array([-0.09971233,  0.11135196], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50600386,  0.64429772],\n",
       "           [ 1.06871128,  0.29206365]], dtype=float32),\n",
       "    array([[ 0.29473117, -0.7995308 ],\n",
       "           [-0.97972369, -0.1993846 ]], dtype=float32),\n",
       "    array([-0.09996858,  0.11176378], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50600386,  0.64429772],\n",
       "           [ 1.06871128,  0.29206365]], dtype=float32),\n",
       "    array([[ 0.29473117, -0.7995308 ],\n",
       "           [-0.97972369, -0.1993846 ]], dtype=float32),\n",
       "    array([-0.09996858,  0.11176378], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50551355,  0.64462334],\n",
       "           [ 1.06806254,  0.29210842]], dtype=float32),\n",
       "    array([[ 0.29496357, -0.7988525 ],\n",
       "           [-0.97955644, -0.19834132]], dtype=float32),\n",
       "    array([-0.10030591,  0.11217344], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50551355,  0.64462334],\n",
       "           [ 1.06806254,  0.29210842]], dtype=float32),\n",
       "    array([[ 0.29496357, -0.7988525 ],\n",
       "           [-0.97955644, -0.19834132]], dtype=float32),\n",
       "    array([-0.10030591,  0.11217344], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50514799,  0.64485019],\n",
       "           [ 1.06758022,  0.29217193]], dtype=float32),\n",
       "    array([[ 0.29527301, -0.79820234],\n",
       "           [-0.97922814, -0.19728841]], dtype=float32),\n",
       "    array([-0.10049718,  0.11255001], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50514799,  0.64485019],\n",
       "           [ 1.06758022,  0.29217193]], dtype=float32),\n",
       "    array([[ 0.29527301, -0.79820234],\n",
       "           [-0.97922814, -0.19728841]], dtype=float32),\n",
       "    array([-0.10049718,  0.11255001], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50476867,  0.64503509],\n",
       "           [ 1.06715369,  0.29223025]], dtype=float32),\n",
       "    array([[ 0.29555678, -0.79759628],\n",
       "           [-0.97894681, -0.19632304]], dtype=float32),\n",
       "    array([-0.10065812,  0.11292578], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50476867,  0.64503509],\n",
       "           [ 1.06715369,  0.29223025]], dtype=float32),\n",
       "    array([[ 0.29555678, -0.79759628],\n",
       "           [-0.97894681, -0.19632304]], dtype=float32),\n",
       "    array([-0.10065812,  0.11292578], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50436968,  0.64520442],\n",
       "           [ 1.06669044,  0.29236078]], dtype=float32),\n",
       "    array([[ 0.295816  , -0.79693598],\n",
       "           [-0.97869885, -0.19536777]], dtype=float32),\n",
       "    array([-0.10083048,  0.11332887], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50436968,  0.64520442],\n",
       "           [ 1.06669044,  0.29236078]], dtype=float32),\n",
       "    array([[ 0.295816  , -0.79693598],\n",
       "           [-0.97869885, -0.19536777]], dtype=float32),\n",
       "    array([-0.10083048,  0.11332887], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50398892,  0.6455003 ],\n",
       "           [ 1.06614041,  0.29264218]], dtype=float32),\n",
       "    array([[ 0.29602879, -0.79624021],\n",
       "           [-0.97849834, -0.19444317]], dtype=float32),\n",
       "    array([-0.10105409,  0.11383145], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50398892,  0.6455003 ],\n",
       "           [ 1.06614041,  0.29264218]], dtype=float32),\n",
       "    array([[ 0.29602879, -0.79624021],\n",
       "           [-0.97849834, -0.19444317]], dtype=float32),\n",
       "    array([-0.10105409,  0.11383145], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50363362,  0.6457116 ],\n",
       "           [ 1.06558597,  0.29288727]], dtype=float32),\n",
       "    array([[ 0.29625952, -0.7956658 ],\n",
       "           [-0.97835588, -0.19367385]], dtype=float32),\n",
       "    array([-0.10125688,  0.11430176], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50363362,  0.6457116 ],\n",
       "           [ 1.06558597,  0.29288727]], dtype=float32),\n",
       "    array([[ 0.29625952, -0.7956658 ],\n",
       "           [-0.97835588, -0.19367385]], dtype=float32),\n",
       "    array([-0.10125688,  0.11430176], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5033108 ,  0.64582831],\n",
       "           [ 1.06503904,  0.2930226 ]], dtype=float32),\n",
       "    array([[ 0.29655036, -0.79506081],\n",
       "           [-0.97813457, -0.19280651]], dtype=float32),\n",
       "    array([-0.1014482 ,  0.11469926], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5033108 ,  0.64582831],\n",
       "           [ 1.06503904,  0.2930226 ]], dtype=float32),\n",
       "    array([[ 0.29655036, -0.79506081],\n",
       "           [-0.97813457, -0.19280651]], dtype=float32),\n",
       "    array([-0.1014482 ,  0.11469926], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50309664,  0.64588535],\n",
       "           [ 1.06453049,  0.29295629]], dtype=float32),\n",
       "    array([[ 0.29699618, -0.79440993],\n",
       "           [-0.97773319, -0.19186854]], dtype=float32),\n",
       "    array([-0.10151195,  0.1149688 ], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50309664,  0.64588535],\n",
       "           [ 1.06453049,  0.29295629]], dtype=float32),\n",
       "    array([[ 0.29699618, -0.79440993],\n",
       "           [-0.97773319, -0.19186854]], dtype=float32),\n",
       "    array([-0.10151195,  0.1149688 ], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50267541,  0.64599895],\n",
       "           [ 1.06392217,  0.29301107]], dtype=float32),\n",
       "    array([[ 0.29722169, -0.79376149],\n",
       "           [-0.97762018, -0.19092652]], dtype=float32),\n",
       "    array([-0.10178045,  0.11532443], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50267541,  0.64599895],\n",
       "           [ 1.06392217,  0.29301107]], dtype=float32),\n",
       "    array([[ 0.29722169, -0.79376149],\n",
       "           [-0.97762018, -0.19092652]], dtype=float32),\n",
       "    array([-0.10178045,  0.11532443], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50228196,  0.64616561],\n",
       "           [ 1.06334007,  0.29311389]], dtype=float32),\n",
       "    array([[ 0.29742742, -0.79313397],\n",
       "           [-0.97758222, -0.19001852]], dtype=float32),\n",
       "    array([-0.1019954 ,  0.11574096], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50228196,  0.64616561],\n",
       "           [ 1.06334007,  0.29311389]], dtype=float32),\n",
       "    array([[ 0.29742742, -0.79313397],\n",
       "           [-0.97758222, -0.19001852]], dtype=float32),\n",
       "    array([-0.1019954 ,  0.11574096], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50185186,  0.64643949],\n",
       "           [ 1.06270242,  0.29326099]], dtype=float32),\n",
       "    array([[ 0.29755303, -0.79251063],\n",
       "           [-0.97769815, -0.18911345]], dtype=float32),\n",
       "    array([-0.10226354,  0.11622903], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50185186,  0.64643949],\n",
       "           [ 1.06270242,  0.29326099]], dtype=float32),\n",
       "    array([[ 0.29755303, -0.79251063],\n",
       "           [-0.97769815, -0.18911345]], dtype=float32),\n",
       "    array([-0.10226354,  0.11622903], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50132114,  0.64667588],\n",
       "           [ 1.06196964,  0.29338124]], dtype=float32),\n",
       "    array([[ 0.29752836, -0.79192275],\n",
       "           [-0.97799969, -0.1883346 ]], dtype=float32),\n",
       "    array([-0.10261194,  0.11671522], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50132114,  0.64667588],\n",
       "           [ 1.06196964,  0.29338124]], dtype=float32),\n",
       "    array([[ 0.29752836, -0.79192275],\n",
       "           [-0.97799969, -0.1883346 ]], dtype=float32),\n",
       "    array([-0.10261194,  0.11671522], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.5007931 ,  0.6469875 ],\n",
       "           [ 1.06119561,  0.29363289]], dtype=float32),\n",
       "    array([[ 0.29744044, -0.79129648],\n",
       "           [-0.97831541, -0.18747713]], dtype=float32),\n",
       "    array([-0.10299433,  0.11727287], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.5007931 ,  0.6469875 ],\n",
       "           [ 1.06119561,  0.29363289]], dtype=float32),\n",
       "    array([[ 0.29744044, -0.79129648],\n",
       "           [-0.97831541, -0.18747713]], dtype=float32),\n",
       "    array([-0.10299433,  0.11727287], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.50024039,  0.64731729],\n",
       "           [ 1.06039655,  0.29384533]], dtype=float32),\n",
       "    array([[ 0.29736876, -0.79065561],\n",
       "           [-0.9786163 , -0.18665634]], dtype=float32),\n",
       "    array([-0.10338923,  0.11780988], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.50024039,  0.64731729],\n",
       "           [ 1.06039655,  0.29384533]], dtype=float32),\n",
       "    array([[ 0.29736876, -0.79065561],\n",
       "           [-0.9786163 , -0.18665634]], dtype=float32),\n",
       "    array([-0.10338923,  0.11780988], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49966031,  0.64763874],\n",
       "           [ 1.05959713,  0.29403707]], dtype=float32),\n",
       "    array([[ 0.29732844, -0.79001653],\n",
       "           [-0.97887713, -0.18582603]], dtype=float32),\n",
       "    array([-0.10377882,  0.11833574], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49966031,  0.64763874],\n",
       "           [ 1.05959713,  0.29403707]], dtype=float32),\n",
       "    array([[ 0.29732844, -0.79001653],\n",
       "           [-0.97887713, -0.18582603]], dtype=float32),\n",
       "    array([-0.10377882,  0.11833574], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.4990021 ,  0.64805651],\n",
       "           [ 1.05879235,  0.29433697]], dtype=float32),\n",
       "    array([[ 0.29726624, -0.78933215],\n",
       "           [-0.97911525, -0.18491288]], dtype=float32),\n",
       "    array([-0.10425692,  0.11891238], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.4990021 ,  0.64805651],\n",
       "           [ 1.05879235,  0.29433697]], dtype=float32),\n",
       "    array([[ 0.29726624, -0.78933215],\n",
       "           [-0.97911525, -0.18491288]], dtype=float32),\n",
       "    array([-0.10425692,  0.11891238], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49841222,  0.64853007],\n",
       "           [ 1.0580852 ,  0.29463992]], dtype=float32),\n",
       "    array([[ 0.2972081 , -0.78867495],\n",
       "           [-0.97936308, -0.18399569]], dtype=float32),\n",
       "    array([-0.104659 ,  0.1195174], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49841222,  0.64853007],\n",
       "           [ 1.0580852 ,  0.29463992]], dtype=float32),\n",
       "    array([[ 0.2972081 , -0.78867495],\n",
       "           [-0.97936308, -0.18399569]], dtype=float32),\n",
       "    array([-0.104659 ,  0.1195174], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49785221,  0.64900595],\n",
       "           [ 1.05746472,  0.29496232]], dtype=float32),\n",
       "    array([[ 0.29718509, -0.78802502],\n",
       "           [-0.97954631, -0.18308187]], dtype=float32),\n",
       "    array([-0.10498589,  0.12014462], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49785221,  0.64900595],\n",
       "           [ 1.05746472,  0.29496232]], dtype=float32),\n",
       "    array([[ 0.29718509, -0.78802502],\n",
       "           [-0.97954631, -0.18308187]], dtype=float32),\n",
       "    array([-0.10498589,  0.12014462], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49721059,  0.64946169],\n",
       "           [ 1.05680597,  0.29528564]], dtype=float32),\n",
       "    array([[ 0.29714468, -0.78738028],\n",
       "           [-0.97971129, -0.18213269]], dtype=float32),\n",
       "    array([-0.10538442,  0.12072016], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49721059,  0.64946169],\n",
       "           [ 1.05680597,  0.29528564]], dtype=float32),\n",
       "    array([[ 0.29714468, -0.78738028],\n",
       "           [-0.97971129, -0.18213269]], dtype=float32),\n",
       "    array([-0.10538442,  0.12072016], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49666589,  0.64982909],\n",
       "           [ 1.05618811,  0.2954751 ]], dtype=float32),\n",
       "    array([[ 0.29723313, -0.78675056],\n",
       "           [-0.97972405, -0.18121381]], dtype=float32),\n",
       "    array([-0.10568301,  0.12122338], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49666589,  0.64982909],\n",
       "           [ 1.05618811,  0.2954751 ]], dtype=float32),\n",
       "    array([[ 0.29723313, -0.78675056],\n",
       "           [-0.97972405, -0.18121381]], dtype=float32),\n",
       "    array([-0.10568301,  0.12122338], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49622288,  0.65014303],\n",
       "           [ 1.05561006,  0.29556665]], dtype=float32),\n",
       "    array([[ 0.29740545, -0.78615987],\n",
       "           [-0.97964716, -0.18030614]], dtype=float32),\n",
       "    array([-0.10588651,  0.12160219], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49622288,  0.65014303],\n",
       "           [ 1.05561006,  0.29556665]], dtype=float32),\n",
       "    array([[ 0.29740545, -0.78615987],\n",
       "           [-0.97964716, -0.18030614]], dtype=float32),\n",
       "    array([-0.10588651,  0.12160219], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49587056,  0.65034503],\n",
       "           [ 1.05520535,  0.29560357]], dtype=float32),\n",
       "    array([[ 0.29770908, -0.78554934],\n",
       "           [-0.97936529, -0.17932066]], dtype=float32),\n",
       "    array([-0.10593186,  0.12189193], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49587056,  0.65034503],\n",
       "           [ 1.05520535,  0.29560357]], dtype=float32),\n",
       "    array([[ 0.29770908, -0.78554934],\n",
       "           [-0.97936529, -0.17932066]], dtype=float32),\n",
       "    array([-0.10593186,  0.12189193], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49555239,  0.65053481],\n",
       "           [ 1.05467844,  0.295589  ]], dtype=float32),\n",
       "    array([[ 0.29805341, -0.78487712],\n",
       "           [-0.97900486, -0.17824855]], dtype=float32),\n",
       "    array([-0.10602836,  0.12217452], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49555239,  0.65053481],\n",
       "           [ 1.05467844,  0.295589  ]], dtype=float32),\n",
       "    array([[ 0.29805341, -0.78487712],\n",
       "           [-0.97900486, -0.17824855]], dtype=float32),\n",
       "    array([-0.10602836,  0.12217452], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49515602,  0.65085632],\n",
       "           [ 1.05410302,  0.29568049]], dtype=float32),\n",
       "    array([[ 0.29828444, -0.78417438],\n",
       "           [-0.97880191, -0.17712569]], dtype=float32),\n",
       "    array([-0.10619982,  0.12257297], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49515602,  0.65085632],\n",
       "           [ 1.05410302,  0.29568049]], dtype=float32),\n",
       "    array([[ 0.29828444, -0.78417438],\n",
       "           [-0.97880191, -0.17712569]], dtype=float32),\n",
       "    array([-0.10619982,  0.12257297], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49471739,  0.6511367 ],\n",
       "           [ 1.05362868,  0.29578909]], dtype=float32),\n",
       "    array([[ 0.29858947, -0.78347617],\n",
       "           [-0.97850442, -0.17597874]], dtype=float32),\n",
       "    array([-0.10637024,  0.12294916], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49471739,  0.6511367 ],\n",
       "           [ 1.05362868,  0.29578909]], dtype=float32),\n",
       "    array([[ 0.29858947, -0.78347617],\n",
       "           [-0.97850442, -0.17597874]], dtype=float32),\n",
       "    array([-0.10637024,  0.12294916], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49434724,  0.65141171],\n",
       "           [ 1.05316627,  0.2959519 ]], dtype=float32),\n",
       "    array([[ 0.29892755, -0.7828359 ],\n",
       "           [-0.97822475, -0.17490429]], dtype=float32),\n",
       "    array([-0.10651372,  0.12334224], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49434724,  0.65141171],\n",
       "           [ 1.05316627,  0.2959519 ]], dtype=float32),\n",
       "    array([[ 0.29892755, -0.7828359 ],\n",
       "           [-0.97822475, -0.17490429]], dtype=float32),\n",
       "    array([-0.10651372,  0.12334224], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.4939127 ,  0.65173912],\n",
       "           [ 1.05260992,  0.2961134 ]], dtype=float32),\n",
       "    array([[ 0.29922605, -0.78221154],\n",
       "           [-0.97808397, -0.17391299]], dtype=float32),\n",
       "    array([-0.10673462,  0.12380071], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.4939127 ,  0.65173912],\n",
       "           [ 1.05260992,  0.2961134 ]], dtype=float32),\n",
       "    array([[ 0.29922605, -0.78221154],\n",
       "           [-0.97808397, -0.17391299]], dtype=float32),\n",
       "    array([-0.10673462,  0.12380071], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.4935604 ,  0.65187275],\n",
       "           [ 1.05217659,  0.29614893]], dtype=float32),\n",
       "    array([[ 0.29954034, -0.78172803],\n",
       "           [-0.97792965, -0.17316076]], dtype=float32),\n",
       "    array([-0.10678632,  0.12412543], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.4935604 ,  0.65187275],\n",
       "           [ 1.05217659,  0.29614893]], dtype=float32),\n",
       "    array([[ 0.29954034, -0.78172803],\n",
       "           [-0.97792965, -0.17316076]], dtype=float32),\n",
       "    array([-0.10678632,  0.12412543], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49325025,  0.651995  ],\n",
       "           [ 1.05172944,  0.29609644]], dtype=float32),\n",
       "    array([[ 0.29995492, -0.78117478],\n",
       "           [-0.97762871, -0.1723499 ]], dtype=float32),\n",
       "    array([-0.10682538,  0.12441382], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49325025,  0.651995  ],\n",
       "           [ 1.05172944,  0.29609644]], dtype=float32),\n",
       "    array([[ 0.29995492, -0.78117478],\n",
       "           [-0.97762871, -0.1723499 ]], dtype=float32),\n",
       "    array([-0.10682538,  0.12441382], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49292803,  0.65212566],\n",
       "           [ 1.05125868,  0.29607347]], dtype=float32),\n",
       "    array([[ 0.30037856, -0.78059477],\n",
       "           [-0.97733057, -0.17153533]], dtype=float32),\n",
       "    array([-0.10686298,  0.12471846], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49292803,  0.65212566],\n",
       "           [ 1.05125868,  0.29607347]], dtype=float32),\n",
       "    array([[ 0.30037856, -0.78059477],\n",
       "           [-0.97733057, -0.17153533]], dtype=float32),\n",
       "    array([-0.10686298,  0.12471846], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49264109,  0.65235519],\n",
       "           [ 1.05077696,  0.29606944]], dtype=float32),\n",
       "    array([[ 0.30077404, -0.78003031],\n",
       "           [-0.97709554, -0.17077427]], dtype=float32),\n",
       "    array([-0.10690873,  0.12505761], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49264109,  0.65235519],\n",
       "           [ 1.05077696,  0.29606944]], dtype=float32),\n",
       "    array([[ 0.30077404, -0.78003031],\n",
       "           [-0.97709554, -0.17077427]], dtype=float32),\n",
       "    array([-0.10690873,  0.12505761], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49232274,  0.65249354],\n",
       "           [ 1.05030179,  0.2960147 ]], dtype=float32),\n",
       "    array([[ 0.30122736, -0.77952123],\n",
       "           [-0.9767946 , -0.17010707]], dtype=float32),\n",
       "    array([-0.10692709,  0.12538217], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49232274,  0.65249354],\n",
       "           [ 1.05030179,  0.2960147 ]], dtype=float32),\n",
       "    array([[ 0.30122736, -0.77952123],\n",
       "           [-0.9767946 , -0.17010707]], dtype=float32),\n",
       "    array([-0.10692709,  0.12538217], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49184641,  0.65268266],\n",
       "           [ 1.04968905,  0.29606089]], dtype=float32),\n",
       "    array([[ 0.30152312, -0.77898872],\n",
       "           [-0.97670025, -0.16941079]], dtype=float32),\n",
       "    array([-0.1071153 ,  0.12577376], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49184641,  0.65268266],\n",
       "           [ 1.04968905,  0.29606089]], dtype=float32),\n",
       "    array([[ 0.30152312, -0.77898872],\n",
       "           [-0.97670025, -0.16941079]], dtype=float32),\n",
       "    array([-0.1071153 ,  0.12577376], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49122795,  0.65301067],\n",
       "           [ 1.04885912,  0.29633814]], dtype=float32),\n",
       "    array([[ 0.30155501, -0.77835119],\n",
       "           [-0.97685063, -0.1686299 ]], dtype=float32),\n",
       "    array([-0.10750524,  0.12631121], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49122795,  0.65301067],\n",
       "           [ 1.04885912,  0.29633814]], dtype=float32),\n",
       "    array([[ 0.30155501, -0.77835119],\n",
       "           [-0.97685063, -0.1686299 ]], dtype=float32),\n",
       "    array([-0.10750524,  0.12631121], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49065721,  0.65339392],\n",
       "           [ 1.04809809,  0.2965723 ]], dtype=float32),\n",
       "    array([[ 0.30162969, -0.77766901],\n",
       "           [-0.97694111, -0.16778056]], dtype=float32),\n",
       "    array([-0.10782142,  0.12683104], dtype=float32)]}],\n",
       " [{'begin_input_18': []},\n",
       "  {'begin_attrnn_11': [array([[ 0.49065721,  0.65339392],\n",
       "           [ 1.04809809,  0.2965723 ]], dtype=float32),\n",
       "    array([[ 0.30162969, -0.77766901],\n",
       "           [-0.97694111, -0.16778056]], dtype=float32),\n",
       "    array([-0.10782142,  0.12683104], dtype=float32)]}],\n",
       " [{'end_input_18': []}, {'end_attrnn_11': [array([[ 0.49016598,  0.65370816],\n",
       "           [ 1.04738414,  0.29685566]], dtype=float32),\n",
       "    array([[ 0.3016994 , -0.77697706],\n",
       "           [-0.97696817, -0.16693795]], dtype=float32),\n",
       "    array([-0.10808679,  0.12734595], dtype=float32)]}]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'attrnn_11/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'attrnn_11/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'attrnn_11/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTRNN 2 : States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fullrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import *\n",
    "\n",
    "\n",
    "def fullrnn(step_function, inputs, initial_states,\n",
    "        go_backwards=False, mask=None, constants=None,\n",
    "        unroll=False, input_length=None):\n",
    "    \"\"\"Iterates over the time dimension of a tensor.\n",
    "\n",
    "    # Arguments\n",
    "        step_function: RNN step function.\n",
    "            Parameters:\n",
    "                inputs: tensor with shape `(samples, ...)` (no time dimension),\n",
    "                    representing input for the batch of samples at a certain\n",
    "                    time step.\n",
    "                states: list of tensors.\n",
    "            Returns:\n",
    "                outputs: tensor with shape `(samples, output_dim)`\n",
    "                    (no time dimension).\n",
    "                new_states: list of tensors, same length and shapes\n",
    "                    as 'states'. The first state in the list must be the\n",
    "                    output tensor at the previous timestep.\n",
    "        inputs: tensor of temporal data of shape `(samples, time, ...)`\n",
    "            (at least 3D).\n",
    "        initial_states: tensor with shape (samples, output_dim)\n",
    "            (no time dimension),\n",
    "            containing the initial values for the states used in\n",
    "            the step function.\n",
    "        go_backwards: boolean. If True, do the iteration over the time\n",
    "            dimension in reverse order and return the reversed sequence.\n",
    "        mask: binary tensor with shape `(samples, time, 1)`,\n",
    "            with a zero for every element that is masked.\n",
    "        constants: a list of constant values passed at each step.\n",
    "        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n",
    "        input_length: not relevant in the TensorFlow implementation.\n",
    "            Must be specified if using unrolling with Theano.\n",
    "\n",
    "    # Returns\n",
    "        A tuple, `(last_output, outputs, new_states)`.\n",
    "\n",
    "            last_output: the latest output of the rnn, of shape `(samples, ...)`\n",
    "            outputs: tensor with shape `(samples, time, ...)` where each\n",
    "                entry `outputs[s, t]` is the output of the step function\n",
    "                at time `t` for sample `s`.\n",
    "            new_states: list of tensors, latest states returned by\n",
    "                the step function, of shape `(samples, ...)`.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: if input dimension is less than 3.\n",
    "        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n",
    "        ValueError: if `mask` is provided (not `None`) but states is not provided\n",
    "            (`len(states)` == 0).\n",
    "    \"\"\"\n",
    "    ndim = len(inputs.get_shape())\n",
    "    if ndim < 3:\n",
    "        raise ValueError('Input should be at least 3D.')\n",
    "\n",
    "    # Transpose to time-major, i.e.\n",
    "    # from (batch, time, ...) to (time, batch, ...)\n",
    "    axes = [1, 0] + list(range(2, ndim))\n",
    "    inputs = tf.transpose(inputs, (axes))\n",
    "\n",
    "    if mask is not None:\n",
    "        if mask.dtype != tf.bool:\n",
    "            mask = tf.cast(mask, tf.bool)\n",
    "        if len(mask.get_shape()) == ndim - 1:\n",
    "            mask = expand_dims(mask)\n",
    "        mask = tf.transpose(mask, axes)\n",
    "\n",
    "    if constants is None:\n",
    "        constants = []\n",
    "\n",
    "    global uses_learning_phase\n",
    "    uses_learning_phase = False\n",
    "\n",
    "    if unroll:\n",
    "        if not inputs.get_shape()[0]:\n",
    "            raise ValueError('Unrolling requires a '\n",
    "                             'fixed number of timesteps.')\n",
    "        states = initial_states\n",
    "        successive_states = []\n",
    "        successive_outputs = []\n",
    "\n",
    "        input_list = tf.unstack(inputs)\n",
    "        if go_backwards:\n",
    "            input_list.reverse()\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_list = tf.unstack(mask)\n",
    "            if go_backwards:\n",
    "                mask_list.reverse()\n",
    "\n",
    "            for inp, mask_t in zip(input_list, mask_list):\n",
    "                output, new_states = step_function(inp, states + constants)\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "\n",
    "                # tf.where needs its condition tensor\n",
    "                # to be the same shape as its two\n",
    "                # result tensors, but in our case\n",
    "                # the condition (mask) tensor is\n",
    "                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n",
    "                # So we need to\n",
    "                # broadcast the mask to match the shape of A and B.\n",
    "                # That's what the tile call does,\n",
    "                # it just repeats the mask along its second dimension\n",
    "                # n times.\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "\n",
    "                if not successive_outputs:\n",
    "                    prev_output = zeros_like(output)\n",
    "                else:\n",
    "                    prev_output = successive_outputs[-1]\n",
    "\n",
    "                output = tf.where(tiled_mask_t, output, prev_output)\n",
    "\n",
    "                return_states = []\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    # (see earlier comment for tile explanation)\n",
    "                    tiled_mask_t = tf.tile(mask_t,\n",
    "                                           tf.stack([1, tf.shape(new_state)[1]]))\n",
    "                    return_states.append(tf.where(tiled_mask_t,\n",
    "                                                  new_state,\n",
    "                                                  state))\n",
    "                states = return_states\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "        else:\n",
    "            for inp in input_list:\n",
    "                output, states = step_function(inp, states + constants)\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "\n",
    "    else:\n",
    "        if go_backwards:\n",
    "            inputs = reverse(inputs, 0)\n",
    "\n",
    "        states = tuple(initial_states)\n",
    "\n",
    "        time_steps = tf.shape(inputs)[0]\n",
    "        outputs, _ = step_function(inputs[0], initial_states + constants)\n",
    "        output_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=outputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='output_ta')\n",
    "        input_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=inputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='input_ta')\n",
    "        input_ta = input_ta.unstack(inputs)\n",
    "        time = tf.constant(0, dtype='int32', name='time')\n",
    "\n",
    "        if mask is not None:\n",
    "            if not states:\n",
    "                raise ValueError('No initial states provided! '\n",
    "                                 'When using masking in an RNN, you should '\n",
    "                                 'provide initial states '\n",
    "                                 '(and your step function should return '\n",
    "                                 'as its first state at time `t` '\n",
    "                                 'the output at time `t-1`).')\n",
    "            if go_backwards:\n",
    "                mask = reverse(mask, 0)\n",
    "\n",
    "            mask_ta = tensor_array_ops.TensorArray(\n",
    "                dtype=tf.bool,\n",
    "                size=time_steps,\n",
    "                tensor_array_name='mask_ta')\n",
    "            mask_ta = mask_ta.unstack(mask)\n",
    "\n",
    "            def _step(time, output_ta_t, *states):\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]\n",
    "\n",
    "\n",
    "                mask_t = mask_ta.read(time)\n",
    "                output, new_states = step_function(current_input,\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "                output = tf.where(tiled_mask_t, output, states[0])\n",
    "                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t) + tuple(new_states)\n",
    "        else:\n",
    "            def _step(time, output_ta_t, *states):\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]\n",
    "                #states = states_ta_t.stack()[:time]\n",
    "\n",
    "\n",
    "                output, new_states = step_function(current_input,\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t) + tuple(new_states)\n",
    "\n",
    "        final_outputs = control_flow_ops.while_loop(\n",
    "            cond=lambda time, *_: time < time_steps,\n",
    "            body=_step,\n",
    "            loop_vars=(time, output_ta) + states,\n",
    "            parallel_iterations=32,\n",
    "            swap_memory=True)\n",
    "        last_time = final_outputs[0]\n",
    "        output_ta = final_outputs[1]\n",
    "        new_states = final_outputs[2:]\n",
    "\n",
    "        outputs = output_ta.stack()\n",
    "        last_output = output_ta.read(last_time - 1)\n",
    "\n",
    "    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n",
    "    outputs = tf.transpose(outputs, axes)\n",
    "    last_output._uses_learning_phase = uses_learning_phase\n",
    "    return last_output, outputs, new_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RNNCell Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellWrapper(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    A Cell Wrapper for Attention Mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        super(CellWrapper, self).__init__(*args, **kwargs)\n",
    "        self.cell = cell\n",
    "        self.cell.__init__(self.units, **kwargs)\n",
    "\n",
    "        self.trainable = self.cell.trainable\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self.cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self.cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self.cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self.cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self.cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self.cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self.cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self.cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self.cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self.cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self.cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self.cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self.cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self.cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def wrapper_state_size(self):\n",
    "        wrapper_state_size = self.cell.units\n",
    "        wrapper_state_size = 6\n",
    "        return wrapper_state_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        state_size_s = []\n",
    "        for state_size in [self.cell.state_size, self.wrapper_state_size]:\n",
    "            if hasattr(state_size, '__len__'):\n",
    "                state_size_s += list(state_size)\n",
    "            else:\n",
    "                state_size_s.append(state_size)\n",
    "        return tuple(state_size_s)\n",
    "        #return (self.cell.state_size, 3 * 2, )\n",
    "        #return (self.cell.units, self.cell.units)\n",
    "\n",
    "    @property\n",
    "    def state_length(self):\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            cell_state_length = len(self.cell.state_size)\n",
    "        else:\n",
    "            cell_state_length = 1\n",
    "        \n",
    "        wrapper_state_length = len(self.state_size) - cell_state_length\n",
    "        state_length = (cell_state_length, wrapper_state_length)\n",
    "        return state_length\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.cell.output_size\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "\n",
    "#    @property\n",
    "#    def weights(self):\n",
    "#        return self.cell.weights + super(CellWrapper, self).weights\n",
    "\n",
    "#    @property\n",
    "#    def get_weights(self):\n",
    "#        #return self.cell.weights + self.weights\n",
    "#        #return self.weights\n",
    "#\n",
    "#        params = self.weights\n",
    "#        return K.batch_get_value(params)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.cell.build(input_shape)\n",
    "        if self.cell.trainable:\n",
    "            self._trainable_weights.extend(self.cell.weights)\n",
    "        else:\n",
    "            self._non_trainable_weights.extend(self.cell.weights)\n",
    "\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kk = self.add_weight(shape=(input_dim, self.units,),\n",
    "                                  name='wrapper_kernel',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bb = self.add_weight(shape=(self.units,),\n",
    "                                  name='wrapper_bias',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        \"\"\"\n",
    "        self.kernel\n",
    "        self.recurrent_kernel\n",
    "\n",
    "        \"\"\"\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        inner_states = states[:self.state_length[0]]\n",
    "        wrapper_states = states[self.state_length[0]:]\n",
    "\n",
    "        new_outputs, new_inner_states = self.cell.call(inputs, inner_states,\n",
    "                                                 training=training)\n",
    "\n",
    "        i = K.dot(new_outputs, self.kk)\n",
    "        h = K.bias_add(i, self.bb)\n",
    "        \n",
    "        new_wrapper_states = h\n",
    "        \n",
    "        new_states = list(new_inner_states) + list(wrapper_states)\n",
    "\n",
    "        return new_outputs, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.state_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CellWrapper' object has no attribute '_cell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-840-908f4e48b07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CellWrapper' object has no attribute '_cell'"
     ]
    }
   ],
   "source": [
    "cc._cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTRNN(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 attention_ok=True,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(ATTRNN, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "        \n",
    "        self.attention_ok = attention_ok\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim])\n",
    "                    for dim in self.cell.state_size]\n",
    "        else:\n",
    "            return [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        \n",
    "        if self.attention_ok:\n",
    "            constants = inputs\n",
    "        \n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ATTRNN, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        #constants = K.stack(inputs)\n",
    "        #constants = [inputs]\n",
    "        last_output, outputs, states = fullrnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(ATTRNN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(ATTRNN, self).get_losses_for(inputs)\n",
    "        return super(ATTRNN, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"int\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-844-69ba36b9d733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCellWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mATTRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-843-f81a3382cf01>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATTRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-843-f81a3382cf01>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mstep_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconstants_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-838-4d5f1162f7be>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    845\u001b[0m                                       \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    848\u001b[0m         self.recurrent_kernel = self.add_weight(\n\u001b[1;32m    849\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    398\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "DD = ATTRNN(cc, return_sequences=True, return_state=False)\n",
    "dd = DD(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 2)"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 10, BATCH_SIZE 2\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.5688 - mean_absolute_error: 0.5688 - val_loss: 0.5684 - val_mean_absolute_error: 0.5684\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5221 - mean_absolute_error: 0.5221 - val_loss: 0.5084 - val_mean_absolute_error: 0.5084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/callbacks.py:93: UserWarning: Method on_batch_begin() is slow compared to the batch update (0.663406). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 0s - loss: 0.4854 - mean_absolute_error: 0.4854 - val_loss: 0.4684 - val_mean_absolute_error: 0.4684\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4593 - mean_absolute_error: 0.4593 - val_loss: 0.4401 - val_mean_absolute_error: 0.4401\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4402 - mean_absolute_error: 0.4402 - val_loss: 0.4162 - val_mean_absolute_error: 0.4162\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4210 - mean_absolute_error: 0.4210 - val_loss: 0.4004 - val_mean_absolute_error: 0.4004\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4029 - mean_absolute_error: 0.4029 - val_loss: 0.3828 - val_mean_absolute_error: 0.3828\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.3857 - mean_absolute_error: 0.3857 - val_loss: 0.3650 - val_mean_absolute_error: 0.3650\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3696 - mean_absolute_error: 0.3696 - val_loss: 0.3502 - val_mean_absolute_error: 0.3502\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3559 - mean_absolute_error: 0.3559 - val_loss: 0.3378 - val_mean_absolute_error: 0.3378\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_180': []},\n",
      "  {'begin_attrnn_158': [array([[-0.53507167,  0.28470337],\n",
      "       [-1.07608581, -0.23499501]], dtype=float32),\n",
      "                        array([[-0.03090984,  0.99952215],\n",
      "       [ 0.99952215,  0.03090984]], dtype=float32),\n",
      "                        array([ 0.,  0.], dtype=float32),\n",
      "                        array([[ 1.12380588, -0.85901451],\n",
      "       [ 1.0907377 ,  0.28698218]], dtype=float32),\n",
      "                        array([ 1.31809926,  0.67772174], dtype=float32)]}],\n",
      " [{'end_input_180': []},\n",
      "  {'end_attrnn_158': [array([[-0.53432751,  0.28544751],\n",
      "       [-1.0753417 , -0.23425086]], dtype=float32),\n",
      "                      array([[-0.03165398,  0.99877799],\n",
      "       [ 0.99877799,  0.03016569]], dtype=float32),\n",
      "                      array([ 0.00074414,  0.00074414], dtype=float32),\n",
      "                      array([[ 1.12306178, -0.85827035],\n",
      "       [ 1.0899936 ,  0.28772631]], dtype=float32),\n",
      "                      array([ 1.31884336,  0.67697757], dtype=float32)]}],\n",
      " [{'begin_input_180': []},\n",
      "  {'begin_attrnn_158': [array([[-0.53432751,  0.28544751],\n",
      "       [-1.0753417 , -0.23425086]], dtype=float32),\n",
      "                        array([[-0.03165398,  0.99877799],\n",
      "       [ 0.99877799,  0.03016569]], dtype=float32),\n",
      "                        array([ 0.00074414,  0.00074414], dtype=float32),\n",
      "                        array([[ 1.12306178, -0.85827035],\n",
      "       [ 1.0899936 ,  0.28772631]], dtype=float32),\n",
      "                        array([ 1.31884336,  0.67697757], dtype=float32)]}],\n",
      " [{'end_input_180': []},\n",
      "  {'end_attrnn_158': [array([[-0.5334745 ,  0.28627962],\n",
      "       [-1.07454157, -0.23339674]], dtype=float32),\n",
      "                      array([[-0.03250606,  0.99800885],\n",
      "       [ 0.99815655,  0.02936843]], dtype=float32),\n",
      "                      array([ 0.00153833,  0.00155937], dtype=float32),\n",
      "                      array([[ 1.12222731, -0.85741383],\n",
      "       [ 1.08918881,  0.28855669]], dtype=float32),\n",
      "                      array([ 1.31964362,  0.67611909], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTRNN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTRNNWrapper(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(ATTRNNWrapper, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim])\n",
    "                    for dim in self.cell.state_size]\n",
    "        else:\n",
    "            return [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(ATTRNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ATTRNNWrapper, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ATTRNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        #constants = K.stack(inputs)\n",
    "        constants = [inputs]\n",
    "        last_output, outputs, states = K.rnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(ATTRNNWrapper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(ATTRNNWrapper, self).get_losses_for(inputs)\n",
    "        return super(ATTRNNWrapper, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = ATTRNNWrapper(LSTM(cc, return_sequences=True, return_state=False))(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4883 - mean_absolute_error: 0.4883 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.4515 - val_mean_absolute_error: 0.4515\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4717 - mean_absolute_error: 0.4717 - val_loss: 0.4276 - val_mean_absolute_error: 0.4276\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - val_loss: 0.4182 - val_mean_absolute_error: 0.4182\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4073 - val_mean_absolute_error: 0.4073\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4118 - mean_absolute_error: 0.4118 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4204 - mean_absolute_error: 0.4204 - val_loss: 0.3904 - val_mean_absolute_error: 0.3904\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4052 - mean_absolute_error: 0.4052 - val_loss: 0.3814 - val_mean_absolute_error: 0.3814\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3981 - mean_absolute_error: 0.3981 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# GRU Decoder with Attention (encoder: `return_sequence=True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_many_to_many_1'](lstm_many_to_many_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_attention'](rnn_with_att.jpg)\n",
    "!['Overview of the Attention mechanism in an Encoder-Decoder setup'](lstm_attention_3.png)\n",
    "!['detail_lstm_attention'](detail_attentionmodel1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Attention Structure 1](https://blog.heuritech.com/2016/01/20/attention-mechanism/)  \n",
    "[Attention Structure 2](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)  \n",
    "[Attention Structure 3](https://medium.com/datalogue/attention-in-keras-1892773a4f22)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Embedding`:  \n",
    "> `(nb_words, vocab_size) x (vocab_size, embedding_dim) = (nb_words, embedding_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyGRUAttention (Feed-Forward, Not Recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import _object_list_uid\n",
    "from keras.utils.generic_utils import has_arg\n",
    "\n",
    "# Legacy support.\n",
    "from keras.legacy.layers import Recurrent\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from keras.layers import RNN, GRUCell, GRU, SimpleRNNCell\n",
    "#from keras.layers.recurrent import (_generate_dropout_ones,\n",
    "#                                    _generate_dropout_mask)\n",
    "\n",
    "\n",
    "def _generate_dropout_ones(inputs, dims):\n",
    "    # Currently, CTNK can't instantiate `ones` with symbolic shapes.\n",
    "    # Will update workaround once CTNK supports it.\n",
    "    if K.backend() == 'cntk':\n",
    "        ones = K.ones_like(K.reshape(inputs[:, 0], (-1, 1)))\n",
    "        return K.tile(ones, (1, dims))\n",
    "    else:\n",
    "        return K.ones((K.shape(inputs)[0], dims))\n",
    "\n",
    "\n",
    "def _generate_dropout_mask(ones, rate, training=None, count=1):\n",
    "    def dropped_inputs():\n",
    "        return K.dropout(ones, rate)\n",
    "\n",
    "    if count > 1:\n",
    "        return [K.in_train_phase(\n",
    "            dropped_inputs,\n",
    "            ones,\n",
    "            training=training) for _ in range(count)]\n",
    "    return K.in_train_phase(\n",
    "        dropped_inputs,\n",
    "        ones,\n",
    "        training=training)\n",
    "\n",
    "\n",
    "class GRUAttentionCell(GRUCell):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.state_size = self.units :for RNN, GRU\n",
    "        #self.state_size = (self.units, self.units) : for LSTM\n",
    "        #self.attn_length = 79\n",
    "        #self.attn_size = 79\n",
    "        #self.attn_vec_size = self.attn_size\n",
    "        #self.input_size = None\n",
    "        self.state_size = (self.units, 79*self.units)\n",
    "        #self.state_size = (self.units, self.units)\n",
    "        self.full_inputs = None\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print('cell.build Shape:', input_shape)\n",
    "        #self.timesteps = input_shape[1]\n",
    "        input_dim = input_shape[-1]\n",
    "        self.states = [None, None]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n",
    "                                      name='kernel',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units * 4),\n",
    "            name='recurrent_kernel',\n",
    "            initializer=self.recurrent_initializer,\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.context_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.units * 3),\n",
    "            name='context_kernel',\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units * 4,),\n",
    "                                        name='bias',\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.kernel_z = self.kernel[:,               : self.units * 1]\n",
    "        self.kernel_r = self.kernel[:, self.units * 1: self.units * 2]\n",
    "        self.kernel_h = self.kernel[:, self.units * 2: self.units * 3]\n",
    "        self.kernel_c = self.kernel[:, self.units * 3:]\n",
    "\n",
    "        self.recurrent_kernel_z = self.recurrent_kernel[:,               : self.units * 1]\n",
    "        self.recurrent_kernel_r = self.recurrent_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n",
    "        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 3:]\n",
    "\n",
    "        self.context_kernel_z = self.context_kernel[:,               : self.units * 1]\n",
    "        self.context_kernel_r = self.context_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.context_kernel_h = self.context_kernel[:, self.units * 2:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_z = self.bias[              : self.units * 1]\n",
    "            self.bias_r = self.bias[self.units * 1: self.units * 2]\n",
    "            self.bias_h = self.bias[self.units * 2: self.units * 3]\n",
    "            self.bias_c = self.bias[self.units * 3:]\n",
    "        else:\n",
    "            self.bias_z = None\n",
    "            self.bias_r = None\n",
    "            self.bias_h = None\n",
    "            self.bias_c = None\n",
    "        self.built = True\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameter Shapes\n",
    "        kernel : (input_dim, units)\n",
    "        recurrent_kernel : (units, units)\n",
    "        bias : (units, )\n",
    "\n",
    "        # Inherited Parameters\n",
    "        kernel : z, r, h\n",
    "        recurrent_kernel : z, r, h\n",
    "        bias : z, r, h\n",
    "\n",
    "        # New Parameters\n",
    "        input_dim\n",
    "        kernel_c\n",
    "        recurrent_kernel_c\n",
    "        bias_c\n",
    "        \"\"\"\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        if self.full_inputs is None:\n",
    "            self.full_inputs = states[-1]\n",
    "        full_inputs = self.full_inputs\n",
    "        timesteps = K.int_shape(full_inputs)[1]\n",
    "        print('cell.call Input Shape:', K.int_shape(inputs),\n",
    "              'Full State len:', len(states),\n",
    "              'State Shape:', K.int_shape(states[0]),\n",
    "              'Full h Shape:', K.int_shape(states[-1]))\n",
    "\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
    "                self.dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, self.units),\n",
    "                self.recurrent_dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        if self.implementation == 1:\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs_z = inputs * dp_mask[0]\n",
    "                inputs_r = inputs * dp_mask[1]\n",
    "                inputs_h = inputs * dp_mask[2]\n",
    "                inputs_c = inputs * dp_mask[3]\n",
    "            else:\n",
    "                inputs_z = inputs\n",
    "                inputs_r = inputs\n",
    "                inputs_h = inputs\n",
    "                inputs_c = inputs\n",
    "            x_z = K.dot(inputs_z, self.kernel_z)\n",
    "            x_r = K.dot(inputs_r, self.kernel_r)\n",
    "            x_h = K.dot(inputs_h, self.kernel_h)\n",
    "            x_c = K.dot(inputs_c, self.kernel_c)\n",
    "            if self.use_bias:\n",
    "                x_z = K.bias_add(x_z, self.bias_z)\n",
    "                x_r = K.bias_add(x_r, self.bias_r)\n",
    "                x_h = K.bias_add(x_h, self.bias_h)\n",
    "                x_c = K.bias_add(x_c, self.bias_c)\n",
    "\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1_z = h_tm1 * rec_dp_mask[0]\n",
    "                h_tm1_r = h_tm1 * rec_dp_mask[1]\n",
    "                h_tm1_h = h_tm1 * rec_dp_mask[2]\n",
    "                h_tm1_c = h_tm1 * rec_dp_mask[3]\n",
    "            else:\n",
    "                h_tm1_z = h_tm1\n",
    "                h_tm1_r = h_tm1\n",
    "                h_tm1_h = h_tm1\n",
    "                h_tm1_c = h_tm1\n",
    "\n",
    "            # calculate the context vector\n",
    "            #context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "\n",
    "            # Attention Context Part\n",
    "            h_tm1_c = K.repeat(h_tm1_c, timesteps)\n",
    "            #h_tm1_c = full_inputs\n",
    "            print('h:', K.int_shape(full_inputs), 's0:', K.int_shape(h_tm1_c))\n",
    "            e = self.activation(h_tm1_c + K.dot(full_inputs, self.recurrent_kernel_c))\n",
    "            a = K.softmax(e)\n",
    "            print('A:', K.int_shape(a), 'inputs_c:', K.int_shape(inputs_c), 'full input:', K.int_shape(full_inputs))\n",
    "            c_t = K.sum(a * full_inputs, axis=1, keepdims=False)\n",
    "            #c_t = K.batch_dot(a, inputs_c, axes=1)\n",
    "\n",
    "            print('Done c_t:', K.int_shape(c_t))\n",
    "            print('Done context_kernel:', K.int_shape(self.context_kernel_z))\n",
    "            print('Done recurrent_kernel:', self.recurrent_kernel_z)\n",
    "            print('Done h_tm_z * rec:', K.dot(h_tm1_z, self.recurrent_kernel_z))\n",
    "            \n",
    "            # GRU Part\n",
    "            z = self.recurrent_activation(x_z +\n",
    "                                          K.dot(h_tm1_z,\n",
    "                                                self.recurrent_kernel_z) +\n",
    "                                          K.dot(c_t, self.context_kernel_z))\n",
    "            r = self.recurrent_activation(x_r +\n",
    "                                          K.dot(h_tm1_r,\n",
    "                                                self.recurrent_kernel_r) +\n",
    "                                          K.dot(c_t, self.context_kernel_r))\n",
    "\n",
    "            hh = self.activation(x_h +\n",
    "                                 K.dot(r * h_tm1_h,\n",
    "                                       self.recurrent_kernel_h) +\n",
    "                                 K.dot(c_t, self.context_kernel_h))\n",
    "\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs *= dp_mask[0]\n",
    "            matrix_x = K.dot(inputs, self.kernel)\n",
    "            if self.use_bias:\n",
    "                matrix_x = K.bias_add(matrix_x, self.bias)\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1 *= rec_dp_mask[0]\n",
    "            matrix_inner = K.dot(h_tm1,\n",
    "                                 self.recurrent_kernel[:, :2 * self.units])\n",
    "\n",
    "            x_z = matrix_x[:, :self.units]\n",
    "            x_r = matrix_x[:, self.units: 2 * self.units]\n",
    "            recurrent_z = matrix_inner[:, :self.units]\n",
    "            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n",
    "\n",
    "            z = self.recurrent_activation(x_z + recurrent_z)\n",
    "            r = self.recurrent_activation(x_r + recurrent_r)\n",
    "\n",
    "            x_h = matrix_x[:, 2 * self.units:]\n",
    "            recurrent_h = K.dot(r * h_tm1,\n",
    "                                self.recurrent_kernel[:, 2 * self.units:])\n",
    "            hh = self.activation(x_h + recurrent_h)\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                h._uses_learning_phase = True\n",
    "                \n",
    "        print(K.int_shape(states[-1]))\n",
    "        states = [h] + [states[-1]]\n",
    "        return h, [h, self.full_inputs]\n",
    "\n",
    "\n",
    "class MyRNNAttention(RNN):\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state = [K.tile(initial_state, [1, dim])\n",
    "                     for dim in self.cell.state_size[:-1]]\n",
    "        else:\n",
    "            state = [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "        full_inputs = [inputs]\n",
    "        return state + full_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: [(None, 80), (None, 79, 80)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"int\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-74594e56f235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mGRUAttention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyRNNAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mstep_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconstants_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f19f6a0e6532>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                       \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         self.recurrent_kernel = self.add_weight(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    398\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "GRUAttention = MyRNNAttention(GRUAttentionCell(ndimY), return_sequences=True)\n",
    "dec = GRUAttention(enc, constants=enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MinimalRNNCell(Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        #self.state_size = units\n",
    "        self.state_size = (units, units * 79)\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-456-aa30eef606a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinimalRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36minput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \"\"\"\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[1;32m   1029\u001b[0m                                  'and thus has no defined input shape.')\n\u001b[1;32m   1030\u001b[0m         \u001b[0mall_input_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "a = MinimalRNNCell(ndimY)\n",
    "a.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An initial_state was passed that is not compatible with `cell.state_size`. Received `state_spec`=[<keras.engine.topology.InputSpec object at 0x7f70d9075a90>]; However `cell.state_size` is (110, 8690)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-453-bee2953dda3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Cel = MinimalRNNCell(ndimY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMinimalRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0;34m'`cell.state_size`. Received `state_spec`={}; '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0;34m'However `cell.state_size` is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                     '{}'.format(self.state_spec, self.cell.state_size))\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             self.state_spec = [InputSpec(shape=(None, dim))\n",
      "\u001b[0;31mValueError\u001b[0m: An initial_state was passed that is not compatible with `cell.state_size`. Received `state_spec`=[<keras.engine.topology.InputSpec object at 0x7f70d9075a90>]; However `cell.state_size` is (110, 8690)"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "#Cel = MinimalRNNCell(ndimY)\n",
    "dec = RNN(MinimalRNNCell(ndimY), return_sequences=True)(enc, enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class CellWrapper(Layer):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(**kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self._cell.output_shape\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self._cell.weights, self.weights]\n",
    "\n",
    "    def get_weights(self):\n",
    "        return [self._cell.get_weights(), self.get_weights()]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        \n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: (None, 80)\n",
      "cell.call Input Shape: (None, 80) Full State len: 2 State Shape: (None, 80) Full h Shape: (None, 6320)\n",
      "h: (None, 6320) s0: (None, 6320, 80)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-0e340b8850aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mCel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    587\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2563\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m<ipython-input-435-f19f6a0e6532>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m#h_tm1_c = full_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's0:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs_c:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80]."
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "Cel = GRUAttentionCell(ndimX)\n",
    "dec = RNN(Cel, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CellWrapper(Layer):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(**kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self._cell.output_shape\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        inner_weights = self._cell.weights\n",
    "        wrapper_weights = super(CellWrapper, self).weights\n",
    "        return [inner_weights, inner_weights]\n",
    "\n",
    "    def get_weights(self):\n",
    "        return [self._cell.get_weights(), super(CellWrapper, self).get_weights()]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        \n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CellWrapper(SimpleRNNCell):\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(cell.units, **kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "        \n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine import Layer\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import has_arg\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "\n",
    "\n",
    "class _RNNAttentionCell(Layer):\n",
    "    \"\"\"Base class for recurrent attention mechanisms.\n",
    "\n",
    "    This base class implements the RNN cell interface and defines a standard\n",
    "    way for attention mechanisms to interact with a (wrapped) \"core\" RNN cell\n",
    "    (such as the `SimpleRNNCell`, `GRUCell` or `LSTMCell`).\n",
    "\n",
    "    The main idea is that the attention mechanism, implemented by\n",
    "    `attention_call` in extensions of this class, computes an \"attention\n",
    "    encoding\", based on the attended input as well as the input and the core\n",
    "    cell state(s) at the current time step, which will be used as modified\n",
    "    input for the core cell.\n",
    "\n",
    "    # Arguments\n",
    "        cell: A RNN cell instance. The cell to wrap by the attention mechanism.\n",
    "            A RNN cell is a class that has:\n",
    "            - a `call(input_at_t, states_at_t)` method, returning\n",
    "                `(output_at_t, states_at_t_plus_1)`.\n",
    "            - a `state_size` attribute. This can be a single integer\n",
    "                (single state) in which case it is the size of the recurrent\n",
    "                state (which should be the same as the size of the cell\n",
    "                output). This can also be a list/tuple of integers (one size\n",
    "                per state). In this case, the first entry (`state_size[0]`)\n",
    "                should be the same as the size of the cell output.\n",
    "        attend_after: Boolean (default False). If True, the attention\n",
    "            transformation defined by `attention_call` will be applied after\n",
    "            the core cell transformation (and the attention encoding will be\n",
    "            used as input for core cell transformation next time step).\n",
    "        concatenate_input: Boolean (default True). If True the concatenation of\n",
    "            the attention encoding and the original input will be used as input\n",
    "            for the core cell transformation. If set to False, only the\n",
    "            attention encoding will be used as input for the core cell\n",
    "            transformation.\n",
    "\n",
    "    # Abstract Methods and Properties\n",
    "        Extension of this class must implement:\n",
    "            - `attention_build` (method): Builds the attention transformation\n",
    "              based on input shapes.\n",
    "            - `attention_call` (method): Defines the attention transformation\n",
    "              returning the attention encoding.\n",
    "            - `attention_size` (property): After `attention_build` has been\n",
    "              called, this property should return the size (int) of the\n",
    "              attention encoding. Do this by setting `_attention_size` in scope\n",
    "              of `attention_build` or by implementing `attention_size`\n",
    "              property.\n",
    "        Extension of this class can optionally implement:\n",
    "            - `attention_state_size` (property): Default [`attention_size`].\n",
    "              If the attention mechanism has it own internal states (besides\n",
    "              the attention encoding which is by default the only part of\n",
    "              `attention_states`) override this property accordingly.\n",
    "        See docs of the respective method/property for further details.\n",
    "\n",
    "    # Details of interaction between attention and cell transformations\n",
    "        Let \"cell\" denote core (wrapped) RNN cell and \"att(cell)\" the complete\n",
    "        attentive RNN cell defined by this class. We write the core cell\n",
    "        transformation as:\n",
    "\n",
    "            y{t}, s_cell{t+1} = cell.call(x{t}, s_cell{t})\n",
    "\n",
    "        where y{t} denotes the output, x{t} the input at and s_cell{t} the core\n",
    "        cell state(s) at time t and s_cell{t+1} the updated state(s).\n",
    "\n",
    "        We can then write the complete \"attentive\" cell transformation as:\n",
    "\n",
    "            y{t}, s_att(cell){t+1} = att(cell).call(x{t}, s_att(cell){t},\n",
    "                                                    constants=attended)\n",
    "\n",
    "        where s_att(cell) denotes the complete states of the attentive cell,\n",
    "        which consists of the core cell state(s) followed but the attention\n",
    "        state(s), and attended denotes the tensor attended to (note: no time\n",
    "        indexing as this is the same constant input at each time step).\n",
    "\n",
    "        Internally, this is how the attention transformation, implemented by\n",
    "        `attention_call`, interacts with the core cell transformation\n",
    "        `cell.call`:\n",
    "\n",
    "        - with `attend_after=False` (default):\n",
    "            a{t}, s_att{t+1} = att(cell).attention_call(x_t, s_cell{t},\n",
    "                                                        attended, s_att{t})\n",
    "            with `concatenate_input=True` (default):\n",
    "                x'{t} = [x{t}, a{t}]\n",
    "            else:\n",
    "                x'{t} = a{t}\n",
    "            y{t}, s_cell{t+1} = cell.call(x'{t}, s_cell{t})\n",
    "\n",
    "        - with `attend_after=True`:\n",
    "            with `concatenate_input=True` (default):\n",
    "                x'{t} = [x{t}, a{t-1}]\n",
    "            else:\n",
    "                x'{t} = a{t-1}\n",
    "            y{t}, s_cell{t+1} = cell.call(x'{t}, s_cell{t})\n",
    "            a{t}, s_att{t+1} = att(cell).attention_call(x_t, s_cell{t+1},\n",
    "                                                        attended, s_att{t})\n",
    "\n",
    "        where a{t} denotes the attention encoding, s_att{t} the attention\n",
    "        state(s), x'{t} the modified core cell input and [x{.}, a{.}] the\n",
    "        (tensor) concatenation of the input and attention encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 attend_after=False,\n",
    "                 concatenate_input=False,\n",
    "                 **kwargs):\n",
    "        self.cell = cell  # must be set before calling super\n",
    "        super(_RNNAttentionCell, self).__init__(**kwargs)\n",
    "        self.attend_after = attend_after\n",
    "        self.concatenate_input = concatenate_input\n",
    "        self.attended_spec = None\n",
    "        self._attention_size = None\n",
    "\n",
    "    def attention_call(self,\n",
    "                       inputs,\n",
    "                       cell_states,\n",
    "                       attended,\n",
    "                       attention_states,\n",
    "                       training=None):\n",
    "        \"\"\"The main logic for computing the attention encoding.\n",
    "\n",
    "        # Arguments\n",
    "            inputs: The input at current time step.\n",
    "            cell_states: States for the core RNN cell.\n",
    "            attended: The same tensor(s) to attend at each time step.\n",
    "            attention_states: States dedicated for the attention mechanism.\n",
    "            training: whether run in training mode or not\n",
    "\n",
    "        # Returns\n",
    "            attention_h: The computed attention encoding at current time step.\n",
    "            attention_states: States to be passed to next `attention_call`. By\n",
    "                default this should be [`attention_h`].\n",
    "                NOTE: if additional states are used, these should be appended\n",
    "                after `attention_h`, i.e. `attention_states[0]` should always\n",
    "                be `attention_h`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`attention_call` must be implemented by extensions of `{}`'.format(\n",
    "                self.__class__.__name__))\n",
    "\n",
    "    def attention_build(self, input_shape, cell_state_size, attended_shape):\n",
    "        \"\"\"Build the attention mechanism.\n",
    "\n",
    "        NOTE: `self._attention_size` should be set in this method to the size\n",
    "        of the attention encoding (i.e. size of first `attention_states`)\n",
    "        unless `attention_size` property is implemented in another way.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of integers. Shape of the input at a single time\n",
    "                step.\n",
    "            cell_state_size: List of tuple of integers.\n",
    "            attended_shape: List of tuple of integers.\n",
    "\n",
    "            NOTE: both `cell_state_size` and `attended_shape` will always be\n",
    "            lists - for simplicity. For example: even if (wrapped)\n",
    "            `cell.state_size` is an integer, `cell_state_size` will be a list\n",
    "            of this one element.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`attention_build` must be implemented by extensions of `{}`'.format(\n",
    "                self.__class__.__name__))\n",
    "\n",
    "    @property\n",
    "    def attention_size(self):\n",
    "        \"\"\"Size off attention encoding, an integer.\n",
    "        \"\"\"\n",
    "        if self._attention_size is None and self.built:\n",
    "            raise NotImplementedError(\n",
    "                'extensions of `{}` must either set property `_attention_size`'\n",
    "                ' in `attention_build` or implement the or implement'\n",
    "                ' `attention_size` in some other way'.format(\n",
    "                    self.__class__.__name__))\n",
    "\n",
    "        return self._attention_size\n",
    "\n",
    "    @property\n",
    "    def attention_state_size(self):\n",
    "        \"\"\"Size of attention states, defaults to `attention_size`, an integer.\n",
    "\n",
    "        Modify this property to return list of integers if the attention\n",
    "        mechanism has several internal states. Note that the first size should\n",
    "        always be the size of the attention encoding, i.e.:\n",
    "            `attention_state_size[0]` = `attention_size`\n",
    "        \"\"\"\n",
    "        return self.attention_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        \"\"\"Size of states of the complete attentive cell, a tuple of integers.\n",
    "\n",
    "        The attentive cell's states consists of the core RNN cell state size(s)\n",
    "        followed by attention state size(s). NOTE it is important that the core\n",
    "        cell states are first as the first state of any RNN cell should be same\n",
    "        as the cell's output.\n",
    "        \"\"\"\n",
    "        state_size_s = []\n",
    "        for state_size in [self.cell.state_size, self.attention_state_size]:\n",
    "            if hasattr(state_size, '__len__'):\n",
    "                state_size_s += list(state_size)\n",
    "            else:\n",
    "                state_size_s.append(state_size)\n",
    "\n",
    "        return tuple(state_size_s)\n",
    "\n",
    "    def call(self, inputs, states, constants, training=None):\n",
    "        \"\"\"Complete attentive cell transformation.\n",
    "        \"\"\"\n",
    "        attended = constants\n",
    "        cell_states = states[:self._num_wrapped_states]\n",
    "        attention_states = states[self._num_wrapped_states:]\n",
    "\n",
    "        if self.attend_after:\n",
    "            attention_call = self.call_attend_after\n",
    "        else:\n",
    "            attention_call = self.call_attend_before\n",
    "\n",
    "        return attention_call(inputs=inputs,\n",
    "                              cell_states=cell_states,\n",
    "                              attended=attended,\n",
    "                              attention_states=attention_states,\n",
    "                              training=training)\n",
    "\n",
    "    def call_attend_before(self,\n",
    "                           inputs,\n",
    "                           cell_states,\n",
    "                           attended,\n",
    "                           attention_states,\n",
    "                           training=None):\n",
    "        \"\"\"Complete attentive cell transformation, if `attend_after=False`.\n",
    "        \"\"\"\n",
    "        attention_h, new_attention_states = self.attention_call(\n",
    "            inputs=inputs,\n",
    "            cell_states=cell_states,\n",
    "            attended=attended,\n",
    "            attention_states=attention_states,\n",
    "            training=training)\n",
    "\n",
    "        if self.concatenate_input:\n",
    "            cell_input = concatenate([attention_h, inputs])\n",
    "        else:\n",
    "            cell_input = attention_h\n",
    "\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states,\n",
    "                                                     training=training)\n",
    "        else:\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states)\n",
    "\n",
    "        return output, new_cell_states + new_attention_states\n",
    "\n",
    "    def call_attend_after(self,\n",
    "                          inputs,\n",
    "                          cell_states,\n",
    "                          attended,\n",
    "                          attention_states,\n",
    "                          training=None):\n",
    "        \"\"\"Complete attentive cell transformation, if `attend_after=True`.\n",
    "        \"\"\"\n",
    "        attention_h_previous = attention_states[0]\n",
    "\n",
    "        if self.concatenate_input:\n",
    "            cell_input = concatenate([attention_h_previous, inputs])\n",
    "        else:\n",
    "            cell_input = attention_h_previous\n",
    "\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states,\n",
    "                                                     training=training)\n",
    "        else:\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states)\n",
    "\n",
    "        attention_h, new_attention_states = self.attention_call(\n",
    "            inputs=inputs,\n",
    "            cell_states=new_cell_states,\n",
    "            attended=attended,\n",
    "            attention_states=attention_states,\n",
    "            training=training)\n",
    "\n",
    "        return output, new_cell_states, new_attention_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _num_elements(x):\n",
    "        if hasattr(x, '__len__'):\n",
    "            return len(x)\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    @property\n",
    "    def _num_wrapped_states(self):\n",
    "        return self._num_elements(self.cell.state_size)\n",
    "\n",
    "    @property\n",
    "    def _num_attention_states(self):\n",
    "        return self._num_elements(self.attention_state_size)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Builds attention mechanism and wrapped cell (if keras layer).\n",
    "\n",
    "        Arguments:\n",
    "            input_shape: list of tuples of integers, the input feature shape\n",
    "                (inputs sequence shape without time dimension) followed by\n",
    "                constants (i.e. attended) shapes.\n",
    "        \"\"\"\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('input shape should contain shape of both cell '\n",
    "                             'inputs and constants (attended)')\n",
    "\n",
    "        attended_shape = input_shape[1:]\n",
    "        input_shape = input_shape[0]\n",
    "        self.attended_spec = [InputSpec(shape=shape) for shape in attended_shape]\n",
    "        if isinstance(self.cell.state_size, int):\n",
    "            cell_state_size = [self.cell.state_size]\n",
    "        else:\n",
    "            cell_state_size = list(self.cell.state_size)\n",
    "        self.attention_build(\n",
    "            input_shape=input_shape,\n",
    "            cell_state_size=cell_state_size,\n",
    "            attended_shape=attended_shape,\n",
    "        )\n",
    "\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_input_shape = (input_shape[0],\n",
    "                                self.attention_size +\n",
    "                                input_shape[-1] if self.concatenate_input\n",
    "                                else self._attention_size)\n",
    "            self.cell.build(cell_input_shape)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            cell_output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            cell_output_dim = self.cell.state_size\n",
    "\n",
    "        return input_shape[0], cell_output_dim\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        return super(_RNNAttentionCell, self).trainable_weights + \\\n",
    "               self.cell.trainable_weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        return super(_RNNAttentionCell, self).non_trainable_weights + \\\n",
    "               self.cell.non_trainable_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'attend_after': self.attend_after,\n",
    "                  'concatenate_input': self.concatenate_input}\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(_RNNAttentionCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class MixtureOfGaussian1DAttention(_RNNAttentionCell):\n",
    "    \"\"\"RNN attention mechanism for attending sequences.\n",
    "\n",
    "    The attention encoding (passed to the wrapped core RNN cell) is obtained by\n",
    "    letting the attention mechanism predict a Mixture of Gaussian distribution\n",
    "    (MoG) over the time dimension of the attended feature sequence. The\n",
    "    attention encoding is taken as the weighted sum of all features - where the\n",
    "    weight is given by the probability density function (evaluated in the\n",
    "    respective time step) according the predicted MoG distribution.\n",
    "\n",
    "    # Arguments\n",
    "        components: Positive integer, the number of mixture components to use\n",
    "            (for each head, see below).\n",
    "        heads: Positive integer (Default 1), the number of independent \"read\n",
    "            heads\" to use. Each head produces an independent (sub) attention\n",
    "            encoding, by predicting an independent MoG each. The (full)\n",
    "            attention encoding passed to the wrapped core RNN cell is the\n",
    "            concatenation of the attention encodings from each head. See \"Notes\n",
    "            on multiple heads vs multiple components\" below.\n",
    "        mu_activation: The activation function applied (after learnt linear\n",
    "            transformation) for mu:s (expectation value/location) of each\n",
    "            Gaussian component.\n",
    "        sigma_activation: The activation function applied (after learnt linear\n",
    "            transformation) for sigma:s (standard deviation) of each Gaussian\n",
    "            component. *NOTE* that this function should only return values > 0.\n",
    "        sigma_epsilon: Positive Float, this value is added to sigma to force it\n",
    "            to be at least this value.\n",
    "        predict_delta_mu: Boolean (Default True), whether or not to let the\n",
    "            attention mechanism to predict the _change_ in location (mu) of\n",
    "            each mixture component. This is recommended as it usually leads to\n",
    "            more stable convergence. By passing a `mu_activation` that always\n",
    "            returns a value > 0 and having `predict_delta_mu=True` it is\n",
    "            enforced that the attention mechanism \"parses\" the attended\n",
    "            sequence \"from start to end\" as the attention can not be moved\n",
    "            backwards.\n",
    "        For initializers, regularizers & constraints: See docs of Dense layer.\n",
    "\n",
    "    # Notes on multiple heads vs multiple components\n",
    "        A single head can \"attend to multiple parts of the sequence\" by\n",
    "        using multiple components. However, the features from the location of\n",
    "        the components are averaged together by a weighted sum (no\n",
    "        information is kept on their internal ordering for example). With\n",
    "        multiple heads, on the other side, the attention mechanism can \"pick\n",
    "        out\" features from multiple locations without averaging them, and\n",
    "        passing them \"intact\" to the core RNN cell. This is done at the cost of\n",
    "        a larger input vector to, and thereby more parameters of, the core RNN\n",
    "        cell.\n",
    "\n",
    "    # Example - Machine Translation with Attention and \"teacher forcing\"\n",
    "        # NOTE that this is a minimal naive example, this setup will not\n",
    "        # perform well for machine translation in general.\n",
    "        # TODO add `examples/machine_translation_with_attention.py`\n",
    "        # with performing setup\n",
    "\n",
    "        input_english = Input((None, tokens_english))\n",
    "        target_french_tm1 = Input((None, tokens_french))\n",
    "\n",
    "        cell = MixtureOfGaussian1DAttention(LSTMCell(64), components=3, heads=3)\n",
    "        attention_lstm = RNN(cell, return_sequences=True)\n",
    "        h_sequence = attention_lstm(target_french_tm1, constants=input_english)\n",
    "        output_layer = TimeDistributed(Dense(tokens_french, activation='softmax'))\n",
    "        predicted_french = output_layer(h_sequence)\n",
    "\n",
    "        train_model = Model(\n",
    "            inputs=[target_french_tm1, input_english],\n",
    "            outputs=predicted_french\n",
    "        )\n",
    "        model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "        model.fit(\n",
    "            x=[french_text[:, :-1], english_text],\n",
    "            y=french_text[:, 1:],\n",
    "            epochs=10\n",
    "        )\n",
    "    \"\"\"\n",
    "    def __init__(self, cell,\n",
    "                 components,\n",
    "                 heads=1,\n",
    "                 mu_activation=None,\n",
    "                 sigma_activation='exponential',\n",
    "                 sigma_epsilon=1e-3,\n",
    "                 predict_delta_mu=True,  # TODO alternative name `cumulative_mu`?\n",
    "                 kernel_initializer='glorot_uniform',  # FIXME most likely not optimal\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MixtureOfGaussian1DAttention, self).__init__(cell, **kwargs)\n",
    "        self.components = components\n",
    "        self.heads = heads\n",
    "        self.mu_activation = activations.get(mu_activation)\n",
    "        self.sigma_activation = activations.get(sigma_activation)\n",
    "        self.sigma_epsilon = sigma_epsilon\n",
    "        self.predict_delta_mu = predict_delta_mu\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "    @property\n",
    "    def attention_state_size(self):\n",
    "        \"\"\"Size of states dedicated for the attention mechanism.\n",
    "\n",
    "        If self.predict_delta_mu is True, mu (the \"location\") for all heads'\n",
    "        components needs to be forwarded to next time step and is therefore\n",
    "        added to the attention states.\n",
    "        \"\"\"\n",
    "        attention_state_size = [self.attention_size]\n",
    "        if self.predict_delta_mu:\n",
    "            mu_size = self.components * self.heads\n",
    "            attention_state_size.append(mu_size)\n",
    "\n",
    "        return attention_state_size\n",
    "\n",
    "    def attention_call(self,\n",
    "                       inputs,\n",
    "                       cell_states,\n",
    "                       attended,\n",
    "                       attention_states,\n",
    "                       training=None):\n",
    "        # only one attended sequence for now (verified in build)\n",
    "        [attended] = attended\n",
    "        mu_tm1 = attention_states[1] if self.predict_delta_mu else None\n",
    "\n",
    "        mog_input = concatenate([inputs, cell_states[0]])\n",
    "        params = K.bias_add(K.dot(mog_input, self.kernel), self.bias)\n",
    "\n",
    "        # dynamic creation of time index\n",
    "        # TODO check support by all backends\n",
    "        # TODO faster with non-dynamic if size of time dimension is fixed?\n",
    "        time_idx = K.arange(K.shape(attended)[1], dtype='float32')\n",
    "        time_idx = K.expand_dims(K.expand_dims(time_idx, 0), -1)\n",
    "\n",
    "        if self.heads == 1:\n",
    "            attention_h, mu = self._get_attention_h_and_mu(params, attended,\n",
    "                                                           mu_tm1, time_idx)\n",
    "        else:\n",
    "            c = self.components\n",
    "            attention_h_s, mu_s = zip(*[\n",
    "                self._get_attention_h_and_mu(\n",
    "                    params=params[..., c * i * 3:c * (i+1) * 3],\n",
    "                    attended=attended,\n",
    "                    mu_tm1=(mu_tm1[..., c * i:c * (i+1)]\n",
    "                            if self.predict_delta_mu else None),\n",
    "                    time_idx=time_idx\n",
    "                ) for i in range(self.heads)\n",
    "            ])\n",
    "            attention_h = concatenate(list(attention_h_s))\n",
    "            mu = concatenate(list(mu_s))\n",
    "\n",
    "        new_attention_states = [attention_h]\n",
    "        if self.predict_delta_mu:\n",
    "            new_attention_states.append(mu)\n",
    "\n",
    "        return attention_h, new_attention_states\n",
    "\n",
    "    def _get_attention_h_and_mu(self, params, attended, mu_tm1, time_idx):\n",
    "        \"\"\"Computes the attention encoding for \"one head\".\n",
    "\n",
    "        # Arguments\n",
    "            params: The MoG params (before activation) for one head.\n",
    "            attended: The attended sequence (tensor).\n",
    "            mu_tm1: mu from previous time step (tensor) if self.use_delta is\n",
    "                True otherwise None.\n",
    "            time_idx: Time index of the attended (tensor).\n",
    "\n",
    "        # Returns\n",
    "            attention_h: The attention encoding for the attention of one head.\n",
    "            mu: the location(s) of each mixture component for one head.\n",
    "        \"\"\"\n",
    "        def sigma_activation(x):\n",
    "            return self.sigma_activation(x) + self.sigma_epsilon\n",
    "\n",
    "        mixture_weights, mu, sigma = [\n",
    "            activation(params[..., i * self.components:(i + 1) * self.components])\n",
    "            for i, activation in enumerate(\n",
    "                [K.softmax, self.mu_activation, sigma_activation])]\n",
    "\n",
    "        if self.predict_delta_mu:\n",
    "            mu += mu_tm1\n",
    "\n",
    "        mixture_weights_, mu_, sigma_ = [\n",
    "            K.expand_dims(p, 1) for p in [mixture_weights, mu, sigma]]\n",
    "\n",
    "        attention_w = K.sum(\n",
    "            mixture_weights_ * K.exp(- sigma_ * K.square(mu_ - time_idx)),\n",
    "            # NOTE no normalisation was carried out in original paper by A. Graves\n",
    "            axis=-1,\n",
    "            keepdims=True\n",
    "        )\n",
    "        attention_h = K.sum(attention_w * attended, axis=1)\n",
    "\n",
    "        return attention_h, mu\n",
    "\n",
    "    def attention_build(self, input_shape, cell_state_size, attended_shape):\n",
    "        if not len(attended_shape) == 1:\n",
    "            raise ValueError('only a single attended supported')\n",
    "        attended_shape = attended_shape[0]\n",
    "        if not len(attended_shape) == 3:\n",
    "            raise ValueError('only support attending tensors with dim=3')\n",
    "\n",
    "        # NOTE _attention_size must always be set in `attention_build`\n",
    "        self._attention_size = attended_shape[-1] * self.heads\n",
    "        mog_in_dim = (input_shape[-1] + cell_state_size[0])\n",
    "        mog_out_dim = self.heads * self.components * 3\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(mog_in_dim, mog_out_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            name='kernel',\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "        self.bias = self.add_weight(shape=(mog_out_dim,),\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    name='bias',\n",
    "                                    regularizer=self.bias_regularizer,\n",
    "                                    constraint=self.bias_constraint)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'components': self.components,\n",
    "            'heads': self.heads,\n",
    "            'mu_activation': activations.serialize(self.mu_activation),\n",
    "            'sigma_activation': activations.serialize(self.sigma_activation),\n",
    "            'sigma_epsilon': self.sigma_epsilon,\n",
    "            'predict_delta_mu': self.predict_delta_mu,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(MixtureOfGaussian1DAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRUAttentionCell(GRUCell):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.state_size = self.units :for RNN, GRU\n",
    "        #self.state_size = (self.units, self.units) : for LSTM\n",
    "        self.attn_length = 79\n",
    "        self.attn_size = 79\n",
    "        self.attn_vec_size = self.attn_size\n",
    "        self.input_size = None\n",
    "        self.state_size = (self.units, self.units)\n",
    "\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def state_size(self):\n",
    "    size = (self._cell.state_size, self._attn_size,\n",
    "            self._attn_size * self._attn_length)\n",
    "    if self._state_is_tuple:\n",
    "      return size\n",
    "    else:\n",
    "      return sum(list(size))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state = [K.tile(initial_state, [1, dim])\n",
    "                     for dim in self.cell.state_size[:-1]]\n",
    "        else:\n",
    "            state = [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #self.timesteps = input_shape[0]\n",
    "        print('build cell:', input_shape)\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n",
    "                                      name='kernel',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units * 4),\n",
    "            name='recurrent_kernel',\n",
    "            initializer=self.recurrent_initializer,\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.context_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.units * 3),\n",
    "            name='context_kernel',\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units * 4,),\n",
    "                                        name='bias',\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.kernel_z = self.kernel[:,               : self.units * 1]\n",
    "        self.kernel_r = self.kernel[:, self.units * 1: self.units * 2]\n",
    "        self.kernel_h = self.kernel[:, self.units * 2: self.units * 3]\n",
    "        self.kernel_c = self.kernel[:, self.units * 3:]\n",
    "\n",
    "        self.recurrent_kernel_z = self.recurrent_kernel[:,               : self.units * 1]\n",
    "        self.recurrent_kernel_r = self.recurrent_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n",
    "        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 3:]\n",
    "\n",
    "        self.context_kernel_z = self.context_kernel[:,               : self.units * 1]\n",
    "        self.context_kernel_r = self.context_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.context_kernel_h = self.context_kernel[:, self.units * 2:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_z = self.bias[              : self.units * 1]\n",
    "            self.bias_r = self.bias[self.units * 1: self.units * 2]\n",
    "            self.bias_h = self.bias[self.units * 2: self.units * 3]\n",
    "            self.bias_c = self.bias[self.units * 3:]\n",
    "        else:\n",
    "            self.bias_z = None\n",
    "            self.bias_r = None\n",
    "            self.bias_h = None\n",
    "            self.bias_c = None\n",
    "        self.built = True\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameter Shapes\n",
    "        kernel : (input_dim, units)\n",
    "        recurrent_kernel : (units, units)\n",
    "        bias : (units, )\n",
    "\n",
    "        # Inherited Parameters\n",
    "        kernel : z, r, h\n",
    "        recurrent_kernel : z, r, h\n",
    "        bias : z, r, h\n",
    "\n",
    "        # New Parameters\n",
    "        input_dim\n",
    "        kernel_c\n",
    "        recurrent_kernel_c\n",
    "        bias_c\n",
    "        \"\"\"\n",
    "\n",
    "    def call(self, inputs, states, training=None,\n",
    "             constants=None):\n",
    "        print('cell.call Input Shape:', K.int_shape(inputs), 'State Shape:', K.int_shape(states[0]))\n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        full_inputs = constants\n",
    "        timesteps = K.int_shape(full_inputs)[1]\n",
    "\n",
    "\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
    "                self.dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, self.units),\n",
    "                self.recurrent_dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        if self.implementation == 1:\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs_z = inputs * dp_mask[0]\n",
    "                inputs_r = inputs * dp_mask[1]\n",
    "                inputs_h = inputs * dp_mask[2]\n",
    "                inputs_c = inputs * dp_mask[3]\n",
    "            else:\n",
    "                inputs_z = inputs\n",
    "                inputs_r = inputs\n",
    "                inputs_h = inputs\n",
    "                inputs_c = inputs\n",
    "            x_z = K.dot(inputs_z, self.kernel_z)\n",
    "            x_r = K.dot(inputs_r, self.kernel_r)\n",
    "            x_h = K.dot(inputs_h, self.kernel_h)\n",
    "            x_c = K.dot(inputs_c, self.kernel_c)\n",
    "            if self.use_bias:\n",
    "                x_z = K.bias_add(x_z, self.bias_z)\n",
    "                x_r = K.bias_add(x_r, self.bias_r)\n",
    "                x_h = K.bias_add(x_h, self.bias_h)\n",
    "                x_c = K.bias_add(x_c, self.bias_c)\n",
    "\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1_z = h_tm1 * rec_dp_mask[0]\n",
    "                h_tm1_r = h_tm1 * rec_dp_mask[1]\n",
    "                h_tm1_h = h_tm1 * rec_dp_mask[2]\n",
    "                h_tm1_c = h_tm1 * rec_dp_mask[3]\n",
    "            else:\n",
    "                h_tm1_z = h_tm1\n",
    "                h_tm1_r = h_tm1\n",
    "                h_tm1_h = h_tm1\n",
    "                h_tm1_c = h_tm1\n",
    "\n",
    "            # calculate the context vector\n",
    "            #context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "\n",
    "            # Attention Context Part\n",
    "            #h_tm1_c = K.repeat(h_tm1_c, timesteps)\n",
    "            h_tm1_c = full_inputs\n",
    "            e = self.activation(x_c + K.dot(h_tm1_c, self.recurrent_kernel_c))\n",
    "            a = K.softmax(e)\n",
    "            print('A:', K.int_shape(a), 'inputs_c:', K.int_shape(inputs_c), 'full input:', K.int_shape(full_inputs))\n",
    "            c_t = K.dot(a, inputs_c)\n",
    "\n",
    "            # GRU Part\n",
    "            z = self.recurrent_activation(x_z +\n",
    "                                          K.dot(h_tm1_z,\n",
    "                                                self.recurrent_kernel_z) +\n",
    "                                          K.dot(c_t, self.context_kernel_z))\n",
    "            r = self.recurrent_activation(x_r +\n",
    "                                          K.dot(h_tm1_r,\n",
    "                                                self.recurrent_kernel_r) +\n",
    "                                          K.dot(c_t, self.context_kernel_r))\n",
    "\n",
    "            hh = self.activation(x_h +\n",
    "                                 K.dot(r * h_tm1_h,\n",
    "                                       self.recurrent_kernel_h) +\n",
    "                                 K.dot(c_t, self.context_kernel_h))\n",
    "\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs *= dp_mask[0]\n",
    "            matrix_x = K.dot(inputs, self.kernel)\n",
    "            if self.use_bias:\n",
    "                matrix_x = K.bias_add(matrix_x, self.bias)\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1 *= rec_dp_mask[0]\n",
    "            matrix_inner = K.dot(h_tm1,\n",
    "                                 self.recurrent_kernel[:, :2 * self.units])\n",
    "\n",
    "            x_z = matrix_x[:, :self.units]\n",
    "            x_r = matrix_x[:, self.units: 2 * self.units]\n",
    "            recurrent_z = matrix_inner[:, :self.units]\n",
    "            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n",
    "\n",
    "            z = self.recurrent_activation(x_z + recurrent_z)\n",
    "            r = self.recurrent_activation(x_r + recurrent_r)\n",
    "\n",
    "            x_h = matrix_x[:, 2 * self.units:]\n",
    "            recurrent_h = K.dot(r * h_tm1,\n",
    "                                self.recurrent_kernel[:, 2 * self.units:])\n",
    "            hh = self.activation(x_h + recurrent_h)\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                h._uses_learning_phase = True\n",
    "        return h, [h]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        input_english = Input((None, tokens_english))\n",
    "        target_french_tm1 = Input((None, tokens_french))\n",
    "\n",
    "        cell = MixtureOfGaussian1DAttention(LSTMCell(64), components=3, heads=3)\n",
    "        h_sequence = RNN(cell, return_sequences=True)(target_french_tm1, constants=input_english)\n",
    "        output_layer = TimeDistributed(Dense(tokens_french, activation='softmax'))\n",
    "        predicted_french = output_layer(h_sequence)\n",
    "\n",
    "        train_model = Model(\n",
    "            inputs=[target_french_tm1, input_english],\n",
    "            outputs=predicted_french\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: (None, 80)\n",
      "cell.call Input Shape: (None, 80) Full State len: 2 State Shape: (None, 80) Full h Shape: (None, 6320)\n",
      "h: (None, 6320) s0: (None, 6320, 80)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-442-0e340b8850aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mCel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    587\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2563\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m<ipython-input-435-f19f6a0e6532>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m#h_tm1_c = full_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's0:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs_c:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80]."
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "Cel = GRUAttentionCell(ndimX)\n",
    "dec = RNN(Cel, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_172 (InputLayer)       (None, 79, 80)            0         \n",
      "_________________________________________________________________\n",
      "lstm_167 (LSTM)              (None, 79, 80)            51520     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 79, 1)             81        \n",
      "=================================================================\n",
      "Total params: 51,601\n",
      "Trainable params: 51,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "tim = TimeDistributed(Dense(1))(enc)\n",
    "#dec = GRUAttention(4, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(tim)\n",
    "model = Model(inputs=input_, outputs=tim)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent  # _time_distributed_dense\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    "\n",
    "\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                            input_dim=None, output_dim=None,\n",
    "                            timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        w: weight matrix.\n",
    "        b: optional bias vector.\n",
    "        dropout: wether to apply dropout (same dropout mask\n",
    "            for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyGRUAttentionDecoder(Recurrent):\n",
    "\n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 output_activation='sigmoid',\n",
    "                 return_probabilities=False,\n",
    "                 name='MyGRUAttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='ones',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states \n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. \n",
    "            \"Neural machine translation by jointly learning to align and translate.\" \n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.output_activation = output_activation\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    "\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    "\n",
    "        if self.stateful:\n",
    "            super().reset_states()\n",
    "\n",
    "        self.states = [None, None]  # y, h\n",
    "\n",
    "        \n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "\n",
    "\n",
    "        # Matrices for creating the context vector\n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        # Matrices for Gates\n",
    "        # st = h_tilda\n",
    "        num = len(['reset_gate', 'update_gate', 'h_tilda(proposal)'])\n",
    "\n",
    "        self.W = self.add_weight(shape=(num, self.output_dim, self.units),\n",
    "                                   name='W',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U = self.add_weight(shape=(num, self.units, self.units),\n",
    "                                   name='U',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.V = self.add_weight(shape=(num, self.input_dim, self.units),\n",
    "                                   name='V',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b = self.add_weight(shape=(num, self.units, ),\n",
    "                                   name='b',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "\n",
    "        # Matrices for making the final prediction vector\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    "\n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    "\n",
    "\n",
    "        return super().call(x)\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        print('inputs shape:', inputs.get_shape())\n",
    "\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        h0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    "\n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    "\n",
    "        return [y0, h0]\n",
    "\n",
    "    def step(self, x, states):\n",
    "\n",
    "        yt_before, ht_before = states\n",
    "\n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        repeated_ht_before = K.repeat(ht_before, self.timesteps)\n",
    "\n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        weighted_ht_before = K.dot(repeated_ht_before, self.W_a)\n",
    "\n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(weighted_ht_before + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.softmax(et)  # vector of size (batchsize, timesteps, 1)\n",
    "\n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        \n",
    "        # At timestep `t`:\n",
    "        \n",
    "        # first calculate the \"r\"; reset gate\n",
    "        # r = sigmoid(xt * Ur + ht-1 * Wr + br) \n",
    "        # New r = sigmoid(xt * Ur + ht-1 * Wr + br + context * Vr)\n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(yt_before, self.W[0])\n",
    "            + K.dot(ht_before, self.U[0])\n",
    "            + K.dot(context, self.V[0])\n",
    "            + self.b[0])\n",
    "\n",
    "        # now calculate the \"z\"; update gate\n",
    "        # z = sigmoid(xt * Uz + ht-1 * Wz + bz)\n",
    "        # New z = sigmoid(xt * Uz + ht-1 * Wz + bz + context * Vz)\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(yt_before, self.W[1])\n",
    "            + K.dot(ht_before, self.U[1])\n",
    "            + K.dot(context, self.V[1])\n",
    "            + self.b[1])\n",
    "\n",
    "        # calculate the proposal \"g\"; hidden state for now(tilda)\n",
    "        # h_tilda = tanh(xt * Wh + (ht-1 * rt) * Uh + bh)\n",
    "        # New h_tilda = tanh(xt * Wh + (ht-1 * rt) * Uh + bh + context * Vh)\n",
    "        h_tilda = activations.tanh(\n",
    "            K.dot(yt_before, self.W[2])\n",
    "            + K.dot((rt * ht_before), self.U[2])\n",
    "            + K.dot(context, self.V[2])\n",
    "            + self.b[2])\n",
    "\n",
    "        # new hidden state 'ht' from 'h_tilda'\n",
    "        # ht = (1-zt) * h_tilda + zt * ht-1\n",
    "        # ht = (1-zt) * h_tilda + zt * ht-1\n",
    "        ht = (1 - zt) * h_tilda + zt * ht_before\n",
    "\n",
    "        \n",
    "        # Output Activation\n",
    "        y_ = (K.dot(yt_before, self.W_o)\n",
    "              + K.dot(ht_before, self.U_o)\n",
    "              + K.dot(context, self.C_o)\n",
    "              + self.b_o)\n",
    "\n",
    "        if self.output_activation == 'softmax':\n",
    "            yt = activations.softmax(y_)\n",
    "            \n",
    "        elif self.output_activation == 'sigmoid':\n",
    "            yt = activations.sigmoid(y_)\n",
    "\n",
    "        elif self.output_activation == 'tanh':\n",
    "            yt = activations.tanh(y_)\n",
    "\n",
    "            \n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, ht]\n",
    "        else:\n",
    "            return yt, [yt, ht]\n",
    "\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_10 to have shape (None, 79, 80) but got array with shape (80000, 79, 110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-d5e98611bd84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;31m# 1: progress bar, 2: one line per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0;31m#validation_data=(testX, testY),  # Validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                    \u001b[0;31m#callbacks=[history],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   )\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_10 to have shape (None, 79, 80) but got array with shape (80000, 79, 110)"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   #callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 3))\n",
    "ax.plot(fitted.history['loss'], label='train')\n",
    "if 'val_loss' in fitted.history.keys():\n",
    "    ax.plot(fitted.history['val_loss'], label='validation')\n",
    "ax.legend()\n",
    "ax.set_xticks(np.arange(EPOCH_NUM))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = fitted.model.evaluate(train_X, train_Y, verbose=0)\n",
    "print('Accuracy: %.3f' % (train_accuracy * 100))\n",
    "\n",
    "train_Y_hat_array = fitted.model.predict(train_X)\n",
    "train_Y_real = output_decoder(train_Y)\n",
    "train_Y_hat = output_decoder(train_Y_hat_array)\n",
    "train_X_real = input_decoder(train_X)\n",
    "\n",
    "print(train_X_real[:3])\n",
    "print(train_Y_real[:3])\n",
    "print(train_Y_hat[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train mean of RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = fitted.model.evaluate(test_X, test_Y, verbose=0)\n",
    "print('Accuracy: %.3f' % (test_accuracy * 100))\n",
    "\n",
    "test_Y_hat_array = fitted.model.predict(test_X)\n",
    "test_Y_real = output_decoder(test_Y)\n",
    "test_Y_hat = output_decoder(test_Y_hat_array)\n",
    "test_X_real = input_decoder(test_X)\n",
    "\n",
    "print(test_X_real[:3])\n",
    "print(test_Y_real[:3])\n",
    "print(test_Y_hat[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "gist": {
   "data": {
    "description": "tensorflow/konlpy.ipynb",
    "public": false
   },
   "id": "5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "kernelspec": {
   "display_name": "Tensorflow: Python3.6 (conda env)",
   "language": "python",
   "name": "tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "1189px",
    "left": "0px",
    "right": "1123px",
    "top": "136px",
    "width": "157px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": 16,
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
