{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Network-Learning-Parameter\" data-toc-modified-id=\"Network-Learning-Parameter-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Network Learning Parameter</a></div><div class=\"lev1 toc-item\"><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></div><div class=\"lev1 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev4 toc-item\"><a href=\"#Run\" data-toc-modified-id=\"Run-3001\"><span class=\"toc-item-num\">3.0.0.1&nbsp;&nbsp;</span>Run</a></div><div class=\"lev3 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-301\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev4 toc-item\"><a href=\"#Run\" data-toc-modified-id=\"Run-3011\"><span class=\"toc-item-num\">3.0.1.1&nbsp;&nbsp;</span>Run</a></div><div class=\"lev1 toc-item\"><a href=\"#RNNCell-Wrapper\" data-toc-modified-id=\"RNNCell-Wrapper-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>RNNCell Wrapper</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-401\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev2 toc-item\"><a href=\"#RNN-Wrapper\" data-toc-modified-id=\"RNN-Wrapper-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>RNN Wrapper</a></div><div class=\"lev3 toc-item\"><a href=\"#fullrnn\" data-toc-modified-id=\"fullrnn-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>fullrnn</a></div><div class=\"lev3 toc-item\"><a href=\"#RNN-Wrapper\" data-toc-modified-id=\"RNN-Wrapper-412\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>RNN Wrapper</a></div><div class=\"lev4 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-4121\"><span class=\"toc-item-num\">4.1.2.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev3 toc-item\"><a href=\"#ATTRNN\" data-toc-modified-id=\"ATTRNN-413\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>ATTRNN</a></div><div class=\"lev4 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-4131\"><span class=\"toc-item-num\">4.1.3.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev3 toc-item\"><a href=\"#ATTRNN-Wrapper\" data-toc-modified-id=\"ATTRNN-Wrapper-414\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>ATTRNN Wrapper</a></div><div class=\"lev4 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-4141\"><span class=\"toc-item-num\">4.1.4.1&nbsp;&nbsp;</span>Training</a></div><div class=\"lev1 toc-item\"><a href=\"#GRU-Decoder-with-Attention-(encoder:-return_sequence=True)\" data-toc-modified-id=\"GRU-Decoder-with-Attention-(encoder:-return_sequence=True)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>GRU Decoder with Attention (encoder: <code>return_sequence=True</code>)</a></div><div class=\"lev3 toc-item\"><a href=\"#MyGRUAttention-(Feed-Forward,-Not-Recurrent)\" data-toc-modified-id=\"MyGRUAttention-(Feed-Forward,-Not-Recurrent)-501\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>MyGRUAttention (Feed-Forward, Not Recurrent)</a></div><div class=\"lev3 toc-item\"><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-502\"><span class=\"toc-item-num\">5.0.2&nbsp;&nbsp;</span>Modeling</a></div><div class=\"lev3 toc-item\"><a href=\"#Training\" data-toc-modified-id=\"Training-503\"><span class=\"toc-item-num\">5.0.3&nbsp;&nbsp;</span>Training</a></div><div class=\"lev3 toc-item\"><a href=\"#Scoring\" data-toc-modified-id=\"Scoring-504\"><span class=\"toc-item-num\">5.0.4&nbsp;&nbsp;</span>Scoring</a></div><div class=\"lev3 toc-item\"><a href=\"#Testing\" data-toc-modified-id=\"Testing-505\"><span class=\"toc-item-num\">5.0.5&nbsp;&nbsp;</span>Testing</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pydemia/apps/anaconda3/envs/tf-py36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (SimpleRNN, RNN, LSTM, GRU,\n",
    "                          Input, Reshape, Dense, Flatten, Permute, Lambda,\n",
    "                          Embedding, RepeatVector, Activation,\n",
    "                          TimeDistributed, Bidirectional,\n",
    "                          dot, multiply, concatenate, merge)\n",
    "from keras.callbacks import Callback, LambdaCallback\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.weights = []\n",
    "        self.states = []\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.weights.append([{'begin_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.weights.append([{'end_' + layer.name: layer.get_weights()} for layer in model.layers])\n",
    "        \n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[0].get_weights()))\n",
    "#print_outputs = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[2].output))\n",
    "#print_states = LambdaCallback(on_epoch_end=lambda batch, logs: pprint(model.layers[2].states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Learning Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = HIDDEN_SIZE = 64\n",
    "EPOCH_NUM = 100\n",
    "BATCH_SIZE = 256\n",
    "#GPU_NUM = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence to sequence example in Keras (character-level).\n",
    "This script demonstrates how to implement a basic character-level\n",
    "sequence-to-sequence model.  \n",
    "We apply it to translating\n",
    "short English sentences into short French sentences,\n",
    "character-by-character. Note that it is fairly unusual to\n",
    "do character-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "\n",
    "* Summary of the algorithm\n",
    "    - We start with input sequences from a domain (e.g. English sentences)\n",
    "        and correspding target sequences from another domain\n",
    "        (e.g. French sentences).\n",
    "    - An encoder LSTM turns input sequences to 2 state vectors\n",
    "        (we keep the last LSTM state and discard the outputs).\n",
    "    - A decoder LSTM is trained to turn the target sequences into\n",
    "        the same sequence but offset by one timestep in the future,\n",
    "        a training process called \"teacher forcing\" in this context.  \n",
    "        Is uses as initial state the state vectors from the encoder.\n",
    "        Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "        given `targets[...t]`, conditioned on the input sequence.\n",
    "    - In inference mode, when we want to decode unknown input sequences, we:\n",
    "        - Encode the input sequence into state vectors\n",
    "        - Start with a target sequence of size 1\n",
    "            (just the start-of-sequence character)\n",
    "        - Feed the state vectors and 1-char target sequence\n",
    "            to the decoder to produce predictions for the next character\n",
    "        - Sample the next character using these predictions\n",
    "            (we simply use argmax).\n",
    "        - Append the sampled character to the target sequence\n",
    "        - Repeat until we generate the end-of-sequence character or we\n",
    "            hit the character limit.\n",
    "* Data download\n",
    "    English to French sentence pairs.\n",
    "    http://www.manythings.org/anki/fra-eng.zip\n",
    "    Lots of neat sentence pairs datasets can be found at:\n",
    "    http://www.manythings.org/anki/\n",
    "\n",
    "* References\n",
    "    - Sequence to Sequence Learning with Neural Networks\n",
    "        https://arxiv.org/abs/1409.3215\n",
    "    - Learning Phrase Representations using\n",
    "        RNN Encoder-Decoder for Statistical Machine Translation\n",
    "        https://arxiv.org/abs/1406.1078\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_X = np.random.sample(300).reshape(-1, 3, 2)\n",
    "train_Y = np.random.sample(300).reshape(-1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.48190335,  0.37729399],\n",
       "        [ 0.17947748,  0.50321185],\n",
       "        [ 0.1484575 ,  0.80850603]],\n",
       "\n",
       "       [[ 0.2486874 ,  0.18620542],\n",
       "        [ 0.1939146 ,  0.40464986],\n",
       "        [ 0.52080591,  0.13876185]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.20182727,  0.66169752],\n",
       "        [ 0.82607336,  0.71335799],\n",
       "        [ 0.74202261,  0.13219845]],\n",
       "\n",
       "       [[ 0.26560703,  0.1766803 ],\n",
       "        [ 0.97170505,  0.43612362],\n",
       "        [ 0.41986697,  0.10127776]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_many_to_many_1'](lstm_many_to_many_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_attention'](rnn_with_att.jpg)\n",
    "!['Overview of the Attention mechanism in an Encoder-Decoder setup'](lstm_attention_3.png)\n",
    "!['detail_lstm_attention'](detail_attentionmodel1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Attention Structure 1](https://blog.heuritech.com/2016/01/20/attention-mechanism/)  \n",
    "[Attention Structure 2](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)  \n",
    "[Attention Structure 3](https://medium.com/datalogue/attention-in-keras-1892773a4f22)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Embedding`:  \n",
    "> `(nb_words, vocab_size) x (vocab_size, embedding_dim) = (nb_words, embedding_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import _object_list_uid\n",
    "from keras.utils.generic_utils import has_arg\n",
    "\n",
    "# Legacy support.\n",
    "from keras.legacy.layers import Recurrent\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import (RNN,\n",
    "                          SimpleRNNCell,\n",
    "                          LSTMCell, LSTM,\n",
    "                          GRUCell, GRU,\n",
    "                          Layer, Input,\n",
    "                          Wrapper)\n",
    "\n",
    "from keras.layers.recurrent import *\n",
    "from keras import Model\n",
    "#from keras.layers.recurrent import (_generate_dropout_ones,\n",
    "#                                    _generate_dropout_mask)\n",
    "\n",
    "# %% ATTRNNCell ---------------------------------------------------------------\n",
    "\n",
    "class ATTRNNCell(Layer):\n",
    "\n",
    "    def __init__(self, units, attn_size, attn_length,\n",
    "                 activation='tanh',\n",
    "                 **kwargs):\n",
    "        super(ATTRNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self._attn_size = attn_size\n",
    "        self._attn_length = attn_length\n",
    "        self._state_size = self.units\n",
    "        #self.state_size = (self.units,\n",
    "        #                   self._attn_size,\n",
    "        #                   self._attn_size * self._attn_length)\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        #state_size = self.units\n",
    "\n",
    "        state_size_a = []\n",
    "        for state_size in (self.units, self.units):\n",
    "            state_size_a.append(state_size)\n",
    "\n",
    "        return state_size_a\n",
    "\n",
    "    #@state_size.setter\n",
    "    #def state_size(self, state_size):\n",
    "    #    self.state_size = state_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "        self.attn_kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                           initializer='uniform',\n",
    "                                           name='attn_kernel')\n",
    "\n",
    "    def call(self, inputs, states, constants=None):\n",
    "        prev_output = states[0]\n",
    "        attn_state = states[1:]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        output = self.activation(output)\n",
    "        return output, [output] + list(attn_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  [(None, 3, 2), (None, 2), 8         \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "bb = ATTRNNCell(2, 3, 3)\n",
    "cc = RNN(bb, return_sequences=True, return_state=True)(aa)\n",
    "#cc = LSTM(2, return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% ATTRNN Layer -------------------------------------------------------------\n",
    "\n",
    "class ATTRNN(RNN):\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        super(ATTRNN, self).__init__(cell, **kwargs)\n",
    "        #self.cell = cell\n",
    "        #self.return_sequences = return_sequences\n",
    "        #self.return_state = return_state\n",
    "        #self.go_backwards = go_backwards\n",
    "        #self.stateful = stateful\n",
    "        #self.unroll = unroll\n",
    "\n",
    "        #self.supports_masking = True\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        #self.state_spec = None\n",
    "        #self._states = None\n",
    "        #self.constants_spec = None\n",
    "        #self._num_constants = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        return super(ATTRNN, self).get_initial_state(inputs)\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(RNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(RNN, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(RNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        last_output, outputs, states = fullrnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "    \n",
    "    def get_attention(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "attrnn_2 (ATTRNN)            (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %% RUN ----------------------------------------------------------------------\n",
    "\n",
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "cc = ATTRNN(ATTRNNCell(2, 3, 3), return_sequences=True, return_state=True)(aa)\n",
    "#cc = LSTM(2, return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "attrnn_3 (ATTRNN)            (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %% RUN ----------------------------------------------------------------------\n",
    "\n",
    "aa = Input(shape=(3, 1), dtype='float32')\n",
    "bb = Input(tensor=aa)\n",
    "#cc = RNN(ATTRNNCell(2, 3, 3), return_sequences=True, return_state=True)(aa, constants=bb)\n",
    "cc = ATTRNN(LSTMCell(2), return_sequences=True, return_state=True)(aa)\n",
    "dd = Model(inputs=aa, outputs=cc)\n",
    "dd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RNNCell Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellWrapper(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    A Cell Wrapper for Attention Mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        super(CellWrapper, self).__init__(*args, **kwargs)\n",
    "        self._cell = cell\n",
    "        self._cell.__init__(self.units, **kwargs)\n",
    "\n",
    "        self.trainable = self._cell.trainable\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._cell.output_size\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "#    @property\n",
    "#    def weights(self):\n",
    "#        return self._cell.weights + super(CellWrapper, self).weights\n",
    "\n",
    "#    @property\n",
    "#    def get_weights(self):\n",
    "#        #return self._cell.weights + self.weights\n",
    "#        #return self.weights\n",
    "#\n",
    "#        params = self.weights\n",
    "#        return K.batch_get_value(params)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self._cell.build(input_shape)\n",
    "        if self._cell.trainable:\n",
    "            self._trainable_weights.extend(self._cell.weights)\n",
    "        else:\n",
    "            self._non_trainable_weights.extend(self._cell.weights)\n",
    "\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kk = self.add_weight(shape=(input_dim, self.units,),\n",
    "                                  name='wrapper_kernel',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bb = self.add_weight(shape=(self.units,),\n",
    "                                  name='wrapper_bias',\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        \"\"\"\n",
    "        self.kernel\n",
    "        self.recurrent_kernel\n",
    "\n",
    "        \"\"\"\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        new_inputs, new_states = self._cell.call(inputs, states,\n",
    "                                                 training=training)\n",
    "\n",
    "        new_inputs = K.dot(self.kk, new_inputs)\n",
    "        new_inputs = K.bias_add(new_inputs, self.bb)\n",
    "\n",
    "        return new_inputs, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = RNN(cc, return_sequences=True, return_state=False)(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_3/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_3/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.21733773,  0.08077967],\n",
       "        [-0.56632608, -1.07468975]], dtype=float32),\n",
       " array([[-0.99097782,  0.13402598],\n",
       "        [ 0.13402598,  0.99097782]], dtype=float32),\n",
       " array([ 0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_3/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.21733773,  0.08077967],\n",
       "        [-0.56632608, -1.07468975]], dtype=float32),\n",
       " array([[-0.99097782,  0.13402598],\n",
       "        [ 0.13402598,  0.99097782]], dtype=float32),\n",
       " array([ 0.,  0.], dtype=float32),\n",
       " array([[ 0.89775884, -0.07153285],\n",
       "        [-0.35253835, -0.80943173]], dtype=float32),\n",
       " array([ 0.14992344,  1.28210735], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn_3/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/recurrent_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn_3/wrapper_bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4883 - mean_absolute_error: 0.4883 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.4515 - val_mean_absolute_error: 0.4515\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4717 - mean_absolute_error: 0.4717 - val_loss: 0.4276 - val_mean_absolute_error: 0.4276\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - val_loss: 0.4182 - val_mean_absolute_error: 0.4182\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4073 - val_mean_absolute_error: 0.4073\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4118 - mean_absolute_error: 0.4118 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4204 - mean_absolute_error: 0.4204 - val_loss: 0.3904 - val_mean_absolute_error: 0.3904\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4052 - mean_absolute_error: 0.4052 - val_loss: 0.3814 - val_mean_absolute_error: 0.3814\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3981 - mean_absolute_error: 0.3981 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fullrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import *\n",
    "\n",
    "\n",
    "def fullrnn(step_function, inputs, initial_states,\n",
    "        go_backwards=False, mask=None, constants=None,\n",
    "        unroll=False, input_length=None):\n",
    "    \"\"\"Iterates over the time dimension of a tensor.\n",
    "\n",
    "    # Arguments\n",
    "        step_function: RNN step function.\n",
    "            Parameters:\n",
    "                inputs: tensor with shape `(samples, ...)` (no time dimension),\n",
    "                    representing input for the batch of samples at a certain\n",
    "                    time step.\n",
    "                states: list of tensors.\n",
    "            Returns:\n",
    "                outputs: tensor with shape `(samples, output_dim)`\n",
    "                    (no time dimension).\n",
    "                new_states: list of tensors, same length and shapes\n",
    "                    as 'states'. The first state in the list must be the\n",
    "                    output tensor at the previous timestep.\n",
    "        inputs: tensor of temporal data of shape `(samples, time, ...)`\n",
    "            (at least 3D).\n",
    "        initial_states: tensor with shape (samples, output_dim)\n",
    "            (no time dimension),\n",
    "            containing the initial values for the states used in\n",
    "            the step function.\n",
    "        go_backwards: boolean. If True, do the iteration over the time\n",
    "            dimension in reverse order and return the reversed sequence.\n",
    "        mask: binary tensor with shape `(samples, time, 1)`,\n",
    "            with a zero for every element that is masked.\n",
    "        constants: a list of constant values passed at each step.\n",
    "        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n",
    "        input_length: not relevant in the TensorFlow implementation.\n",
    "            Must be specified if using unrolling with Theano.\n",
    "\n",
    "    # Returns\n",
    "        A tuple, `(last_output, outputs, new_states)`.\n",
    "\n",
    "            last_output: the latest output of the rnn, of shape `(samples, ...)`\n",
    "            outputs: tensor with shape `(samples, time, ...)` where each\n",
    "                entry `outputs[s, t]` is the output of the step function\n",
    "                at time `t` for sample `s`.\n",
    "            new_states: list of tensors, latest states returned by\n",
    "                the step function, of shape `(samples, ...)`.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: if input dimension is less than 3.\n",
    "        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n",
    "        ValueError: if `mask` is provided (not `None`) but states is not provided\n",
    "            (`len(states)` == 0).\n",
    "    \"\"\"\n",
    "    ndim = len(inputs.get_shape())\n",
    "    if ndim < 3:\n",
    "        raise ValueError('Input should be at least 3D.')\n",
    "\n",
    "    # Transpose to time-major, i.e.\n",
    "    # from (batch, time, ...) to (time, batch, ...)\n",
    "    axes = [1, 0] + list(range(2, ndim))\n",
    "    inputs = tf.transpose(inputs, (axes))\n",
    "\n",
    "    if mask is not None:\n",
    "        if mask.dtype != tf.bool:\n",
    "            mask = tf.cast(mask, tf.bool)\n",
    "        if len(mask.get_shape()) == ndim - 1:\n",
    "            mask = expand_dims(mask)\n",
    "        mask = tf.transpose(mask, axes)\n",
    "\n",
    "    if constants is None:\n",
    "        constants = []\n",
    "\n",
    "    global uses_learning_phase\n",
    "    uses_learning_phase = False\n",
    "\n",
    "    if unroll:\n",
    "        if not inputs.get_shape()[0]:\n",
    "            raise ValueError('Unrolling requires a '\n",
    "                             'fixed number of timesteps.')\n",
    "        states = initial_states\n",
    "        successive_states = []\n",
    "        successive_outputs = []\n",
    "\n",
    "        input_list = tf.unstack(inputs)\n",
    "        if go_backwards:\n",
    "            input_list.reverse()\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_list = tf.unstack(mask)\n",
    "            if go_backwards:\n",
    "                mask_list.reverse()\n",
    "\n",
    "            for inp, mask_t in zip(input_list, mask_list):\n",
    "                output, new_states = step_function(inp, states + constants)\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "\n",
    "                # tf.where needs its condition tensor\n",
    "                # to be the same shape as its two\n",
    "                # result tensors, but in our case\n",
    "                # the condition (mask) tensor is\n",
    "                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n",
    "                # So we need to\n",
    "                # broadcast the mask to match the shape of A and B.\n",
    "                # That's what the tile call does,\n",
    "                # it just repeats the mask along its second dimension\n",
    "                # n times.\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "\n",
    "                if not successive_outputs:\n",
    "                    prev_output = zeros_like(output)\n",
    "                else:\n",
    "                    prev_output = successive_outputs[-1]\n",
    "\n",
    "                output = tf.where(tiled_mask_t, output, prev_output)\n",
    "\n",
    "                return_states = []\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    # (see earlier comment for tile explanation)\n",
    "                    tiled_mask_t = tf.tile(mask_t,\n",
    "                                           tf.stack([1, tf.shape(new_state)[1]]))\n",
    "                    return_states.append(tf.where(tiled_mask_t,\n",
    "                                                  new_state,\n",
    "                                                  state))\n",
    "                states = return_states\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "        else:\n",
    "            for inp in input_list:\n",
    "                output, states = step_function(inp, states + constants)\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    uses_learning_phase = True\n",
    "                successive_outputs.append(output)\n",
    "                successive_states.append(states)\n",
    "            last_output = successive_outputs[-1]\n",
    "            new_states = successive_states[-1]\n",
    "            outputs = tf.stack(successive_outputs)\n",
    "\n",
    "    else:\n",
    "        if go_backwards:\n",
    "            inputs = reverse(inputs, 0)\n",
    "\n",
    "        states = tuple(initial_states)\n",
    "\n",
    "        time_steps = tf.shape(inputs)[0]\n",
    "        outputs, _ = step_function(inputs[0], initial_states + constants)\n",
    "        output_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=outputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='output_ta')\n",
    "        input_ta = tensor_array_ops.TensorArray(\n",
    "            dtype=inputs.dtype,\n",
    "            size=time_steps,\n",
    "            tensor_array_name='input_ta')\n",
    "        input_ta = input_ta.unstack(inputs)\n",
    "        time = tf.constant(0, dtype='int32', name='time')\n",
    "\n",
    "        if mask is not None:\n",
    "            if not states:\n",
    "                raise ValueError('No initial states provided! '\n",
    "                                 'When using masking in an RNN, you should '\n",
    "                                 'provide initial states '\n",
    "                                 '(and your step function should return '\n",
    "                                 'as its first state at time `t` '\n",
    "                                 'the output at time `t-1`).')\n",
    "            if go_backwards:\n",
    "                mask = reverse(mask, 0)\n",
    "\n",
    "            mask_ta = tensor_array_ops.TensorArray(\n",
    "                dtype=tf.bool,\n",
    "                size=time_steps,\n",
    "                tensor_array_name='mask_ta')\n",
    "            mask_ta = mask_ta.unstack(mask)\n",
    "\n",
    "            def _step(time, output_ta_t, *states):\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]\n",
    "\n",
    "\n",
    "                mask_t = mask_ta.read(time)\n",
    "                output, new_states = step_function(current_input,\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                tiled_mask_t = tf.tile(mask_t,\n",
    "                                       tf.stack([1, tf.shape(output)[1]]))\n",
    "                output = tf.where(tiled_mask_t, output, states[0])\n",
    "                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t) + tuple(new_states)\n",
    "        else:\n",
    "            def _step(time, output_ta_t, *states):\n",
    "                \"\"\"RNN step function.\n",
    "\n",
    "                # Arguments\n",
    "                    time: Current timestep value.\n",
    "                    output_ta_t: TensorArray.\n",
    "                    *states: List of states.\n",
    "\n",
    "                # Returns\n",
    "                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n",
    "                \"\"\"\n",
    "                current_input = input_ta.read(time)\n",
    "\n",
    "                # Edited Inputs\n",
    "                full_inputs = input_ta.stack()  # [:time]\n",
    "                #states = states_ta_t.stack()[:time]\n",
    "\n",
    "\n",
    "                output, new_states = step_function(current_input,\n",
    "                                                   tuple(states) +\n",
    "                                                   tuple(constants))\n",
    "                if getattr(output, '_uses_learning_phase', False):\n",
    "                    global uses_learning_phase\n",
    "                    uses_learning_phase = True\n",
    "                for state, new_state in zip(states, new_states):\n",
    "                    new_state.set_shape(state.get_shape())\n",
    "                output_ta_t = output_ta_t.write(time, output)\n",
    "                return (time + 1, output_ta_t) + tuple(new_states)\n",
    "\n",
    "        final_outputs = control_flow_ops.while_loop(\n",
    "            cond=lambda time, *_: time < time_steps,\n",
    "            body=_step,\n",
    "            loop_vars=(time, output_ta) + states,\n",
    "            parallel_iterations=32,\n",
    "            swap_memory=True)\n",
    "        last_time = final_outputs[0]\n",
    "        output_ta = final_outputs[1]\n",
    "        new_states = final_outputs[2:]\n",
    "\n",
    "        outputs = output_ta.stack()\n",
    "        last_output = output_ta.read(last_time - 1)\n",
    "\n",
    "    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n",
    "    outputs = tf.transpose(outputs, axes)\n",
    "    last_output._uses_learning_phase = uses_learning_phase\n",
    "    return last_output, outputs, new_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWrapper(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(RNNWrapper, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim])\n",
    "                    for dim in self.cell.state_size]\n",
    "        else:\n",
    "            return [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(RNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(RNNWrapper, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(RNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        #constants = K.stack(inputs)\n",
    "        constants = [inputs]\n",
    "        last_output, outputs, states = K.rnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(RNNWrapper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(RNNWrapper, self).get_losses_for(inputs)\n",
    "        return super(RNNWrapper, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = RNN(cc, return_sequences=True, return_state=False)(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4883 - mean_absolute_error: 0.4883 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.4515 - val_mean_absolute_error: 0.4515\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4717 - mean_absolute_error: 0.4717 - val_loss: 0.4276 - val_mean_absolute_error: 0.4276\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - val_loss: 0.4182 - val_mean_absolute_error: 0.4182\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4073 - val_mean_absolute_error: 0.4073\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4118 - mean_absolute_error: 0.4118 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4204 - mean_absolute_error: 0.4204 - val_loss: 0.3904 - val_mean_absolute_error: 0.3904\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4052 - mean_absolute_error: 0.4052 - val_loss: 0.3814 - val_mean_absolute_error: 0.3814\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3981 - mean_absolute_error: 0.3981 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTRNN(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(ATTRNN, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim])\n",
    "                    for dim in self.cell.state_size]\n",
    "        else:\n",
    "            return [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ATTRNN, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ATTRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        #constants = K.stack(inputs)\n",
    "        constants = [inputs]\n",
    "        last_output, outputs, states = K.rnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(ATTRNN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(ATTRNN, self).get_losses_for(inputs)\n",
    "        return super(ATTRNN, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = ATTRNNWrapper(cc, return_sequences=True, return_state=False)(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4883 - mean_absolute_error: 0.4883 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.4515 - val_mean_absolute_error: 0.4515\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4717 - mean_absolute_error: 0.4717 - val_loss: 0.4276 - val_mean_absolute_error: 0.4276\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - val_loss: 0.4182 - val_mean_absolute_error: 0.4182\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4073 - val_mean_absolute_error: 0.4073\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4118 - mean_absolute_error: 0.4118 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4204 - mean_absolute_error: 0.4204 - val_loss: 0.3904 - val_mean_absolute_error: 0.3904\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4052 - mean_absolute_error: 0.4052 - val_loss: 0.3814 - val_mean_absolute_error: 0.3814\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3981 - mean_absolute_error: 0.3981 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTRNN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTRNNWrapper(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 **kwargs):\n",
    "        if isinstance(cell, (list, tuple)):\n",
    "            cell = StackedRNNCells(cell)\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. '\n",
    "                             'The RNN was passed:', cell)\n",
    "        if not hasattr(cell, 'state_size'):\n",
    "            raise ValueError('The RNN cell should have '\n",
    "                             'an attribute `state_size` '\n",
    "                             '(tuple of integers, '\n",
    "                             'one integer per RNN state).')\n",
    "        super(ATTRNNWrapper, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.state_spec = None\n",
    "        self._states = None\n",
    "        self.constants_spec = None\n",
    "        self._num_constants = None\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        if self._states is None:\n",
    "            if isinstance(self.cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.cell.state_size)\n",
    "            return [None for _ in range(num_states)]\n",
    "        return self._states\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self._states = states\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            output_dim = self.cell.state_size\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        output_mask = mask if self.return_sequences else None\n",
    "        if self.return_state:\n",
    "            state_mask = [None for _ in self.states]\n",
    "            return [output_mask] + state_mask\n",
    "        else:\n",
    "            return output_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Note input_shape will be list of shapes of initial states and\n",
    "        # constants if these are passed in __call__.\n",
    "        if self._num_constants is not None:\n",
    "            constants_shape = input_shape[-self._num_constants:]\n",
    "        else:\n",
    "            constants_shape = None\n",
    "\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        input_dim = input_shape[-1]\n",
    "        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n",
    "\n",
    "        # allow cell (if layer) to build before we set or validate state_spec\n",
    "        if isinstance(self.cell, Layer):\n",
    "            step_input_shape = (input_shape[0],) + input_shape[2:]\n",
    "            if constants_shape is not None:\n",
    "                self.cell.build([step_input_shape] + constants_shape)\n",
    "            else:\n",
    "                self.cell.build(step_input_shape)\n",
    "\n",
    "        # set or validate state_spec\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = list(self.cell.state_size)\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "\n",
    "        if self.state_spec is not None:\n",
    "            # initial_state was passed in call, check compatibility\n",
    "            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n",
    "                raise ValueError(\n",
    "                    'An initial_state was passed that is not compatible with '\n",
    "                    '`cell.state_size`. Received `state_spec`={}; '\n",
    "                    'However `cell.state_size` is '\n",
    "                    '{}'.format(self.state_spec, self.cell.state_size))\n",
    "        else:\n",
    "            self.state_spec = [InputSpec(shape=(None, dim))\n",
    "                               for dim in state_size]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim])\n",
    "                    for dim in self.cell.state_size]\n",
    "        else:\n",
    "            return [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        inputs, initial_state, constants = self._standardize_args(\n",
    "            inputs, initial_state, constants)\n",
    "\n",
    "        if initial_state is None and constants is None:\n",
    "            return super(ATTRNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "        # If any of `initial_state` or `constants` are specified and are Keras\n",
    "        # tensors, then add them to the inputs and temporarily modify the\n",
    "        # input_spec to include them.\n",
    "\n",
    "        additional_inputs = []\n",
    "        additional_specs = []\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "            additional_inputs += initial_state\n",
    "            self.state_spec = [InputSpec(shape=K.int_shape(state))\n",
    "                               for state in initial_state]\n",
    "            additional_specs += self.state_spec\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            additional_inputs += constants\n",
    "            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n",
    "                                   for constant in constants]\n",
    "            self._num_constants = len(constants)\n",
    "            additional_specs += self.constants_spec\n",
    "        # at this point additional_inputs cannot be empty\n",
    "        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n",
    "        for tensor in additional_inputs:\n",
    "            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n",
    "                raise ValueError('The initial state or constants of an RNN'\n",
    "                                 ' layer cannot be specified with a mix of'\n",
    "                                 ' Keras tensors and non-Keras tensors')\n",
    "\n",
    "        if is_keras_tensor:\n",
    "            # Compute the full input spec, including state and constants\n",
    "            full_input = [inputs] + additional_inputs\n",
    "            full_input_spec = self.input_spec + additional_specs\n",
    "            # Perform the call with temporarily replaced input_spec\n",
    "            original_input_spec = self.input_spec\n",
    "            self.input_spec = full_input_spec\n",
    "            output = super(ATTRNNWrapper, self).__call__(full_input, **kwargs)\n",
    "            self.input_spec = original_input_spec\n",
    "            return output\n",
    "        else:\n",
    "            return super(ATTRNNWrapper, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def get_attention(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def call(self,\n",
    "             inputs,\n",
    "             mask=None,\n",
    "             training=None,\n",
    "             initial_state=None,\n",
    "             constants=None):\n",
    "\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        if initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_state = self.states\n",
    "        else:\n",
    "            initial_state = self.get_initial_state(inputs)\n",
    "\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "\n",
    "        if len(initial_state) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_state)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "        if self.unroll and timesteps in [None, 1]:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined or equal to 1. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "\n",
    "        kwargs = {}\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            kwargs['training'] = training\n",
    "\n",
    "        if constants:\n",
    "            if not has_arg(self.cell.call, 'constants'):\n",
    "                raise ValueError('RNN cell does not support constants')\n",
    "\n",
    "            def step(inputs, states):\n",
    "                constants = states[-self._num_constants:]\n",
    "                states = states[:-self._num_constants]\n",
    "                return self.cell.call(inputs, states, constants=constants,\n",
    "                                      **kwargs)\n",
    "        else:\n",
    "            def step(inputs, states):\n",
    "                return self.cell.call(inputs, states, **kwargs)\n",
    "\n",
    "        #constants = K.stack(inputs)\n",
    "        constants = [inputs]\n",
    "        last_output, outputs, states = K.rnn(step,\n",
    "                                             inputs,\n",
    "                                             initial_state,\n",
    "                                             constants=constants,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             mask=mask,\n",
    "                                             unroll=self.unroll,\n",
    "                                             input_length=timesteps)\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output = outputs\n",
    "        else:\n",
    "            output = last_output\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if getattr(last_output, '_uses_learning_phase', False):\n",
    "            output._uses_learning_phase = True\n",
    "\n",
    "        if self.return_state:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            else:\n",
    "                states = list(states)\n",
    "            return [output] + states\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def _standardize_args(self, inputs, initial_state, constants):\n",
    "        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n",
    "        standard format.\n",
    "\n",
    "        When running a model loaded from file, the input tensors\n",
    "        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n",
    "        of `inputs` instead of by the dedicated keyword arguments. This method\n",
    "        makes sure the arguments are separated and that `initial_state` and\n",
    "        `constants` are lists of tensors (or None).\n",
    "\n",
    "        # Arguments\n",
    "            inputs: tensor or list/tuple of tensors\n",
    "            initial_state: tensor or list of tensors or None\n",
    "            constants: tensor or list of tensors or None\n",
    "\n",
    "        # Returns\n",
    "            inputs: tensor\n",
    "            initial_state: list of tensors or None\n",
    "            constants: list of tensors or None\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            assert initial_state is None and constants is None\n",
    "            if self._num_constants is not None:\n",
    "                constants = inputs[-self._num_constants:]\n",
    "                inputs = inputs[:-self._num_constants]\n",
    "            if len(inputs) > 1:\n",
    "                initial_state = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        def to_list_or_none(x):\n",
    "            if x is None or isinstance(x, list):\n",
    "                return x\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            return [x]\n",
    "\n",
    "        initial_state = to_list_or_none(initial_state)\n",
    "        constants = to_list_or_none(constants)\n",
    "\n",
    "        return inputs, initial_state, constants\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        batch_size = self.input_spec[0].shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a RNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "        # initialize state if None\n",
    "        if self.states[0] is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                self.states = [K.zeros((batch_size, dim))\n",
    "                               for dim in self.cell.state_size]\n",
    "            else:\n",
    "                self.states = [K.zeros((batch_size, self.cell.state_size))]\n",
    "        elif states is None:\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                for state, dim in zip(self.states, self.cell.state_size):\n",
    "                    K.set_value(state, np.zeros((batch_size, dim)))\n",
    "            else:\n",
    "                K.set_value(self.states[0],\n",
    "                            np.zeros((batch_size, self.cell.state_size)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 ' state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if hasattr(self.cell.state_size, '__len__'):\n",
    "                    dim = self.cell.state_size[index]\n",
    "                else:\n",
    "                    dim = self.cell.state_size\n",
    "                if value.shape != (batch_size, dim):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, dim)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                # TODO: consider batch calls to `set_value`.\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences,\n",
    "                  'return_state': self.return_state,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(ATTRNNWrapper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        from . import deserialize as deserialize_layer\n",
    "        cell = deserialize_layer(config.pop('cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.losses\n",
    "        return []\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_losses = self.cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(ATTRNNWrapper, self).get_losses_for(inputs)\n",
    "        return super(ATTRNNWrapper, self).get_losses_for(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 3, 2)              16        \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aa = Input(shape=(3, 2), dtype='float32')\n",
    "bb = SimpleRNNCell(2)\n",
    "cc = CellWrapper(bb)\n",
    "dd = ATTRNNWrapper(LSTM(cc, return_sequences=True, return_state=False))(aa)\n",
    "ee = Model(inputs=aa, outputs=dd)\n",
    "ee.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "ee.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4883 - mean_absolute_error: 0.4883 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.4515 - val_mean_absolute_error: 0.4515\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4717 - mean_absolute_error: 0.4717 - val_loss: 0.4276 - val_mean_absolute_error: 0.4276\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - val_loss: 0.4182 - val_mean_absolute_error: 0.4182\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4073 - val_mean_absolute_error: 0.4073\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4118 - mean_absolute_error: 0.4118 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4204 - mean_absolute_error: 0.4204 - val_loss: 0.3904 - val_mean_absolute_error: 0.3904\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4052 - mean_absolute_error: 0.4052 - val_loss: 0.3814 - val_mean_absolute_error: 0.3814\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3981 - mean_absolute_error: 0.3981 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "model = ee\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06655514,  0.20870832],\n",
      "       [-0.62020373, -0.92057413]], dtype=float32),\n",
      "                   array([[-0.87163007,  0.17475815],\n",
      "       [ 0.16320671,  0.86440241]], dtype=float32),\n",
      "                   array([-0.09910914,  0.12928225], dtype=float32),\n",
      "                   array([[ 0.88622832,  0.0257951 ],\n",
      "       [-0.1858207 , -0.63723952]], dtype=float32),\n",
      "                   array([ 0.29415649,  1.09380114], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                 array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                 array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                 array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                 array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'begin_input_11': []},\n",
      "  {'begin_rnn_3': [array([[ 1.06612265,  0.20919719],\n",
      "       [-0.62004465, -0.9200052 ]], dtype=float32),\n",
      "                   array([[-0.87126297,  0.17480175],\n",
      "       [ 0.16317376,  0.8641423 ]], dtype=float32),\n",
      "                   array([-0.09923106,  0.12970468], dtype=float32),\n",
      "                   array([[ 0.88611281,  0.02598154],\n",
      "       [-0.18512374, -0.63658291]], dtype=float32),\n",
      "                   array([ 0.29480287,  1.09283495], dtype=float32)]}],\n",
      " [{'end_input_11': []},\n",
      "  {'end_rnn_3': [array([[ 1.06578982,  0.20963489],\n",
      "       [-0.61976725, -0.91948909]], dtype=float32),\n",
      "                 array([[-0.87097979,  0.17485771],\n",
      "       [ 0.16299176,  0.86390406]], dtype=float32),\n",
      "                 array([-0.09920839,  0.13006558], dtype=float32),\n",
      "                 array([[ 0.88609421,  0.02623362],\n",
      "       [-0.18438773, -0.63590556]], dtype=float32),\n",
      "                 array([ 0.2954461 ,  1.09184504], dtype=float32)]}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(history.weights[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# GRU Decoder with Attention (encoder: `return_sequence=True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_many_to_many_1'](lstm_many_to_many_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['lstm_attention'](rnn_with_att.jpg)\n",
    "!['Overview of the Attention mechanism in an Encoder-Decoder setup'](lstm_attention_3.png)\n",
    "!['detail_lstm_attention'](detail_attentionmodel1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Attention Structure 1](https://blog.heuritech.com/2016/01/20/attention-mechanism/)  \n",
    "[Attention Structure 2](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)  \n",
    "[Attention Structure 3](https://medium.com/datalogue/attention-in-keras-1892773a4f22)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Embedding`:  \n",
    "> `(nb_words, vocab_size) x (vocab_size, embedding_dim) = (nb_words, embedding_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyGRUAttention (Feed-Forward, Not Recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import _object_list_uid\n",
    "from keras.utils.generic_utils import has_arg\n",
    "\n",
    "# Legacy support.\n",
    "from keras.legacy.layers import Recurrent\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from keras.layers import RNN, GRUCell, GRU, SimpleRNNCell\n",
    "#from keras.layers.recurrent import (_generate_dropout_ones,\n",
    "#                                    _generate_dropout_mask)\n",
    "\n",
    "\n",
    "def _generate_dropout_ones(inputs, dims):\n",
    "    # Currently, CTNK can't instantiate `ones` with symbolic shapes.\n",
    "    # Will update workaround once CTNK supports it.\n",
    "    if K.backend() == 'cntk':\n",
    "        ones = K.ones_like(K.reshape(inputs[:, 0], (-1, 1)))\n",
    "        return K.tile(ones, (1, dims))\n",
    "    else:\n",
    "        return K.ones((K.shape(inputs)[0], dims))\n",
    "\n",
    "\n",
    "def _generate_dropout_mask(ones, rate, training=None, count=1):\n",
    "    def dropped_inputs():\n",
    "        return K.dropout(ones, rate)\n",
    "\n",
    "    if count > 1:\n",
    "        return [K.in_train_phase(\n",
    "            dropped_inputs,\n",
    "            ones,\n",
    "            training=training) for _ in range(count)]\n",
    "    return K.in_train_phase(\n",
    "        dropped_inputs,\n",
    "        ones,\n",
    "        training=training)\n",
    "\n",
    "\n",
    "class GRUAttentionCell(GRUCell):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.state_size = self.units :for RNN, GRU\n",
    "        #self.state_size = (self.units, self.units) : for LSTM\n",
    "        #self.attn_length = 79\n",
    "        #self.attn_size = 79\n",
    "        #self.attn_vec_size = self.attn_size\n",
    "        #self.input_size = None\n",
    "        self.state_size = (self.units, 79*self.units)\n",
    "        #self.state_size = (self.units, self.units)\n",
    "        self.full_inputs = None\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print('cell.build Shape:', input_shape)\n",
    "        #self.timesteps = input_shape[1]\n",
    "        input_dim = input_shape[-1]\n",
    "        self.states = [None, None]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n",
    "                                      name='kernel',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units * 4),\n",
    "            name='recurrent_kernel',\n",
    "            initializer=self.recurrent_initializer,\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.context_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.units * 3),\n",
    "            name='context_kernel',\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units * 4,),\n",
    "                                        name='bias',\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.kernel_z = self.kernel[:,               : self.units * 1]\n",
    "        self.kernel_r = self.kernel[:, self.units * 1: self.units * 2]\n",
    "        self.kernel_h = self.kernel[:, self.units * 2: self.units * 3]\n",
    "        self.kernel_c = self.kernel[:, self.units * 3:]\n",
    "\n",
    "        self.recurrent_kernel_z = self.recurrent_kernel[:,               : self.units * 1]\n",
    "        self.recurrent_kernel_r = self.recurrent_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n",
    "        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 3:]\n",
    "\n",
    "        self.context_kernel_z = self.context_kernel[:,               : self.units * 1]\n",
    "        self.context_kernel_r = self.context_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.context_kernel_h = self.context_kernel[:, self.units * 2:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_z = self.bias[              : self.units * 1]\n",
    "            self.bias_r = self.bias[self.units * 1: self.units * 2]\n",
    "            self.bias_h = self.bias[self.units * 2: self.units * 3]\n",
    "            self.bias_c = self.bias[self.units * 3:]\n",
    "        else:\n",
    "            self.bias_z = None\n",
    "            self.bias_r = None\n",
    "            self.bias_h = None\n",
    "            self.bias_c = None\n",
    "        self.built = True\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameter Shapes\n",
    "        kernel : (input_dim, units)\n",
    "        recurrent_kernel : (units, units)\n",
    "        bias : (units, )\n",
    "\n",
    "        # Inherited Parameters\n",
    "        kernel : z, r, h\n",
    "        recurrent_kernel : z, r, h\n",
    "        bias : z, r, h\n",
    "\n",
    "        # New Parameters\n",
    "        input_dim\n",
    "        kernel_c\n",
    "        recurrent_kernel_c\n",
    "        bias_c\n",
    "        \"\"\"\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        if self.full_inputs is None:\n",
    "            self.full_inputs = states[-1]\n",
    "        full_inputs = self.full_inputs\n",
    "        timesteps = K.int_shape(full_inputs)[1]\n",
    "        print('cell.call Input Shape:', K.int_shape(inputs),\n",
    "              'Full State len:', len(states),\n",
    "              'State Shape:', K.int_shape(states[0]),\n",
    "              'Full h Shape:', K.int_shape(states[-1]))\n",
    "\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
    "                self.dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, self.units),\n",
    "                self.recurrent_dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        if self.implementation == 1:\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs_z = inputs * dp_mask[0]\n",
    "                inputs_r = inputs * dp_mask[1]\n",
    "                inputs_h = inputs * dp_mask[2]\n",
    "                inputs_c = inputs * dp_mask[3]\n",
    "            else:\n",
    "                inputs_z = inputs\n",
    "                inputs_r = inputs\n",
    "                inputs_h = inputs\n",
    "                inputs_c = inputs\n",
    "            x_z = K.dot(inputs_z, self.kernel_z)\n",
    "            x_r = K.dot(inputs_r, self.kernel_r)\n",
    "            x_h = K.dot(inputs_h, self.kernel_h)\n",
    "            x_c = K.dot(inputs_c, self.kernel_c)\n",
    "            if self.use_bias:\n",
    "                x_z = K.bias_add(x_z, self.bias_z)\n",
    "                x_r = K.bias_add(x_r, self.bias_r)\n",
    "                x_h = K.bias_add(x_h, self.bias_h)\n",
    "                x_c = K.bias_add(x_c, self.bias_c)\n",
    "\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1_z = h_tm1 * rec_dp_mask[0]\n",
    "                h_tm1_r = h_tm1 * rec_dp_mask[1]\n",
    "                h_tm1_h = h_tm1 * rec_dp_mask[2]\n",
    "                h_tm1_c = h_tm1 * rec_dp_mask[3]\n",
    "            else:\n",
    "                h_tm1_z = h_tm1\n",
    "                h_tm1_r = h_tm1\n",
    "                h_tm1_h = h_tm1\n",
    "                h_tm1_c = h_tm1\n",
    "\n",
    "            # calculate the context vector\n",
    "            #context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "\n",
    "            # Attention Context Part\n",
    "            h_tm1_c = K.repeat(h_tm1_c, timesteps)\n",
    "            #h_tm1_c = full_inputs\n",
    "            print('h:', K.int_shape(full_inputs), 's0:', K.int_shape(h_tm1_c))\n",
    "            e = self.activation(h_tm1_c + K.dot(full_inputs, self.recurrent_kernel_c))\n",
    "            a = K.softmax(e)\n",
    "            print('A:', K.int_shape(a), 'inputs_c:', K.int_shape(inputs_c), 'full input:', K.int_shape(full_inputs))\n",
    "            c_t = K.sum(a * full_inputs, axis=1, keepdims=False)\n",
    "            #c_t = K.batch_dot(a, inputs_c, axes=1)\n",
    "\n",
    "            print('Done c_t:', K.int_shape(c_t))\n",
    "            print('Done context_kernel:', K.int_shape(self.context_kernel_z))\n",
    "            print('Done recurrent_kernel:', self.recurrent_kernel_z)\n",
    "            print('Done h_tm_z * rec:', K.dot(h_tm1_z, self.recurrent_kernel_z))\n",
    "            \n",
    "            # GRU Part\n",
    "            z = self.recurrent_activation(x_z +\n",
    "                                          K.dot(h_tm1_z,\n",
    "                                                self.recurrent_kernel_z) +\n",
    "                                          K.dot(c_t, self.context_kernel_z))\n",
    "            r = self.recurrent_activation(x_r +\n",
    "                                          K.dot(h_tm1_r,\n",
    "                                                self.recurrent_kernel_r) +\n",
    "                                          K.dot(c_t, self.context_kernel_r))\n",
    "\n",
    "            hh = self.activation(x_h +\n",
    "                                 K.dot(r * h_tm1_h,\n",
    "                                       self.recurrent_kernel_h) +\n",
    "                                 K.dot(c_t, self.context_kernel_h))\n",
    "\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs *= dp_mask[0]\n",
    "            matrix_x = K.dot(inputs, self.kernel)\n",
    "            if self.use_bias:\n",
    "                matrix_x = K.bias_add(matrix_x, self.bias)\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1 *= rec_dp_mask[0]\n",
    "            matrix_inner = K.dot(h_tm1,\n",
    "                                 self.recurrent_kernel[:, :2 * self.units])\n",
    "\n",
    "            x_z = matrix_x[:, :self.units]\n",
    "            x_r = matrix_x[:, self.units: 2 * self.units]\n",
    "            recurrent_z = matrix_inner[:, :self.units]\n",
    "            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n",
    "\n",
    "            z = self.recurrent_activation(x_z + recurrent_z)\n",
    "            r = self.recurrent_activation(x_r + recurrent_r)\n",
    "\n",
    "            x_h = matrix_x[:, 2 * self.units:]\n",
    "            recurrent_h = K.dot(r * h_tm1,\n",
    "                                self.recurrent_kernel[:, 2 * self.units:])\n",
    "            hh = self.activation(x_h + recurrent_h)\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                h._uses_learning_phase = True\n",
    "                \n",
    "        print(K.int_shape(states[-1]))\n",
    "        states = [h] + [states[-1]]\n",
    "        return h, [h, self.full_inputs]\n",
    "\n",
    "\n",
    "class MyRNNAttention(RNN):\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state = [K.tile(initial_state, [1, dim])\n",
    "                     for dim in self.cell.state_size[:-1]]\n",
    "        else:\n",
    "            state = [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "        full_inputs = [inputs]\n",
    "        return state + full_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: [(None, 80), (None, 79, 80)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"int\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-74594e56f235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mGRUAttention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyRNNAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mstep_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconstants_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f19f6a0e6532>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                       \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         self.recurrent_kernel = self.add_weight(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    398\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mscale\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "GRUAttention = MyRNNAttention(GRUAttentionCell(ndimY), return_sequences=True)\n",
    "dec = GRUAttention(enc, constants=enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MinimalRNNCell(Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        #self.state_size = units\n",
    "        self.state_size = (units, units * 79)\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-456-aa30eef606a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinimalRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36minput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \"\"\"\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[1;32m   1029\u001b[0m                                  'and thus has no defined input shape.')\n\u001b[1;32m   1030\u001b[0m         \u001b[0mall_input_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "a = MinimalRNNCell(ndimY)\n",
    "a.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An initial_state was passed that is not compatible with `cell.state_size`. Received `state_spec`=[<keras.engine.topology.InputSpec object at 0x7f70d9075a90>]; However `cell.state_size` is (110, 8690)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-453-bee2953dda3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Cel = MinimalRNNCell(ndimY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMinimalRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0;34m'`cell.state_size`. Received `state_spec`={}; '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0;34m'However `cell.state_size` is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                     '{}'.format(self.state_spec, self.cell.state_size))\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             self.state_spec = [InputSpec(shape=(None, dim))\n",
      "\u001b[0;31mValueError\u001b[0m: An initial_state was passed that is not compatible with `cell.state_size`. Received `state_spec`=[<keras.engine.topology.InputSpec object at 0x7f70d9075a90>]; However `cell.state_size` is (110, 8690)"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "#Cel = MinimalRNNCell(ndimY)\n",
    "dec = RNN(MinimalRNNCell(ndimY), return_sequences=True)(enc, enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class CellWrapper(Layer):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(**kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self._cell.output_shape\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self._cell.weights, self.weights]\n",
    "\n",
    "    def get_weights(self):\n",
    "        return [self._cell.get_weights(), self.get_weights()]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        \n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: (None, 80)\n",
      "cell.call Input Shape: (None, 80) Full State len: 2 State Shape: (None, 80) Full h Shape: (None, 6320)\n",
      "h: (None, 6320) s0: (None, 6320, 80)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-0e340b8850aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mCel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    587\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2563\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m<ipython-input-435-f19f6a0e6532>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m#h_tm1_c = full_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's0:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs_c:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_26/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80]."
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "Cel = GRUAttentionCell(ndimX)\n",
    "dec = RNN(Cel, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CellWrapper(Layer):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(**kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def units(self):\n",
    "        return self._cell.units\n",
    "\n",
    "    @property\n",
    "    def activation(self):\n",
    "        return self._cell.activation\n",
    "\n",
    "    @property\n",
    "    def use_bias(self):\n",
    "        return self._cell.use_bias\n",
    "\n",
    "    @property\n",
    "    def kernel_initializer(self):\n",
    "        return self._cell.kernel_initializer\n",
    "\n",
    "    @property\n",
    "    def recurrent_initializer(self):\n",
    "        return self._cell.recurrent_initializer\n",
    "\n",
    "    @property\n",
    "    def bias_initializer(self):\n",
    "        return self._cell.bias_initializer\n",
    "\n",
    "    @property\n",
    "    def kernel_regularizer(self):\n",
    "        return self._cell.kernel_regularizer\n",
    "\n",
    "    @property\n",
    "    def recurrent_regularizer(self):\n",
    "        return self._cell.recurrent_regularizer\n",
    "\n",
    "    @property\n",
    "    def bias_regularizer(self):\n",
    "        return self._cell.bias_regularizer\n",
    "\n",
    "    @property\n",
    "    def kernel_constraint(self):\n",
    "        return self._cell.kernel_constraint\n",
    "\n",
    "    @property\n",
    "    def recurrent_constraint(self):\n",
    "        return self._cell.recurrent_constraint\n",
    "\n",
    "    @property\n",
    "    def bias_constraint(self):\n",
    "        return self._cell.bias_constraint\n",
    "\n",
    "    @property\n",
    "    def dropout(self):\n",
    "        return self._cell.dropout\n",
    "\n",
    "    @property\n",
    "    def recurrent_dropout(self):\n",
    "        return self._cell.recurrent_dropout\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self._cell.output_shape\n",
    "\n",
    "    @property\n",
    "    def implementation(self):\n",
    "        return self.cell.implementation\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        inner_weights = self._cell.weights\n",
    "        wrapper_weights = super(CellWrapper, self).weights\n",
    "        return [inner_weights, inner_weights]\n",
    "\n",
    "    def get_weights(self):\n",
    "        return [self._cell.get_weights(), super(CellWrapper, self).get_weights()]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        \n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class CellWrapper(SimpleRNNCell):\n",
    "    def __init__(self, cell, *args, **kwargs):\n",
    "        self._cell = cell\n",
    "        super(CellWrapper, self).__init__(cell.units, **kwargs)\n",
    "        #self._cell.__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._cell.build(input_shape)\n",
    "        if self.built is None:\n",
    "            self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        cell_output, new_state = self._cell.call(inputs, states, training=None)\n",
    "\n",
    "        output = cell_output\n",
    "        state = new_state\n",
    "        \n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine import Layer\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import has_arg\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "\n",
    "\n",
    "class _RNNAttentionCell(Layer):\n",
    "    \"\"\"Base class for recurrent attention mechanisms.\n",
    "\n",
    "    This base class implements the RNN cell interface and defines a standard\n",
    "    way for attention mechanisms to interact with a (wrapped) \"core\" RNN cell\n",
    "    (such as the `SimpleRNNCell`, `GRUCell` or `LSTMCell`).\n",
    "\n",
    "    The main idea is that the attention mechanism, implemented by\n",
    "    `attention_call` in extensions of this class, computes an \"attention\n",
    "    encoding\", based on the attended input as well as the input and the core\n",
    "    cell state(s) at the current time step, which will be used as modified\n",
    "    input for the core cell.\n",
    "\n",
    "    # Arguments\n",
    "        cell: A RNN cell instance. The cell to wrap by the attention mechanism.\n",
    "            A RNN cell is a class that has:\n",
    "            - a `call(input_at_t, states_at_t)` method, returning\n",
    "                `(output_at_t, states_at_t_plus_1)`.\n",
    "            - a `state_size` attribute. This can be a single integer\n",
    "                (single state) in which case it is the size of the recurrent\n",
    "                state (which should be the same as the size of the cell\n",
    "                output). This can also be a list/tuple of integers (one size\n",
    "                per state). In this case, the first entry (`state_size[0]`)\n",
    "                should be the same as the size of the cell output.\n",
    "        attend_after: Boolean (default False). If True, the attention\n",
    "            transformation defined by `attention_call` will be applied after\n",
    "            the core cell transformation (and the attention encoding will be\n",
    "            used as input for core cell transformation next time step).\n",
    "        concatenate_input: Boolean (default True). If True the concatenation of\n",
    "            the attention encoding and the original input will be used as input\n",
    "            for the core cell transformation. If set to False, only the\n",
    "            attention encoding will be used as input for the core cell\n",
    "            transformation.\n",
    "\n",
    "    # Abstract Methods and Properties\n",
    "        Extension of this class must implement:\n",
    "            - `attention_build` (method): Builds the attention transformation\n",
    "              based on input shapes.\n",
    "            - `attention_call` (method): Defines the attention transformation\n",
    "              returning the attention encoding.\n",
    "            - `attention_size` (property): After `attention_build` has been\n",
    "              called, this property should return the size (int) of the\n",
    "              attention encoding. Do this by setting `_attention_size` in scope\n",
    "              of `attention_build` or by implementing `attention_size`\n",
    "              property.\n",
    "        Extension of this class can optionally implement:\n",
    "            - `attention_state_size` (property): Default [`attention_size`].\n",
    "              If the attention mechanism has it own internal states (besides\n",
    "              the attention encoding which is by default the only part of\n",
    "              `attention_states`) override this property accordingly.\n",
    "        See docs of the respective method/property for further details.\n",
    "\n",
    "    # Details of interaction between attention and cell transformations\n",
    "        Let \"cell\" denote core (wrapped) RNN cell and \"att(cell)\" the complete\n",
    "        attentive RNN cell defined by this class. We write the core cell\n",
    "        transformation as:\n",
    "\n",
    "            y{t}, s_cell{t+1} = cell.call(x{t}, s_cell{t})\n",
    "\n",
    "        where y{t} denotes the output, x{t} the input at and s_cell{t} the core\n",
    "        cell state(s) at time t and s_cell{t+1} the updated state(s).\n",
    "\n",
    "        We can then write the complete \"attentive\" cell transformation as:\n",
    "\n",
    "            y{t}, s_att(cell){t+1} = att(cell).call(x{t}, s_att(cell){t},\n",
    "                                                    constants=attended)\n",
    "\n",
    "        where s_att(cell) denotes the complete states of the attentive cell,\n",
    "        which consists of the core cell state(s) followed but the attention\n",
    "        state(s), and attended denotes the tensor attended to (note: no time\n",
    "        indexing as this is the same constant input at each time step).\n",
    "\n",
    "        Internally, this is how the attention transformation, implemented by\n",
    "        `attention_call`, interacts with the core cell transformation\n",
    "        `cell.call`:\n",
    "\n",
    "        - with `attend_after=False` (default):\n",
    "            a{t}, s_att{t+1} = att(cell).attention_call(x_t, s_cell{t},\n",
    "                                                        attended, s_att{t})\n",
    "            with `concatenate_input=True` (default):\n",
    "                x'{t} = [x{t}, a{t}]\n",
    "            else:\n",
    "                x'{t} = a{t}\n",
    "            y{t}, s_cell{t+1} = cell.call(x'{t}, s_cell{t})\n",
    "\n",
    "        - with `attend_after=True`:\n",
    "            with `concatenate_input=True` (default):\n",
    "                x'{t} = [x{t}, a{t-1}]\n",
    "            else:\n",
    "                x'{t} = a{t-1}\n",
    "            y{t}, s_cell{t+1} = cell.call(x'{t}, s_cell{t})\n",
    "            a{t}, s_att{t+1} = att(cell).attention_call(x_t, s_cell{t+1},\n",
    "                                                        attended, s_att{t})\n",
    "\n",
    "        where a{t} denotes the attention encoding, s_att{t} the attention\n",
    "        state(s), x'{t} the modified core cell input and [x{.}, a{.}] the\n",
    "        (tensor) concatenation of the input and attention encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell,\n",
    "                 attend_after=False,\n",
    "                 concatenate_input=False,\n",
    "                 **kwargs):\n",
    "        self.cell = cell  # must be set before calling super\n",
    "        super(_RNNAttentionCell, self).__init__(**kwargs)\n",
    "        self.attend_after = attend_after\n",
    "        self.concatenate_input = concatenate_input\n",
    "        self.attended_spec = None\n",
    "        self._attention_size = None\n",
    "\n",
    "    def attention_call(self,\n",
    "                       inputs,\n",
    "                       cell_states,\n",
    "                       attended,\n",
    "                       attention_states,\n",
    "                       training=None):\n",
    "        \"\"\"The main logic for computing the attention encoding.\n",
    "\n",
    "        # Arguments\n",
    "            inputs: The input at current time step.\n",
    "            cell_states: States for the core RNN cell.\n",
    "            attended: The same tensor(s) to attend at each time step.\n",
    "            attention_states: States dedicated for the attention mechanism.\n",
    "            training: whether run in training mode or not\n",
    "\n",
    "        # Returns\n",
    "            attention_h: The computed attention encoding at current time step.\n",
    "            attention_states: States to be passed to next `attention_call`. By\n",
    "                default this should be [`attention_h`].\n",
    "                NOTE: if additional states are used, these should be appended\n",
    "                after `attention_h`, i.e. `attention_states[0]` should always\n",
    "                be `attention_h`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`attention_call` must be implemented by extensions of `{}`'.format(\n",
    "                self.__class__.__name__))\n",
    "\n",
    "    def attention_build(self, input_shape, cell_state_size, attended_shape):\n",
    "        \"\"\"Build the attention mechanism.\n",
    "\n",
    "        NOTE: `self._attention_size` should be set in this method to the size\n",
    "        of the attention encoding (i.e. size of first `attention_states`)\n",
    "        unless `attention_size` property is implemented in another way.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of integers. Shape of the input at a single time\n",
    "                step.\n",
    "            cell_state_size: List of tuple of integers.\n",
    "            attended_shape: List of tuple of integers.\n",
    "\n",
    "            NOTE: both `cell_state_size` and `attended_shape` will always be\n",
    "            lists - for simplicity. For example: even if (wrapped)\n",
    "            `cell.state_size` is an integer, `cell_state_size` will be a list\n",
    "            of this one element.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`attention_build` must be implemented by extensions of `{}`'.format(\n",
    "                self.__class__.__name__))\n",
    "\n",
    "    @property\n",
    "    def attention_size(self):\n",
    "        \"\"\"Size off attention encoding, an integer.\n",
    "        \"\"\"\n",
    "        if self._attention_size is None and self.built:\n",
    "            raise NotImplementedError(\n",
    "                'extensions of `{}` must either set property `_attention_size`'\n",
    "                ' in `attention_build` or implement the or implement'\n",
    "                ' `attention_size` in some other way'.format(\n",
    "                    self.__class__.__name__))\n",
    "\n",
    "        return self._attention_size\n",
    "\n",
    "    @property\n",
    "    def attention_state_size(self):\n",
    "        \"\"\"Size of attention states, defaults to `attention_size`, an integer.\n",
    "\n",
    "        Modify this property to return list of integers if the attention\n",
    "        mechanism has several internal states. Note that the first size should\n",
    "        always be the size of the attention encoding, i.e.:\n",
    "            `attention_state_size[0]` = `attention_size`\n",
    "        \"\"\"\n",
    "        return self.attention_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        \"\"\"Size of states of the complete attentive cell, a tuple of integers.\n",
    "\n",
    "        The attentive cell's states consists of the core RNN cell state size(s)\n",
    "        followed by attention state size(s). NOTE it is important that the core\n",
    "        cell states are first as the first state of any RNN cell should be same\n",
    "        as the cell's output.\n",
    "        \"\"\"\n",
    "        state_size_s = []\n",
    "        for state_size in [self.cell.state_size, self.attention_state_size]:\n",
    "            if hasattr(state_size, '__len__'):\n",
    "                state_size_s += list(state_size)\n",
    "            else:\n",
    "                state_size_s.append(state_size)\n",
    "\n",
    "        return tuple(state_size_s)\n",
    "\n",
    "    def call(self, inputs, states, constants, training=None):\n",
    "        \"\"\"Complete attentive cell transformation.\n",
    "        \"\"\"\n",
    "        attended = constants\n",
    "        cell_states = states[:self._num_wrapped_states]\n",
    "        attention_states = states[self._num_wrapped_states:]\n",
    "\n",
    "        if self.attend_after:\n",
    "            attention_call = self.call_attend_after\n",
    "        else:\n",
    "            attention_call = self.call_attend_before\n",
    "\n",
    "        return attention_call(inputs=inputs,\n",
    "                              cell_states=cell_states,\n",
    "                              attended=attended,\n",
    "                              attention_states=attention_states,\n",
    "                              training=training)\n",
    "\n",
    "    def call_attend_before(self,\n",
    "                           inputs,\n",
    "                           cell_states,\n",
    "                           attended,\n",
    "                           attention_states,\n",
    "                           training=None):\n",
    "        \"\"\"Complete attentive cell transformation, if `attend_after=False`.\n",
    "        \"\"\"\n",
    "        attention_h, new_attention_states = self.attention_call(\n",
    "            inputs=inputs,\n",
    "            cell_states=cell_states,\n",
    "            attended=attended,\n",
    "            attention_states=attention_states,\n",
    "            training=training)\n",
    "\n",
    "        if self.concatenate_input:\n",
    "            cell_input = concatenate([attention_h, inputs])\n",
    "        else:\n",
    "            cell_input = attention_h\n",
    "\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states,\n",
    "                                                     training=training)\n",
    "        else:\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states)\n",
    "\n",
    "        return output, new_cell_states + new_attention_states\n",
    "\n",
    "    def call_attend_after(self,\n",
    "                          inputs,\n",
    "                          cell_states,\n",
    "                          attended,\n",
    "                          attention_states,\n",
    "                          training=None):\n",
    "        \"\"\"Complete attentive cell transformation, if `attend_after=True`.\n",
    "        \"\"\"\n",
    "        attention_h_previous = attention_states[0]\n",
    "\n",
    "        if self.concatenate_input:\n",
    "            cell_input = concatenate([attention_h_previous, inputs])\n",
    "        else:\n",
    "            cell_input = attention_h_previous\n",
    "\n",
    "        if has_arg(self.cell.call, 'training'):\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states,\n",
    "                                                     training=training)\n",
    "        else:\n",
    "            output, new_cell_states = self.cell.call(cell_input, cell_states)\n",
    "\n",
    "        attention_h, new_attention_states = self.attention_call(\n",
    "            inputs=inputs,\n",
    "            cell_states=new_cell_states,\n",
    "            attended=attended,\n",
    "            attention_states=attention_states,\n",
    "            training=training)\n",
    "\n",
    "        return output, new_cell_states, new_attention_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _num_elements(x):\n",
    "        if hasattr(x, '__len__'):\n",
    "            return len(x)\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    @property\n",
    "    def _num_wrapped_states(self):\n",
    "        return self._num_elements(self.cell.state_size)\n",
    "\n",
    "    @property\n",
    "    def _num_attention_states(self):\n",
    "        return self._num_elements(self.attention_state_size)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Builds attention mechanism and wrapped cell (if keras layer).\n",
    "\n",
    "        Arguments:\n",
    "            input_shape: list of tuples of integers, the input feature shape\n",
    "                (inputs sequence shape without time dimension) followed by\n",
    "                constants (i.e. attended) shapes.\n",
    "        \"\"\"\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('input shape should contain shape of both cell '\n",
    "                             'inputs and constants (attended)')\n",
    "\n",
    "        attended_shape = input_shape[1:]\n",
    "        input_shape = input_shape[0]\n",
    "        self.attended_spec = [InputSpec(shape=shape) for shape in attended_shape]\n",
    "        if isinstance(self.cell.state_size, int):\n",
    "            cell_state_size = [self.cell.state_size]\n",
    "        else:\n",
    "            cell_state_size = list(self.cell.state_size)\n",
    "        self.attention_build(\n",
    "            input_shape=input_shape,\n",
    "            cell_state_size=cell_state_size,\n",
    "            attended_shape=attended_shape,\n",
    "        )\n",
    "\n",
    "        if isinstance(self.cell, Layer):\n",
    "            cell_input_shape = (input_shape[0],\n",
    "                                self.attention_size +\n",
    "                                input_shape[-1] if self.concatenate_input\n",
    "                                else self._attention_size)\n",
    "            self.cell.build(cell_input_shape)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            cell_output_dim = self.cell.state_size[0]\n",
    "        else:\n",
    "            cell_output_dim = self.cell.state_size\n",
    "\n",
    "        return input_shape[0], cell_output_dim\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        return super(_RNNAttentionCell, self).trainable_weights + \\\n",
    "               self.cell.trainable_weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        return super(_RNNAttentionCell, self).non_trainable_weights + \\\n",
    "               self.cell.non_trainable_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'attend_after': self.attend_after,\n",
    "                  'concatenate_input': self.concatenate_input}\n",
    "\n",
    "        cell_config = self.cell.get_config()\n",
    "        config['cell'] = {'class_name': self.cell.__class__.__name__,\n",
    "                          'config': cell_config}\n",
    "        base_config = super(_RNNAttentionCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class MixtureOfGaussian1DAttention(_RNNAttentionCell):\n",
    "    \"\"\"RNN attention mechanism for attending sequences.\n",
    "\n",
    "    The attention encoding (passed to the wrapped core RNN cell) is obtained by\n",
    "    letting the attention mechanism predict a Mixture of Gaussian distribution\n",
    "    (MoG) over the time dimension of the attended feature sequence. The\n",
    "    attention encoding is taken as the weighted sum of all features - where the\n",
    "    weight is given by the probability density function (evaluated in the\n",
    "    respective time step) according the predicted MoG distribution.\n",
    "\n",
    "    # Arguments\n",
    "        components: Positive integer, the number of mixture components to use\n",
    "            (for each head, see below).\n",
    "        heads: Positive integer (Default 1), the number of independent \"read\n",
    "            heads\" to use. Each head produces an independent (sub) attention\n",
    "            encoding, by predicting an independent MoG each. The (full)\n",
    "            attention encoding passed to the wrapped core RNN cell is the\n",
    "            concatenation of the attention encodings from each head. See \"Notes\n",
    "            on multiple heads vs multiple components\" below.\n",
    "        mu_activation: The activation function applied (after learnt linear\n",
    "            transformation) for mu:s (expectation value/location) of each\n",
    "            Gaussian component.\n",
    "        sigma_activation: The activation function applied (after learnt linear\n",
    "            transformation) for sigma:s (standard deviation) of each Gaussian\n",
    "            component. *NOTE* that this function should only return values > 0.\n",
    "        sigma_epsilon: Positive Float, this value is added to sigma to force it\n",
    "            to be at least this value.\n",
    "        predict_delta_mu: Boolean (Default True), whether or not to let the\n",
    "            attention mechanism to predict the _change_ in location (mu) of\n",
    "            each mixture component. This is recommended as it usually leads to\n",
    "            more stable convergence. By passing a `mu_activation` that always\n",
    "            returns a value > 0 and having `predict_delta_mu=True` it is\n",
    "            enforced that the attention mechanism \"parses\" the attended\n",
    "            sequence \"from start to end\" as the attention can not be moved\n",
    "            backwards.\n",
    "        For initializers, regularizers & constraints: See docs of Dense layer.\n",
    "\n",
    "    # Notes on multiple heads vs multiple components\n",
    "        A single head can \"attend to multiple parts of the sequence\" by\n",
    "        using multiple components. However, the features from the location of\n",
    "        the components are averaged together by a weighted sum (no\n",
    "        information is kept on their internal ordering for example). With\n",
    "        multiple heads, on the other side, the attention mechanism can \"pick\n",
    "        out\" features from multiple locations without averaging them, and\n",
    "        passing them \"intact\" to the core RNN cell. This is done at the cost of\n",
    "        a larger input vector to, and thereby more parameters of, the core RNN\n",
    "        cell.\n",
    "\n",
    "    # Example - Machine Translation with Attention and \"teacher forcing\"\n",
    "        # NOTE that this is a minimal naive example, this setup will not\n",
    "        # perform well for machine translation in general.\n",
    "        # TODO add `examples/machine_translation_with_attention.py`\n",
    "        # with performing setup\n",
    "\n",
    "        input_english = Input((None, tokens_english))\n",
    "        target_french_tm1 = Input((None, tokens_french))\n",
    "\n",
    "        cell = MixtureOfGaussian1DAttention(LSTMCell(64), components=3, heads=3)\n",
    "        attention_lstm = RNN(cell, return_sequences=True)\n",
    "        h_sequence = attention_lstm(target_french_tm1, constants=input_english)\n",
    "        output_layer = TimeDistributed(Dense(tokens_french, activation='softmax'))\n",
    "        predicted_french = output_layer(h_sequence)\n",
    "\n",
    "        train_model = Model(\n",
    "            inputs=[target_french_tm1, input_english],\n",
    "            outputs=predicted_french\n",
    "        )\n",
    "        model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "        model.fit(\n",
    "            x=[french_text[:, :-1], english_text],\n",
    "            y=french_text[:, 1:],\n",
    "            epochs=10\n",
    "        )\n",
    "    \"\"\"\n",
    "    def __init__(self, cell,\n",
    "                 components,\n",
    "                 heads=1,\n",
    "                 mu_activation=None,\n",
    "                 sigma_activation='exponential',\n",
    "                 sigma_epsilon=1e-3,\n",
    "                 predict_delta_mu=True,  # TODO alternative name `cumulative_mu`?\n",
    "                 kernel_initializer='glorot_uniform',  # FIXME most likely not optimal\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MixtureOfGaussian1DAttention, self).__init__(cell, **kwargs)\n",
    "        self.components = components\n",
    "        self.heads = heads\n",
    "        self.mu_activation = activations.get(mu_activation)\n",
    "        self.sigma_activation = activations.get(sigma_activation)\n",
    "        self.sigma_epsilon = sigma_epsilon\n",
    "        self.predict_delta_mu = predict_delta_mu\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "    @property\n",
    "    def attention_state_size(self):\n",
    "        \"\"\"Size of states dedicated for the attention mechanism.\n",
    "\n",
    "        If self.predict_delta_mu is True, mu (the \"location\") for all heads'\n",
    "        components needs to be forwarded to next time step and is therefore\n",
    "        added to the attention states.\n",
    "        \"\"\"\n",
    "        attention_state_size = [self.attention_size]\n",
    "        if self.predict_delta_mu:\n",
    "            mu_size = self.components * self.heads\n",
    "            attention_state_size.append(mu_size)\n",
    "\n",
    "        return attention_state_size\n",
    "\n",
    "    def attention_call(self,\n",
    "                       inputs,\n",
    "                       cell_states,\n",
    "                       attended,\n",
    "                       attention_states,\n",
    "                       training=None):\n",
    "        # only one attended sequence for now (verified in build)\n",
    "        [attended] = attended\n",
    "        mu_tm1 = attention_states[1] if self.predict_delta_mu else None\n",
    "\n",
    "        mog_input = concatenate([inputs, cell_states[0]])\n",
    "        params = K.bias_add(K.dot(mog_input, self.kernel), self.bias)\n",
    "\n",
    "        # dynamic creation of time index\n",
    "        # TODO check support by all backends\n",
    "        # TODO faster with non-dynamic if size of time dimension is fixed?\n",
    "        time_idx = K.arange(K.shape(attended)[1], dtype='float32')\n",
    "        time_idx = K.expand_dims(K.expand_dims(time_idx, 0), -1)\n",
    "\n",
    "        if self.heads == 1:\n",
    "            attention_h, mu = self._get_attention_h_and_mu(params, attended,\n",
    "                                                           mu_tm1, time_idx)\n",
    "        else:\n",
    "            c = self.components\n",
    "            attention_h_s, mu_s = zip(*[\n",
    "                self._get_attention_h_and_mu(\n",
    "                    params=params[..., c * i * 3:c * (i+1) * 3],\n",
    "                    attended=attended,\n",
    "                    mu_tm1=(mu_tm1[..., c * i:c * (i+1)]\n",
    "                            if self.predict_delta_mu else None),\n",
    "                    time_idx=time_idx\n",
    "                ) for i in range(self.heads)\n",
    "            ])\n",
    "            attention_h = concatenate(list(attention_h_s))\n",
    "            mu = concatenate(list(mu_s))\n",
    "\n",
    "        new_attention_states = [attention_h]\n",
    "        if self.predict_delta_mu:\n",
    "            new_attention_states.append(mu)\n",
    "\n",
    "        return attention_h, new_attention_states\n",
    "\n",
    "    def _get_attention_h_and_mu(self, params, attended, mu_tm1, time_idx):\n",
    "        \"\"\"Computes the attention encoding for \"one head\".\n",
    "\n",
    "        # Arguments\n",
    "            params: The MoG params (before activation) for one head.\n",
    "            attended: The attended sequence (tensor).\n",
    "            mu_tm1: mu from previous time step (tensor) if self.use_delta is\n",
    "                True otherwise None.\n",
    "            time_idx: Time index of the attended (tensor).\n",
    "\n",
    "        # Returns\n",
    "            attention_h: The attention encoding for the attention of one head.\n",
    "            mu: the location(s) of each mixture component for one head.\n",
    "        \"\"\"\n",
    "        def sigma_activation(x):\n",
    "            return self.sigma_activation(x) + self.sigma_epsilon\n",
    "\n",
    "        mixture_weights, mu, sigma = [\n",
    "            activation(params[..., i * self.components:(i + 1) * self.components])\n",
    "            for i, activation in enumerate(\n",
    "                [K.softmax, self.mu_activation, sigma_activation])]\n",
    "\n",
    "        if self.predict_delta_mu:\n",
    "            mu += mu_tm1\n",
    "\n",
    "        mixture_weights_, mu_, sigma_ = [\n",
    "            K.expand_dims(p, 1) for p in [mixture_weights, mu, sigma]]\n",
    "\n",
    "        attention_w = K.sum(\n",
    "            mixture_weights_ * K.exp(- sigma_ * K.square(mu_ - time_idx)),\n",
    "            # NOTE no normalisation was carried out in original paper by A. Graves\n",
    "            axis=-1,\n",
    "            keepdims=True\n",
    "        )\n",
    "        attention_h = K.sum(attention_w * attended, axis=1)\n",
    "\n",
    "        return attention_h, mu\n",
    "\n",
    "    def attention_build(self, input_shape, cell_state_size, attended_shape):\n",
    "        if not len(attended_shape) == 1:\n",
    "            raise ValueError('only a single attended supported')\n",
    "        attended_shape = attended_shape[0]\n",
    "        if not len(attended_shape) == 3:\n",
    "            raise ValueError('only support attending tensors with dim=3')\n",
    "\n",
    "        # NOTE _attention_size must always be set in `attention_build`\n",
    "        self._attention_size = attended_shape[-1] * self.heads\n",
    "        mog_in_dim = (input_shape[-1] + cell_state_size[0])\n",
    "        mog_out_dim = self.heads * self.components * 3\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(mog_in_dim, mog_out_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            name='kernel',\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "        self.bias = self.add_weight(shape=(mog_out_dim,),\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    name='bias',\n",
    "                                    regularizer=self.bias_regularizer,\n",
    "                                    constraint=self.bias_constraint)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'components': self.components,\n",
    "            'heads': self.heads,\n",
    "            'mu_activation': activations.serialize(self.mu_activation),\n",
    "            'sigma_activation': activations.serialize(self.sigma_activation),\n",
    "            'sigma_epsilon': self.sigma_epsilon,\n",
    "            'predict_delta_mu': self.predict_delta_mu,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(MixtureOfGaussian1DAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRUAttentionCell(GRUCell):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.state_size = self.units :for RNN, GRU\n",
    "        #self.state_size = (self.units, self.units) : for LSTM\n",
    "        self.attn_length = 79\n",
    "        self.attn_size = 79\n",
    "        self.attn_vec_size = self.attn_size\n",
    "        self.input_size = None\n",
    "        self.state_size = (self.units, self.units)\n",
    "\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def state_size(self):\n",
    "    size = (self._cell.state_size, self._attn_size,\n",
    "            self._attn_size * self._attn_length)\n",
    "    if self._state_is_tuple:\n",
    "      return size\n",
    "    else:\n",
    "      return sum(list(size))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, output_dim)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state = [K.tile(initial_state, [1, dim])\n",
    "                     for dim in self.cell.state_size[:-1]]\n",
    "        else:\n",
    "            state = [K.tile(initial_state, [1, self.cell.state_size])]\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #self.timesteps = input_shape[0]\n",
    "        print('build cell:', input_shape)\n",
    "        input_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n",
    "                                      name='kernel',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units * 4),\n",
    "            name='recurrent_kernel',\n",
    "            initializer=self.recurrent_initializer,\n",
    "            regularizer=self.recurrent_regularizer,\n",
    "            constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.context_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.units * 3),\n",
    "            name='context_kernel',\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units * 4,),\n",
    "                                        name='bias',\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.kernel_z = self.kernel[:,               : self.units * 1]\n",
    "        self.kernel_r = self.kernel[:, self.units * 1: self.units * 2]\n",
    "        self.kernel_h = self.kernel[:, self.units * 2: self.units * 3]\n",
    "        self.kernel_c = self.kernel[:, self.units * 3:]\n",
    "\n",
    "        self.recurrent_kernel_z = self.recurrent_kernel[:,               : self.units * 1]\n",
    "        self.recurrent_kernel_r = self.recurrent_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n",
    "        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 3:]\n",
    "\n",
    "        self.context_kernel_z = self.context_kernel[:,               : self.units * 1]\n",
    "        self.context_kernel_r = self.context_kernel[:, self.units * 1: self.units * 2]\n",
    "        self.context_kernel_h = self.context_kernel[:, self.units * 2:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_z = self.bias[              : self.units * 1]\n",
    "            self.bias_r = self.bias[self.units * 1: self.units * 2]\n",
    "            self.bias_h = self.bias[self.units * 2: self.units * 3]\n",
    "            self.bias_c = self.bias[self.units * 3:]\n",
    "        else:\n",
    "            self.bias_z = None\n",
    "            self.bias_r = None\n",
    "            self.bias_h = None\n",
    "            self.bias_c = None\n",
    "        self.built = True\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameter Shapes\n",
    "        kernel : (input_dim, units)\n",
    "        recurrent_kernel : (units, units)\n",
    "        bias : (units, )\n",
    "\n",
    "        # Inherited Parameters\n",
    "        kernel : z, r, h\n",
    "        recurrent_kernel : z, r, h\n",
    "        bias : z, r, h\n",
    "\n",
    "        # New Parameters\n",
    "        input_dim\n",
    "        kernel_c\n",
    "        recurrent_kernel_c\n",
    "        bias_c\n",
    "        \"\"\"\n",
    "\n",
    "    def call(self, inputs, states, training=None,\n",
    "             constants=None):\n",
    "        print('cell.call Input Shape:', K.int_shape(inputs), 'State Shape:', K.int_shape(states[0]))\n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        full_inputs = constants\n",
    "        timesteps = K.int_shape(full_inputs)[1]\n",
    "\n",
    "\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
    "                self.dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                _generate_dropout_ones(inputs, self.units),\n",
    "                self.recurrent_dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        if self.implementation == 1:\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs_z = inputs * dp_mask[0]\n",
    "                inputs_r = inputs * dp_mask[1]\n",
    "                inputs_h = inputs * dp_mask[2]\n",
    "                inputs_c = inputs * dp_mask[3]\n",
    "            else:\n",
    "                inputs_z = inputs\n",
    "                inputs_r = inputs\n",
    "                inputs_h = inputs\n",
    "                inputs_c = inputs\n",
    "            x_z = K.dot(inputs_z, self.kernel_z)\n",
    "            x_r = K.dot(inputs_r, self.kernel_r)\n",
    "            x_h = K.dot(inputs_h, self.kernel_h)\n",
    "            x_c = K.dot(inputs_c, self.kernel_c)\n",
    "            if self.use_bias:\n",
    "                x_z = K.bias_add(x_z, self.bias_z)\n",
    "                x_r = K.bias_add(x_r, self.bias_r)\n",
    "                x_h = K.bias_add(x_h, self.bias_h)\n",
    "                x_c = K.bias_add(x_c, self.bias_c)\n",
    "\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1_z = h_tm1 * rec_dp_mask[0]\n",
    "                h_tm1_r = h_tm1 * rec_dp_mask[1]\n",
    "                h_tm1_h = h_tm1 * rec_dp_mask[2]\n",
    "                h_tm1_c = h_tm1 * rec_dp_mask[3]\n",
    "            else:\n",
    "                h_tm1_z = h_tm1\n",
    "                h_tm1_r = h_tm1\n",
    "                h_tm1_h = h_tm1\n",
    "                h_tm1_c = h_tm1\n",
    "\n",
    "            # calculate the context vector\n",
    "            #context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "\n",
    "            # Attention Context Part\n",
    "            #h_tm1_c = K.repeat(h_tm1_c, timesteps)\n",
    "            h_tm1_c = full_inputs\n",
    "            e = self.activation(x_c + K.dot(h_tm1_c, self.recurrent_kernel_c))\n",
    "            a = K.softmax(e)\n",
    "            print('A:', K.int_shape(a), 'inputs_c:', K.int_shape(inputs_c), 'full input:', K.int_shape(full_inputs))\n",
    "            c_t = K.dot(a, inputs_c)\n",
    "\n",
    "            # GRU Part\n",
    "            z = self.recurrent_activation(x_z +\n",
    "                                          K.dot(h_tm1_z,\n",
    "                                                self.recurrent_kernel_z) +\n",
    "                                          K.dot(c_t, self.context_kernel_z))\n",
    "            r = self.recurrent_activation(x_r +\n",
    "                                          K.dot(h_tm1_r,\n",
    "                                                self.recurrent_kernel_r) +\n",
    "                                          K.dot(c_t, self.context_kernel_r))\n",
    "\n",
    "            hh = self.activation(x_h +\n",
    "                                 K.dot(r * h_tm1_h,\n",
    "                                       self.recurrent_kernel_h) +\n",
    "                                 K.dot(c_t, self.context_kernel_h))\n",
    "\n",
    "        else:\n",
    "            \"\"\"\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs *= dp_mask[0]\n",
    "            matrix_x = K.dot(inputs, self.kernel)\n",
    "            if self.use_bias:\n",
    "                matrix_x = K.bias_add(matrix_x, self.bias)\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1 *= rec_dp_mask[0]\n",
    "            matrix_inner = K.dot(h_tm1,\n",
    "                                 self.recurrent_kernel[:, :2 * self.units])\n",
    "\n",
    "            x_z = matrix_x[:, :self.units]\n",
    "            x_r = matrix_x[:, self.units: 2 * self.units]\n",
    "            recurrent_z = matrix_inner[:, :self.units]\n",
    "            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n",
    "\n",
    "            z = self.recurrent_activation(x_z + recurrent_z)\n",
    "            r = self.recurrent_activation(x_r + recurrent_r)\n",
    "\n",
    "            x_h = matrix_x[:, 2 * self.units:]\n",
    "            recurrent_h = K.dot(r * h_tm1,\n",
    "                                self.recurrent_kernel[:, 2 * self.units:])\n",
    "            hh = self.activation(x_h + recurrent_h)\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                h._uses_learning_phase = True\n",
    "        return h, [h]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        input_english = Input((None, tokens_english))\n",
    "        target_french_tm1 = Input((None, tokens_french))\n",
    "\n",
    "        cell = MixtureOfGaussian1DAttention(LSTMCell(64), components=3, heads=3)\n",
    "        h_sequence = RNN(cell, return_sequences=True)(target_french_tm1, constants=input_english)\n",
    "        output_layer = TimeDistributed(Dense(tokens_french, activation='softmax'))\n",
    "        predicted_french = output_layer(h_sequence)\n",
    "\n",
    "        train_model = Model(\n",
    "            inputs=[target_french_tm1, input_english],\n",
    "            outputs=predicted_french\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "79 80\n",
      "cell.build Shape: (None, 80)\n",
      "cell.call Input Shape: (None, 80) Full State len: 2 State Shape: (None, 80) Full h Shape: (None, 6320)\n",
      "h: (None, 6320) s0: (None, 6320, 80)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-442-0e340b8850aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mCel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUAttentionCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    587\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2563\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m<ipython-input-435-f19f6a0e6532>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m#h_tm1_c = full_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's0:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs_c:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 6320 and 80 for 'rnn_27/MatMul_4' (op: 'MatMul') with input shapes: [?,6320], [80,80]."
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "print(timestepX, ndimX)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "Cel = GRUAttentionCell(ndimX)\n",
    "dec = RNN(Cel, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(dec)\n",
    "model = Model(inputs=input_, outputs=act)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATENT_DIM: 64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_172 (InputLayer)       (None, 79, 80)            0         \n",
      "_________________________________________________________________\n",
      "lstm_167 (LSTM)              (None, 79, 80)            51520     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 79, 1)             81        \n",
      "=================================================================\n",
      "Total params: 51,601\n",
      "Trainable params: 51,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_, timestepX, ndimX = train_X.shape\n",
    "_, timestepY, ndimY = train_Y.shape\n",
    "#_, ndimY = seq_Y.shape\n",
    "\n",
    "print('LATENT_DIM: %s' % LATENT_DIM)\n",
    "\n",
    "input_ = Input(shape=(timestepX, ndimX), dtype='float32')\n",
    "enc = LSTM(ndimX, return_sequences=True)(input_)\n",
    "tim = TimeDistributed(Dense(1))(enc)\n",
    "#dec = GRUAttention(4, return_sequences=True)(enc)\n",
    "act = Dense(ndimY, activation='softmax')(tim)\n",
    "model = Model(inputs=input_, outputs=tim)\n",
    "\n",
    "#parallel_model = multi_gpu_model(model, gpus=GPU_NUM)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent  # _time_distributed_dense\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    "\n",
    "\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                            input_dim=None, output_dim=None,\n",
    "                            timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        w: weight matrix.\n",
    "        b: optional bias vector.\n",
    "        dropout: wether to apply dropout (same dropout mask\n",
    "            for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyGRUAttentionDecoder(Recurrent):\n",
    "\n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 output_activation='sigmoid',\n",
    "                 return_probabilities=False,\n",
    "                 name='MyGRUAttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='ones',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states \n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. \n",
    "            \"Neural machine translation by jointly learning to align and translate.\" \n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.output_activation = output_activation\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    "\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    "\n",
    "        if self.stateful:\n",
    "            super().reset_states()\n",
    "\n",
    "        self.states = [None, None]  # y, h\n",
    "\n",
    "        \n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "\n",
    "\n",
    "        # Matrices for creating the context vector\n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        # Matrices for Gates\n",
    "        # st = h_tilda\n",
    "        num = len(['reset_gate', 'update_gate', 'h_tilda(proposal)'])\n",
    "\n",
    "        self.W = self.add_weight(shape=(num, self.output_dim, self.units),\n",
    "                                   name='W',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U = self.add_weight(shape=(num, self.units, self.units),\n",
    "                                   name='U',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.V = self.add_weight(shape=(num, self.input_dim, self.units),\n",
    "                                   name='V',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b = self.add_weight(shape=(num, self.units, ),\n",
    "                                   name='b',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "\n",
    "        # Matrices for making the final prediction vector\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    "\n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    "\n",
    "\n",
    "        return super().call(x)\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        print('inputs shape:', inputs.get_shape())\n",
    "\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        h0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    "\n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    "\n",
    "        return [y0, h0]\n",
    "\n",
    "    def step(self, x, states):\n",
    "\n",
    "        yt_before, ht_before = states\n",
    "\n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        repeated_ht_before = K.repeat(ht_before, self.timesteps)\n",
    "\n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        weighted_ht_before = K.dot(repeated_ht_before, self.W_a)\n",
    "\n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(weighted_ht_before + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.softmax(et)  # vector of size (batchsize, timesteps, 1)\n",
    "\n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        \n",
    "        # At timestep `t`:\n",
    "        \n",
    "        # first calculate the \"r\"; reset gate\n",
    "        # r = sigmoid(xt * Ur + ht-1 * Wr + br) \n",
    "        # New r = sigmoid(xt * Ur + ht-1 * Wr + br + context * Vr)\n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(yt_before, self.W[0])\n",
    "            + K.dot(ht_before, self.U[0])\n",
    "            + K.dot(context, self.V[0])\n",
    "            + self.b[0])\n",
    "\n",
    "        # now calculate the \"z\"; update gate\n",
    "        # z = sigmoid(xt * Uz + ht-1 * Wz + bz)\n",
    "        # New z = sigmoid(xt * Uz + ht-1 * Wz + bz + context * Vz)\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(yt_before, self.W[1])\n",
    "            + K.dot(ht_before, self.U[1])\n",
    "            + K.dot(context, self.V[1])\n",
    "            + self.b[1])\n",
    "\n",
    "        # calculate the proposal \"g\"; hidden state for now(tilda)\n",
    "        # h_tilda = tanh(xt * Wh + (ht-1 * rt) * Uh + bh)\n",
    "        # New h_tilda = tanh(xt * Wh + (ht-1 * rt) * Uh + bh + context * Vh)\n",
    "        h_tilda = activations.tanh(\n",
    "            K.dot(yt_before, self.W[2])\n",
    "            + K.dot((rt * ht_before), self.U[2])\n",
    "            + K.dot(context, self.V[2])\n",
    "            + self.b[2])\n",
    "\n",
    "        # new hidden state 'ht' from 'h_tilda'\n",
    "        # ht = (1-zt) * h_tilda + zt * ht-1\n",
    "        # ht = (1-zt) * h_tilda + zt * ht-1\n",
    "        ht = (1 - zt) * h_tilda + zt * ht_before\n",
    "\n",
    "        \n",
    "        # Output Activation\n",
    "        y_ = (K.dot(yt_before, self.W_o)\n",
    "              + K.dot(ht_before, self.U_o)\n",
    "              + K.dot(context, self.C_o)\n",
    "              + self.b_o)\n",
    "\n",
    "        if self.output_activation == 'softmax':\n",
    "            yt = activations.softmax(y_)\n",
    "            \n",
    "        elif self.output_activation == 'sigmoid':\n",
    "            yt = activations.sigmoid(y_)\n",
    "\n",
    "        elif self.output_activation == 'tanh':\n",
    "            yt = activations.tanh(y_)\n",
    "\n",
    "            \n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, ht]\n",
    "        else:\n",
    "            return yt, [yt, ht]\n",
    "\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_NUM: 100, BATCH_SIZE 256\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_10 to have shape (None, 79, 80) but got array with shape (80000, 79, 110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-d5e98611bd84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;31m# 1: progress bar, 2: one line per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0;31m#validation_data=(testX, testY),  # Validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                    \u001b[0;31m#callbacks=[history],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   )\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/apps/anaconda3/envs/tf-py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_10 to have shape (None, 79, 80) but got array with shape (80000, 79, 110)"
     ]
    }
   ],
   "source": [
    "print('EPOCH_NUM: %s, BATCH_SIZE %s' % (EPOCH_NUM, BATCH_SIZE))\n",
    "\n",
    "fitted = model.fit(train_X, train_Y,\n",
    "                   epochs=10,     # How many times to run back_propagation\n",
    "                   batch_size=2,  # How many data to deal with at one epoch\n",
    "                   validation_split=0.2,\n",
    "                   verbose=2,       # 1: progress bar, 2: one line per epoch\n",
    "                   #validation_data=(testX, testY),  # Validation set\n",
    "                   shuffle=True,\n",
    "                   #callbacks=[history],\n",
    "                  )\n",
    "\n",
    "# Save model\n",
    "model.save('gru_attention_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 3))\n",
    "ax.plot(fitted.history['loss'], label='train')\n",
    "if 'val_loss' in fitted.history.keys():\n",
    "    ax.plot(fitted.history['val_loss'], label='validation')\n",
    "ax.legend()\n",
    "ax.set_xticks(np.arange(EPOCH_NUM))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = fitted.model.evaluate(train_X, train_Y, verbose=0)\n",
    "print('Accuracy: %.3f' % (train_accuracy * 100))\n",
    "\n",
    "train_Y_hat_array = fitted.model.predict(train_X)\n",
    "train_Y_real = output_decoder(train_Y)\n",
    "train_Y_hat = output_decoder(train_Y_hat_array)\n",
    "train_X_real = input_decoder(train_X)\n",
    "\n",
    "print(train_X_real[:3])\n",
    "print(train_Y_real[:3])\n",
    "print(train_Y_hat[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train mean of RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = fitted.model.evaluate(test_X, test_Y, verbose=0)\n",
    "print('Accuracy: %.3f' % (test_accuracy * 100))\n",
    "\n",
    "test_Y_hat_array = fitted.model.predict(test_X)\n",
    "test_Y_real = output_decoder(test_Y)\n",
    "test_Y_hat = output_decoder(test_Y_hat_array)\n",
    "test_X_real = input_decoder(test_X)\n",
    "\n",
    "print(test_X_real[:3])\n",
    "print(test_Y_real[:3])\n",
    "print(test_Y_hat[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "gist": {
   "data": {
    "description": "tensorflow/konlpy.ipynb",
    "public": false
   },
   "id": "5481ffd625eda4e9d4455a8d8b181ca6"
  },
  "kernelspec": {
   "display_name": "Tensorflow: Python3.6 (conda env)",
   "language": "python",
   "name": "tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "1176px",
    "left": "0px",
    "right": "1123px",
    "top": "136px",
    "width": "157px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": 16,
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
